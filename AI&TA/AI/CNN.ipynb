{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Network (CNN)\n",
    "---\n",
    "卷积神经网络（Convolutional Neural Network，CNN）是一种专门用于处理图像和图像类数据的深度学习模型。它在计算机视觉领域取得了巨大成功，被广泛应用于图像识别、物体检测、图像分割等任务。以下是对CNN的详细介绍：\n",
    "\n",
    "**卷积神经网络的结构特点：**\n",
    "\n",
    "1. **卷积层（Convolutional Layer）**：CNN最重要的特点之一是卷积层。卷积操作是通过滤波器（也称为卷积核）在输入图像上滑动并执行局部感知操作。卷积层可以自动学习图像中的特征，例如边缘、纹理和形状。通常，多个卷积核用于提取不同的特征。\n",
    "\n",
    "2. **池化层（Pooling Layer）**：池化层用于降低特征图的空间维度，减少参数数量和计算复杂性。常见的池化操作包括最大池化和平均池化，它们分别取池化窗口内的最大值或平均值。池化有助于提取最显著的特征。\n",
    "\n",
    "3. **全连接层（Fully Connected Layer）**：在CNN的顶部，通常有一个或多个全连接层，用于将卷积层和池化层提取的特征映射到最终的输出类别。这些层与传统的前馈神经网络相似。\n",
    "\n",
    "4. **卷积核共享参数**：CNN中的卷积核是共享参数的，这意味着它们在整个输入图像上执行相同的卷积操作。这有助于减少参数数量，并使网络更容易训练。\n",
    "\n",
    "5. **局部感知和平移不变性**：CNN通过卷积操作实现了局部感知，这意味着每个神经元只关注输入的局部区域，从而减少了计算复杂性。此外，卷积神经网络具有平移不变性，即对于不同位置的相似特征具有相同的响应。\n",
    "\n",
    "**CNN的应用领域：**\n",
    "\n",
    "CNN在计算机视觉领域的应用非常广泛，包括但不限于以下领域：\n",
    "\n",
    "1. **图像分类**：CNN可以用于图像分类任务，如将图像分为不同的类别，例如猫、狗、汽车等。\n",
    "\n",
    "2. **物体检测**：CNN能够检测图像中的物体并标出其位置，用于物体识别和定位。\n",
    "\n",
    "3. **图像分割**：CNN可用于图像分割，将图像分成不同的区域，每个区域对应一个对象或物体。\n",
    "\n",
    "4. **人脸识别**：CNN在人脸识别领域取得了显著进展，用于身份验证和安全应用。\n",
    "\n",
    "5. **自动驾驶**：卷积神经网络在自动驾驶系统中广泛应用，用于感知和决策。\n",
    "\n",
    "总的来说，卷积神经网络是一种强大的深度学习模型，特别适用于处理图像和空间数据，它已经在许多领域取得了显著的成就，并持续推动计算机视觉和图像处理技术的发展。\n",
    "\n",
    "与FNN对比，CNN在处理图像和空间数据时具有明显的优势，这些优势包括参数共享、局部感知、平移不变性和自动特征提取等，使其成为计算机视觉和图像处理任务中的首选模型。然而，在某些非图像数据上，FNN仍然具有一定的优势。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8090a2ebceb0ad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T18:51:31.110569Z",
     "start_time": "2024-02-02T18:51:31.060281100Z"
    }
   },
   "id": "535ddda235eb8f97",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 卷积\n",
    "---\n",
    "卷积是一种数学运算，通常在信号处理、图像处理和深度学习等领域中广泛应用。数学上，离散一维卷积和二维卷积可以定义如下：\n",
    "\n",
    "**一维卷积**：\n",
    "对于两个离散信号（序列）f和g，它们的一维卷积（也称为离散卷积）定义为：\n",
    "$$(f * g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m] \\cdot g[n - m]$$\n",
    "其中，$*$ 表示卷积操作，n是输出的序列索引，m是卷积核（滤波器）g的索引。卷积核g通过滑动（翻转后）与信号f的不同位置进行卷积操作，最终得到卷积结果f * g。\n",
    "\n",
    "**二维卷积**：\n",
    "对于两个离散二维图像（矩阵）F和G，它们的二维卷积定义为：\n",
    "$$(F * G)[i, j] = \\sum_{m=-\\infty}^{\\infty} \\sum_{n=-\\infty}^{\\infty} F[m, n] \\cdot G[i - m, j - n]$$\n",
    "其中，$*$ 表示卷积操作，(i, j) 是输出图像的像素坐标，(m, n) 是卷积核G的像素坐标。卷积核G通过滑动（翻转后）与图像F的不同位置进行卷积操作，最终得到卷积结果F * G。\n",
    "\n",
    "要注意的是，卷积操作通常包括了翻转（或翻转后的滑动）卷积核，这是因为在信号处理和深度学习中，通常使用的卷积是“卷积-求和”操作，而不是“交叉相关-求和”操作。因此，在计算卷积时，卷积核通常会进行翻转以匹配卷积操作的定义。\n",
    "\n",
    "卷积操作在信号处理中用于滤波、特征提取等任务，在深度学习中用于卷积神经网络（CNN）的卷积层，用于提取图像和特征的重要操作。通过不同的卷积核，可以捕捉不同的图像特征，例如边缘、纹理、形状等。\n",
    "\n",
    "---\n",
    "在深度学习中，通常使用的是互相关（cross-correlation）操作而不是纯粹的数学卷积操作。尽管它们在数学上略有不同，但在深度学习中，这两者经常被混淆使用，因为它们在实际计算上是等效的。\n",
    "\n",
    "在数学上，卷积操作要求对卷积核进行翻转（旋转180度）后与输入信号进行卷积。而在深度学习中，通常使用的是互相关操作，不进行卷积核的翻转。这是因为在深度学习的卷积神经网络（CNN）中，卷积核的参数是可以学习的，因此网络可以自动学习正确的卷积核权重，而不需要手动翻转它们。\n",
    "\n",
    "在实际应用中，使用互相关操作更常见，因为它更直观并且与卷积核的学习方式更符合。因此，当我们谈论深度学习中的卷积操作时，通常是指互相关操作。\n",
    "\n",
    "总之，虽然在数学上存在区别，但在深度学习中，互相关操作通常用于代替卷积操作，因为它更适合神经网络的训练和应用。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c046e566056e8c90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Stride & Padding\n",
    "Stride（步长）是卷积操作中的一个重要参数，用于控制卷积核在输入上滑动的步长。Stride的值越大，卷积核滑动的步长越大，输出的特征图尺寸越小。Stride的值越小，卷积核滑动的步长越小，输出的特征图尺寸越大。\n",
    "\n",
    "Padding(填充)是在输入数据的周围添加额外的像素值（通常是零）以扩展输入的尺寸。填充在卷积操作之前应用，可以用来控制输出特征图的尺寸。\n",
    "\n",
    "<img src=\"./images/img_2.png\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fda4943cccb8086"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 卷积层\n",
    "FNN中，需要将输入数据展平为一维张量，然后通过全连接层进行处理。然而，对于图像数据，这样处理会导致参数数量过多，计算量过大，且无法利用图像的空间结构信息。CNN通过卷积层来解决这个问题，卷积层可以自动提取图像中的特征，从而减少参数数量和计算量。\n",
    "\n",
    "<img src=\"./images/img_3.png\">\n",
    "\n",
    "\n",
    "- 权重共享：卷积层中的卷积核是共享参数的，即在第k层，所有的卷积核都相同，为$W_k$，这样可以大大减少参数数量，使得网络更容易训练。\n",
    "- 局部连接：卷积层中的每个神经元只连接到输入数据的一个局部区域，这个局部区域称为感受野（receptive field）。这样可以大大减少参数数量，使得网络更容易训练。这个连接区域决定于卷积核的大小，例如，如果卷积核的大小为3x3，则每个神经元只连接到输入数据的3x3区域。\n",
    "\n",
    "当卷积核大小k=input_size时，卷积层可以视为全连接层。但是，卷积层通常用小于input_size的卷积核，以便提取局部特征。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26727d9364c77c23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convolutional Layer 卷积层\n",
    "\n",
    "卷积层是神经网络中用于处理图像数据的重要层，它通过卷积操作从图像中提取特征。在卷积层中，每个神经元不是连接到上一层的所有神经元，而是仅连接到输入中的一个局部区域，这个连接的局部区域称为卷积核或滤波器。多个卷积核允许网络同时学习多个特征。\n",
    "\n",
    "**特征映射**：卷积层的输出称为特征映射（Feature Map），它是通过卷积操作从输入数据中提取的特征。每个卷积核都可以提取输入数据中的一个特定特征，多个卷积核可以提取多个特征。如果为灰度图像，有一个特征映射；如果为彩色图像，有3个特征映射（分别对应RGB通道）。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8c97dff5a5bf234"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)`\n",
    "- `in_channels`：输入数据的通道数，例如彩色图像的通道数为3（RGB）。\n",
    "- `out_channels`：卷积层中卷积核（滤波器）的数量，这也决定了输出数据的通道数。\n",
    "- `kernel_size`：卷积核的大小，可以是一个整数或者由两个整数构成的元组，分别代表卷积核的高度和宽度。若为n则表示卷积核的高度和宽度都为n；若为(n, m)则表示卷积核的高度为n，宽度为m。\n",
    "- `stride`：卷积时的步长，决定了卷积核滑动的距离，可以是一个整数或者由两个整数构成的元组，分别代表在高度和宽度方向上的步长。默认为1。\n",
    "- `padding`：在输入数据周围添加的零填充的层数，可以是一个整数或者由两个整数构成的元组，分别代表在高度和宽度方向上的填充。默认为0。\n",
    "- `dilation`：卷积核中元素之间的间距，用于定义膨胀卷积，可以增加感受野。默认为1。\n",
    "- `groups`：控制输入和输出之间的连接方式，用于实现分组卷积。默认为1，表示标准卷积。\n",
    "- `bias`：是否在卷积层的输出中添加偏置项。默认为True。\n",
    "\n",
    "nn.Conv2d的输入是一个4维张量，形状为$[batch_size, inchannels, height, width]$，其中batch_size表示批处理中的样本数量，in_channels表示输入通道数，height和width表示图像的高度和宽度。输出也是一个4维张量，形状为[batch_size, out_channels, output_height, output_width]，其中output_height和output_width取决于卷积层的参数（如kernel_size、stride、padding等）和输入尺寸。\n",
    "\n",
    "卷积操作本质上是在输入图像的局部区域上应用滤波器，通过滑动卷积核并计算点乘和来提取特征。每个卷积核负责检测输入中的某种特定模式或特征，多个卷积核允许网络学习多种特征。\n",
    "\n",
    "#### 计算公式\n",
    "对于每个维度（宽度和高度），输出大小（`output_size`）可以通过以下公式计算：\n",
    "\n",
    "$$\\[ \\text{output\\_size} = \\left\\lfloor \\frac{\\text{input\\_size} + 2 \\times \\text{padding} - \\text{dilation} \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1 \\right\\rfloor \\]$$\n",
    "\n",
    "一般默认padding=0，dilation=1，stride=1，这时输出大小可以简化为：\n",
    "$$ output\\_size=input\\_size - kernel\\_size + 1$$\n",
    "\n",
    "其中：\n",
    "- `input_size` 是输入图像的尺寸（宽度或高度）。\n",
    "- `padding` 是在输入图像边缘添加的零填充的层数。\n",
    "- `dilation` 是卷积核中相邻元素之间的间距。当 `dilation=1` 时，表示没有膨胀，卷积核的元素是连续的。\n",
    "- `kernel_size` 是卷积核的尺寸（宽度或高度）。\n",
    "- `stride` 是卷积核移动的步长。\n",
    "- 符号 `⌊ ⌋` 表示向下取整。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d83bb0dedaf2c563"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 代码示例\n",
    "\n",
    "$\\[ \\text{output width} = \\left( \\frac{5 + 2 \\times 0 - 2 - 1}{1} \\right) + 1 = 3 \\]$\n",
    "$\\[ \\text{output height} = \\left( \\frac{5 + 2 \\times 0 - 2 - 1}{1} \\right) + 1 = 3 \\]$\n",
    "\n",
    "所以，每个输出特征图的大小是 $\\(3 \\times 3\\)$。这个计算表明，当卷积核滑过输入图像时，由于没有填充来扩展图像的边缘，且步长为1，每个方向上的有效滑动次数是输入尺寸减去卷积核尺寸加1。因此，如果你有一个 $\\(5 \\times 5\\)$ 的图像和一个 $\\(3 \\times 3\\)$ 的卷积核，那么卷积核可以在每个方向上滑动 $\\(5 - 3 + 1 = 3\\)$ 次，产生一个 $\\(3 \\times 3\\)$ 的输出特征图。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39fcab7df048f6a4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2817,  0.1275, -0.0267],\n",
      "          [-0.4894, -0.6437, -0.7979],\n",
      "          [-1.2606, -1.4148, -1.5690]],\n",
      "\n",
      "         [[-0.7577, -1.1682, -1.5788],\n",
      "          [-2.8104, -3.2209, -3.6315],\n",
      "          [-4.8631, -5.2736, -5.6842]],\n",
      "\n",
      "         [[ 6.6946,  7.1855,  7.6765],\n",
      "          [ 9.1493,  9.6402, 10.1312],\n",
      "          [11.6040, 12.0949, 12.5859]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 卷积层示例\n",
    "# 设置随机数种子\n",
    "torch.manual_seed(0)\n",
    "# 创建一个卷积层，输入通道数为1，输出通道数为3，卷积核大小为3*3\n",
    "layer = nn.Conv2d(1, 3, kernel_size=3)\n",
    "# 创建一个4维的单通道（灰度）图像，图像大小为5*5: [1, 1, 5, 5]\n",
    "tensor = torch.FloatTensor([[[[1, 2, 3, 4, 5],\n",
    "                              [6, 7, 8, 9, 10],\n",
    "                              [11, 12, 13, 14, 15],\n",
    "                              [16, 17, 18, 19, 20],\n",
    "                              [21, 22, 23, 24, 25]]]])\n",
    "# 卷积\n",
    "output = layer(tensor)\n",
    "print(output) \n",
    "# 输入size：[1, 1, 5, 5]\n",
    "# 输出size：[1, 3, 3, 3]\n",
    "# 一个卷积层将一个单通道的 5×5 图像转换成了具有3个通道的 3×3 图像。这里的“通道”可以被理解为独立的特征图，每个特征图是由卷积层中的一个独立卷积核通过卷积操作从输入图像中提取的特征。"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T18:51:31.112071700Z",
     "start_time": "2024-02-02T18:51:31.078247700Z"
    }
   },
   "id": "206cb7efd1b2dbce",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pooling Layer 池化层\n",
    "池化层（Pooling Layer）是卷积神经网络（CNN）中常用的一种层，主要用于特征选择，降低特征图的维度，减少计算量，同时保留重要信息。池化操作通过对输入特征图的局部区域进行下采样，从而减小特征图的尺寸。池化层通常跟在卷积层后面，用于减少卷积层输出的特征图的维度，使得网络对于输入的小变化更加不变（invariant），增强了网络的泛化能力。\n",
    "\n",
    "#### 主要类型\n",
    "池化层主要有两种类型：\n",
    "1. **最大池化（Max Pooling）**：在输入特征图的局部区域中取最大值作为该区域的输出。最大池化有助于提取图像中的纹理和形状信息，是最常用的池化方式。\n",
    "2. **平均池化（Average Pooling）**：计算输入特征图的局部区域中所有元素的平均值，并将该平均值作为输出。平均池化有助于平滑图像特征。\n",
    "\n",
    "<img src=\"./images/img_4.png\">\n",
    "\n",
    "#### 参数\n",
    "池化层的主要参数包括：\n",
    "- **池化核大小（Kernel Size）**：池化操作覆盖的区域大小。常见的选择有2x2或3x3。\n",
    "- **步长（Stride）**：池化窗口滑动的步长。如果步长等于池化核的大小，那么池化窗口不会重叠。\n",
    "- **填充（Padding）**：在输入特征图的边缘添加的零填充的层数，用于控制输出特征图的大小。在池化操作中，填充不如在卷积操作中常用。\n",
    "\n",
    "#### 作用\n",
    "池化层的主要作用包括：\n",
    "- **降维**：减少特征图的尺寸，从而减少后续层的参数数量和计算量，防止过拟合。\n",
    "- **增强特征不变性**：通过池化操作，网络能够对输入图像中的小的变化（如平移、旋转等）更加鲁棒。\n",
    "- **特征强化**：最大池化可以强化特征图中的显著特征，有助于模型捕捉关键信息。\n",
    "\n",
    "#### 使用场景\n",
    "池化层广泛应用于各种卷积神经网络架构中，尤其是在处理图像和视频数据时。在多层卷积和池化层的交替使用中，网络能够逐渐提取从低级到高级的特征，从而实现复杂任务的学习，如图像分类、物体检测和语义分割等。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1836116e8864427e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 计算公式\n",
    "池化层只会改变输入特征图的尺寸，不会改变通道数。即输入[batch_size, in_channels, height, width]，输出[batch_size, in_channels, output_height, output_width]。channels维度的大小保持不变，而height和width的大小取决于池化操作的参数（如kernel_size、stride、padding等）和输入尺寸。\n",
    "\n",
    "对于每个维度（宽度和高度），输出大小（`output_size`）可以通过以下公式计算：\n",
    "\n",
    " $$\\(output\\_size = \\left\\lfloor\\frac{{\\text{input\\_size} - \\text{kernel\\_size}}}{{\\text{stride}}} + 1\\right\\rfloor\\)$$\n",
    "\n",
    "$\\lfloor  \\rfloor$ 表示向下取整。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c97baf9d2044cbd7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 卷积网络整体结构\n",
    "<img src=\"./images/img_5.png\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "563d58f5ef9eee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 代码示例\n",
    "下面是一个一般情况使用多层卷积和池化层的示例。在这个示例中，我们使用了一个包含一个卷积层和两个池化层的卷积神经网络，这也是一般卷积神经网络的基本结构。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5647b1a8358af449"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 8, 8])\n",
      "Output shape: torch.Size([1, 6, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# 定义一个简单的CNN模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 继承父类nn.Module的所有属性和方法\n",
    "        \n",
    "        # 定义一个卷积层，输入通道为1，输出通道为6，卷积核大小为3\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=3)\n",
    "        # 定义一个最大池化层，使用2x2的窗口\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 定义一个平均池化层，使用2x2的窗口\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 通过卷积层\n",
    "        x = self.conv1(x) # 此时输出为[1 ,6 , 6, 6]\n",
    "        # 通过ReLU激活函数， 非强制性，但是可以使得输出应用下一层（如池化层）之前引入非线性。\n",
    "        x = F.relu(x) # 添加非线性，结果形状不变\n",
    "        # 通过最大池化层\n",
    "        x = self.max_pool(x) # 此时输出为[1, 6, 3, 3]\n",
    "        # 通过平均池化层\n",
    "        x = self.avg_pool(x) # 此时输出为[1, 6, 1, 1]\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = SimpleCNN()\n",
    "\n",
    "# 创建一个随机输入张量，模拟一个批次中有1个单通道图像，大小为8x8\n",
    "input_tensor = torch.randn(1, 1, 8, 8)\n",
    "\n",
    "# 将输入张量传递给模型\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T18:51:31.112071700Z",
     "start_time": "2024-02-02T18:51:31.093234100Z"
    }
   },
   "id": "f60f30ec3f3115df",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 完整CNN代码示例\n",
    "下面代码的CNN模型包括两个卷积层--两个最大池化层--两个全连接层，通过识别手写数字的MNIST数据集来展示CNN的应用。\n",
    "\n",
    "1. `datasets.MNIST('../data', train=True, download=True, ...)`\n",
    "   - `datasets.MNIST`：PyTorch提供的一个用于加载MNIST手写数字数据集的接口。\n",
    "   - `'../data'`：指定数据集下载（如果尚未下载）和存储的位置。这里是相对于当前工作目录的`data`文件夹。\n",
    "   - `train=True`：指定加载的是训练集。如果设置为`False`，则加载的是测试集。\n",
    "   - `download=True`：如果数据集尚未下载，则允许自动下载。\n",
    "\n",
    "2. `transform=transforms.Compose([...])`\n",
    "   - `transforms.Compose`：组合一系列的变换操作。\n",
    "   - `transforms.ToTensor()`：将PIL图像或NumPy数组转换为PyTorch张量，并且把像素值从[0, 255]缩放到[0.0, 1.0]的范围。\n",
    "   - `transforms.Normalize((0.1307,), (0.3081,))`：标准化张量图像，使用均值`0.1307`和标准差`0.3081`进行归一化。这些值通常是根据数据集预计算得出的。这里使用的是MNIST数据集的全局均值和标准差。\n",
    "\n",
    "3. `DataLoader(...)`\n",
    "   - `DataLoader`：PyTorch中用于加载数据的工具，可以迭代地提供给网络小批量的数据。\n",
    "        - `batch_size=64`：指定每个小批量的数据包含的样本数。这里设置为64，意味着每次迭代会提供64张图片给模型。\n",
    "        - `shuffle=True`：在每个epoch开始时，打乱数据。这有助于模型泛化，防止模型记忆训练数据的顺序。\n",
    "\n",
    "综上所述，这段代码配置了一个数据加载器，它会以64张图片为一组，从MNIST数据集中加载经过标准化处理的图像数据，用于训练过程。数据加载器在每个epoch开始时会打乱数据，以提高训练的效果。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6b3751accf0d327"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 数据加载和预处理\n",
    "train_loader = DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T18:51:31.178850Z",
     "start_time": "2024-02-02T18:51:31.116060900Z"
    }
   },
   "id": "2c2b9dde57439eac",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 定义CNN模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 定义第一个卷积层，输入通道为1（灰度图），输出通道为10，卷积核大小为5\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        # 定义第二个卷积层，输入通道为10，输出通道为20，卷积核大小为5\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        # 定义一个最大池化层，窗口大小为2，即kernel_size=2\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # 定义两个全连接层\n",
    "        self.fc1 = nn.Linear(20*4*4, 50)  # 320 = 20*4*4，4\n",
    "        self.fc2 = nn.Linear(50, 10)  # 10个输出对应于10个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 通过第一个卷积层后使用ReLU激活函数，然后通过最大池化\n",
    "        # \n",
    "        x = F.relu(self.max_pool(self.conv1(x)))\n",
    "        # 通过第二个卷积层后使用ReLU激活函数，然后通过最大池化\n",
    "        x = F.relu(self.max_pool(self.conv2(x)))\n",
    "        # 将特征图展平\n",
    "        x = x.view(-1, 320)\n",
    "        # 通过第一个全连接层后使用ReLU激活函数\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 通过第二个全连接层得到最终的输出\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T18:51:31.194797Z",
     "start_time": "2024-02-02T18:51:31.171874Z"
    }
   },
   "id": "cf5c3631da51a7e9",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.363403\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.668899\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.433514\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.278730\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.173540\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.193385\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.277416\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.383217\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.135102\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.148474\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9590/10000 (96%)\n"
     ]
    }
   ],
   "source": [
    "# 设置设备\n",
    "# device=torch.device(\"cuda\" )\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 实例化模型并移动到设备上\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# 训练模型\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()   # 梯度清零\n",
    "        output = model(data)   # 前向传播\n",
    "        loss = criterion(output, target) # 使用交叉熵损失函数\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新参数\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# 测试模型\n",
    "def test():\n",
    "    # 切换模型为评估模式,这会关闭dropout和batch normalization\n",
    "    model.eval()\n",
    "    # 初始化测试损失\n",
    "    test_loss = 0\n",
    "    # 初始化预测正确的数量\n",
    "    correct = 0\n",
    "    \n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        # 遍历测试集\n",
    "        for data, target in test_loader:\n",
    "            # 将数据移动到设备上,若设置有gpu则device代表gpu\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # 前向传播\n",
    "            output = model(data)\n",
    "            # 计算测试损失，criterion（）.item（）返回张量中的元素值,这里表示用交叉熵损失函数计算损失\n",
    "            test_loss += criterion(output, target).item()  # 将一批的损失相加\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # 获得概率最大的索引\n",
    "            \n",
    "            # 计算预测正确的数量，.eq()表示比较两个张量相同位置的元素是否相等，.view_as(pred)表示将target张量的形状变成和pred一样\n",
    "            # correct为预测正确的数量\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    # test_loss为所有batch的平均损失\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    # 打印测试结果\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "# 执行训练和测试,这里只训练了一个epoch\n",
    "for epoch in range(1, 2):\n",
    "    train(epoch)\n",
    "    test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T19:00:07.913947100Z",
     "start_time": "2024-02-02T18:59:56.312990400Z"
    }
   },
   "id": "615fc8535612c47a",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 典型的卷积神经网络\n",
    "---\n",
    "## 2.1 LeNet-5\n",
    "LeNet-5 是一个经典的卷积神经网络（CNN）架构，由 Yann LeCun 等人于 1998 年提出，主要用于手写数字识别和其他图像识别任务。LeNet-5 是深度学习和计算机视觉领域最早期的突破之一，尽管它的结构相对简单，但它奠定了现代深度卷积网络的基础。\n",
    "\n",
    "LeNet-5 的架构主要包括以下层：\n",
    "\n",
    "1. **输入层**：输入图像大小通常为 32x32x1（对于 MNIST 数据集，图像会被调整到这个大小，因为LeNet-5一般输入为灰度图像，所以只有一个通道）。\n",
    "2. **C1 层（第一个卷积层）**：使用 6 个 5x5 的卷积核，不包括边缘填充（padding），输出维度会是 28x28x6（因为 32-5+1=28）。\n",
    "3. **S2 层（第一个池化层）**：对 C1 层的输出进行 2x2,stride=2 的池化操作，输出维度变为 14x14x6。(因为(28-2)/2+1=14).\n",
    "4. **C3 层（第二个卷积层）**：使用 16 个 5x5 的卷积核，对 S2 层的输出进行卷积，输出维度变为 10x10x16（因为 14-5+1=10）。\n",
    "5. **S4 层（第二个池化层）**：对 C3 层的输出进行 2x2 的池化操作，输出维度变为 5x5x16。(因为(10-2)/2+1=5).\n",
    "\n",
    "接下来是 **C5 层**，这一层通常被视为一个全连接层，因为其卷积核的大小与输入维度相同（5x5），使得每个卷积核覆盖了 S4 层输出的整个区域。因此，每个卷积核产生的输出将是一个单独的值，而不是一个特征图。\n",
    "\n",
    "- **C5 层**：使用 120 个 5x5 的卷积核，每个卷积核都完整地覆盖了 S4 层的 5x5x16 的输出，产生一个单一的输出值。因此，C5 层的输出维度将是 1x1x120。因为 5-5+1=1。\n",
    "\n",
    "- **F6 层（第一个全连接层）**：C5 层的 120 个 1x1x120 的输出将被连接到一个包含 84 个神经元的全连接层，输出维度为 1x1x84。\n",
    "- **输出层**：F6 层的 84 个神经元将连接到一个输出层，输出维度为 1x1x10，对应于 10 个类别的概率分布(因为MNIST数据集有10个类别即数字0-9)。\n",
    "\n",
    "LeNet-5 使用的激活函数最初是 Sigmoid 或者双曲正切（Tanh），但在现代实现中，ReLU 变得更为流行，因为它能够加速训练过程并减少梯度消失的问题。此外，LeNet-5 中的下采样层在现代架构中通常被更有效的最大池化层所替代。\n",
    "\n",
    "尽管 LeNet-5 相对于现代深度学习模型而言比较简单，但它对深度学习和卷积神经网络的发展具有重要的历史意义。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77210394d0c3fcf4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "batch_size = 64\n",
    "\n",
    "# MNIST 数据集的转换器，首先将数据转换为张量，然后标准化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # LeNet-5 需要 32x32 的输入\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 下载并加载训练集\n",
    "train_dataset = datasets.MNIST(root='C:\\\\Users\\\\yhb\\\\MscProject\\\\AI&TA\\\\data', train=True, download=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 下载并加载测试集\n",
    "test_dataset = datasets.MNIST(root='C:\\\\Users\\\\yhb\\\\MscProject\\\\AI&TA\\\\data', train=False, download=False, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T19:55:03.101147500Z",
     "start_time": "2024-02-02T19:55:03.029589Z"
    }
   },
   "id": "3e7a14d8a81faa22",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# LeNet-5示例\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        # 定义第卷积层C1, 输入通道为1，输出通道为6，卷积核大小为5(6个5x5的卷积核)\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        # 定义池化层S2，最大池化，窗口大小为2\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 定义第卷积层C3, 输入通道为6，输出通道为16，卷积核大小为5(16个5x5的卷积核)\n",
    "        self.conv3 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        # 定义池化层S4，最大池化，窗口大小为2\n",
    "        self.max_pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 定义第卷积层C5，可以视为全连接层, 输入通道为16*5*5，输出通道为120。\n",
    "        self.fc5 = nn.Linear(16*5*5, 120)\n",
    "        # 定义全连接层F6，输入维度为120，输出维度为84\n",
    "        self.fc6 = nn.Linear(120, 84)\n",
    "        # 定义输出层，输入维度为84，输出维度为10\n",
    "        self.fc7 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 通过C1后使用ReLU激活函数\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # 通过S2\n",
    "        x = self.max_pool2(x)\n",
    "        # 通过C3后使用ReLU激活函数\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # 通过S4\n",
    "        x = self.max_pool4(x)\n",
    "        # 展平特征图\n",
    "        # x.view(-1, 16*5*5) 这行代码的作用是将前面卷积层和池化层处理后的多维特征图展平为一维向量。这一步是必要的，因为全连接层（如 self.fc5）期望其输入是一维向量形式，而不是多维特征图。\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        # 通过C5后使用ReLU激活函数\n",
    "        x = F.relu(self.fc5(x))\n",
    "        # 通过F6后使用ReLU激活函数\n",
    "        x = F.relu(self.fc6(x))\n",
    "        # 输出层\n",
    "        x = self.fc7(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T20:01:02.500935600Z",
     "start_time": "2024-02-02T20:01:02.482769200Z"
    }
   },
   "id": "6a6f3fe5d831649",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 设置训练过程\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T19:59:40.767831300Z",
     "start_time": "2024-02-02T19:59:40.745904800Z"
    }
   },
   "id": "a472c15f304cc404",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 设置测试过程\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T19:59:43.501757800Z",
     "start_time": "2024-02-02T19:59:43.482818Z"
    }
   },
   "id": "8e6696d3e59ff078",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298209\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.390365\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.098400\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.115190\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.183708\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.141212\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.131079\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.166541\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.087854\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.120810\n",
      "\n",
      "Test set: Average loss: 0.0699, Accuracy: 9768/10000 (98%)\n"
     ]
    }
   ],
   "source": [
    "# 设置设备并实例化模型，定义损失函数和优化器，开始训练和测试\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet5().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(1, 2): # 这里只训练了一个epoch\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T20:02:30.131732300Z",
     "start_time": "2024-02-02T20:02:16.682671Z"
    }
   },
   "id": "e0c403cca40005f",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e7354ee7c7604573"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
