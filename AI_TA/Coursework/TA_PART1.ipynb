{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text Analytics Coursework: PART 1--Tweet Emotion Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f81c9c24b8d0fcb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use HuggingFace's datasets library to access the Emotion dataset\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, TfidfModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from wordcloud import WordCloud\n",
    "import tqdm\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1: Tweet Emotion Classification\n",
    "# 1. Load the dataset\n",
    "Use the TweetEval dataset from HuggingFace's datasets library to load the Emotion dataset. The dataset has three splits: train, validation, and test. Load the train, validation, and test splits into separate variables.\n",
    "The labels in the dataset are: [0,1,2,3] which correspond to the emotions: [anger, joy, optimism, sadness]."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6252accd86db369a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cache_dir = \"./NLP_data_cache\"\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"emotion\",\n",
    "    split=\"train\",\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset)} instances loaded\")\n",
    "\n",
    "\n",
    "val_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"emotion\",\n",
    "    split=\"validation\",\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Development/validation dataset with {len(val_dataset)} instances loaded\")\n",
    "\n",
    "\n",
    "test_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"emotion\",\n",
    "    split=\"test\",\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset)} instances loaded\")\n",
    "\n",
    "# Access the input text and target labels like this...\n",
    "train_texts = train_dataset['text']\n",
    "train_labels = train_dataset['label']\n",
    "\n",
    "val_texts = val_dataset['text']\n",
    "val_labels = val_dataset['label']\n",
    "\n",
    "test_texts = test_dataset['text']\n",
    "test_labels = test_dataset['label']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a2e07d5fa647a0e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_texts[13], train_labels[13]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b6b08563b6f098",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Non-Neural Classifier\n",
    "## 2.1. Preprocessing\n",
    "### 2.1.1. Text Cleaning\n",
    "\n",
    "The text cleaning step includes removing URLs, @mentions and #hashtags, converting to lowercase, removing punctuation. Lexical annotation and word form reduction by the result of lexical annotation. These steps help to reduce the noise and diversity of text data and improve the performance of text analysis."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c35458438f1c250"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 确保已下载nltk的wordnet和stopwords数据包\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english')) # 加载停用词\n",
    "\n",
    "# 映射nltk的词性标签到wordnet的词性标签。用于词形还原\n",
    "def nltk_pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE) # 移除URLs\n",
    "    text = re.sub(r'\\@\\w+|\\#','', text) # 移除@mentions和hashtags\n",
    "    text = text.lower() # 转换为小写\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)) # 移除标点符号\n",
    "    \n",
    "    tokens = word_tokenize(text) # 分词\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words and len(word) > 2] # 删除停用词和短词(长度小于等于2)\n",
    "\n",
    "    nltk_tagged = nltk.pos_tag(filtered_tokens)   # 词性标注\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_pos_tagger(x[1])), nltk_tagged) # 转换词性标注\n",
    "    \n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "\n",
    "# 应用词形还原到你的文本数据\n",
    "train_texts_lemmatized = [lemmatize_text(text) for text in train_texts]\n",
    "val_texts_lemmatized = [lemmatize_text(text) for text in val_texts]\n",
    "test_texts_lemmatized = [lemmatize_text(text) for text in test_texts]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c949cf8e7d335f29",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_texts_lemmatized[0:3]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca0de61066bfb547",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2. Vectorization\n",
    "Use the TF-IDF vectorizer to convert the text data into numerical form."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "903b32a374981d9a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TF-IDF向量化\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "\n",
    "# 将训练和验证数据集合并进行向量化，这样可以提高模型的泛化能力\n",
    "X_all_lemmatized = train_texts_lemmatized + val_texts_lemmatized\n",
    "y_all = train_labels + val_labels\n",
    "\n",
    "# 向量化处理\n",
    "x_train_tfidf = tfidf_vectorizer.fit_transform(X_all_lemmatized)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_texts_lemmatized)\n",
    "\n",
    "y_train = y_all\n",
    "\n",
    "# 分割数据集，这里重新分割是因为我们合并了训练集和验证集进行统一的向量化\n",
    "# x_train_tfidf, x_val_tfidf, y_train, y_val = train_test_split(\n",
    "#     X_all_tfidf, y_all, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "857654fdcd34ab16",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2. Classification Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1177f1a72a234a3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10,100],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(class_weight='balanced'), param_grid, cv=5, n_jobs=-1,verbose=True,scoring='f1_weighted')\n",
    "grid_search.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "print(\"Best estimator: \", grid_search.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ee718ffb715490e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 训练SVM模型\n",
    "# C是正则化参数，C越大，正则化越弱，则模型越容易过拟合；gamma是rbf核函数的系数，gamma越大，模型越容易过拟合\n",
    "svm_model = SVC(random_state=42, kernel='rbf', C=1, gamma=1,class_weight='balanced')\n",
    "svm_model.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# 预测验证集\n",
    "y_train_pred = svm_model.predict(x_train_tfidf)\n",
    "# y_val_pred = svm_model.predict(x_val_tfidf)\n",
    "y_test_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Train Accuracy: \", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "# # 性能评估\n",
    "# print(\"Validation Accuracy: \", accuracy_score(y_val, y_val_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# 测试集性能评估\n",
    "print(\"Test Accuracy: \", accuracy_score(test_labels, y_test_pred))\n",
    "print(\"Test Classification Report:\\n\", classification_report(test_labels, y_test_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b045535a2733497",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(svm_model, x_train_tfidf, y_all, cv=5, scoring='f1_weighted',n_jobs=-1)\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Mean CV F1-score: \", scores.mean())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bf99963208c5a34",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Improving the Model\n",
    "Add Lexicon Features, using NLTK's VADER sentiment analysis tool to extract sentiment scores from the text data. Add these sentiment scores as additional features to the TF-IDF vectorized features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c036b60517662b82"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# 实例化情感分析器\n",
    "analyser = SentimentIntensityAnalyzer()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91105e8ed4698f48",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# 初始化VADER情感分析器\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "X_all_lemmatized = train_texts_lemmatized + val_texts_lemmatized\n",
    "y_all = train_labels + val_labels\n",
    "\n",
    "# 计算情感分数 # compound是综合得分\n",
    "x_all_sentiments = [sia.polarity_scores(text)['compound'] for text in X_all_lemmatized]\n",
    "x_test_sentiments = [sia.polarity_scores(text)['compound'] for text in test_texts_lemmatized]\n",
    "\n",
    "x_all_sentiments = np.array(x_all_sentiments).reshape(-1, 1)\n",
    "x_test_sentiments = np.array(x_test_sentiments).reshape(-1, 1)\n",
    "\n",
    "# 合并情感分数和TF-IDF特征\n",
    "# 向量化处理\n",
    "X_all_tfidf = tfidf_vectorizer.fit_transform(X_all_lemmatized)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_texts_lemmatized)\n",
    "\n",
    "X_all = hstack([X_all_tfidf, x_all_sentiments])\n",
    "X_test = hstack([X_test_tfidf, x_test_sentiments])\n",
    "\n",
    "x_train_augmented = X_all\n",
    "y_train = y_all\n",
    "\n",
    "# 分割数据集\n",
    "# x_train_augmented, x_val_augmented, y_train, y_val = train_test_split(\n",
    "#     X_all, y_all, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8adee85aab060caf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 训练SVM模型\n",
    "svm_model_vader = SVC(random_state=42, kernel='linear', C=1, gamma=0.1,class_weight='balanced')\n",
    "svm_model_vader.fit(x_train_augmented, y_train)\n",
    "\n",
    "# 预测验证集\n",
    "y_train_pred = svm_model_vader.predict(x_train_augmented)\n",
    "# y_val_pred = svm_model_vader.predict(x_val_augmented)\n",
    "y_test_pred = svm_model_vader.predict(X_test)\n",
    "\n",
    "print(\"Train Accuracy: \", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "# # 性能评估\n",
    "# print(\"Validation Accuracy: \", accuracy_score(y_val, y_val_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# 测试集性能评估\n",
    "print(\"Test Accuracy: \", accuracy_score(test_labels, y_test_pred))\n",
    "print(\"Test Classification Report:\\n\", classification_report(test_labels, y_test_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e07ed242dfca142c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 查看分类错误的样本\n",
    "test_df = test_dataset.to_pandas()\n",
    "test_df['pred'] = y_test_pred\n",
    "test_df['gold_label'] = test_labels\n",
    "mistakes = test_df[test_df['pred'] != test_df['gold_label']]\n",
    "mistakes\n",
    "# mistakes.to_csv('./NLP_data_cache/mistakes.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "920502ae44c4dac0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_texts[12], test_labels[12]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5118a2a9b112dc56",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Insights\n",
    "\n",
    "Comparing the performance before and after adding the sentiment score feature, it is found that the performance of the classifier has improved. This indicates that the sentiment score feature is useful for the sentiment classification task.\n",
    "\n",
    "This is shown by the significant improvement in Recall for category 1 (Joy) and Precision for category 2 (Optimise). This indicates that the model is better able to recognize these two categories. This may be due to the fact that the sentiment score provides a way to directly quantify the sentiment tendency of the text, helping the model to capture some of the sentiment features that are difficult to express explicitly through the text content alone. This result suggests that for text categorization tasks, combining content analysis and quantitative analysis of sentiment tendencies can effectively improve the prediction accuracy and generalization ability of the model.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dead10f21f220a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Deep Learning Classifier\n",
    "## 3.1. Preprocessing\n",
    "### 3.1.1. Length of Texts\n",
    "We found that the maximum length of the text data is 36. As the hist plot can show the distribution of the length of the text data, we can see that most of the text data is less than 25 words. Therefore, we can set the maximum length of the text data to 25."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33b712192277da6c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 查看样本长度的分布\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_texts_len = [len(text.split()) for text in train_texts]\n",
    "val_texts_len = [len(text.split()) for text in val_texts]\n",
    "test_texts_len = [len(text.split()) for text in test_texts]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(train_texts_len, bins=30, alpha=0.5, label='train')\n",
    "plt.hist(val_texts_len, bins=30, alpha=0.5, label='val')\n",
    "plt.hist(test_texts_len, bins=30, alpha=0.5, label='test')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Text Length Distribution')\n",
    "plt.show()\n",
    "\n",
    "# 找出最长长度\n",
    "max_len = max(max(train_texts_len), max(val_texts_len), max(test_texts_len))\n",
    "max_len"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebb004858fd6dfaa",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.2. Tokenization, Encoding, Padding&Truncating and Tensorization\n",
    "Use BERT tokenizer to tokenize the text data. Then convert the tokenized text data into vocabulary index. Finally, pad and tensorize the text data and generate the DataLoader."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "633cee5533952ae7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, DistilBertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "## 注意：使用不同模型要使用对应的tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# encode_texts函数用于对文本进行编码,即将文本转换为模型可以理解的数字表示\n",
    "def encode_texts(texts):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        add_special_tokens=True,  # 添加特殊标记，例如[CLS]和[SEP]\n",
    "        max_length=40,  # 设定最大序列长度\n",
    "        padding='max_length',  # 进行填充以达到相同长度\n",
    "        truncation=True,  # 截断超过最大长度的部分\n",
    "        return_attention_mask=True,  # 返回attention_mask（区分填充和非填充部分）\n",
    "        return_token_type_ids=False,  # 不返回token_type_ids(用于区分两个句子，如问答，本模型不需要)\n",
    "        return_tensors='pt'  # 返回PyTorch张量\n",
    "    )\n",
    "\n",
    "# 对训练、验证和测试数据进行编码\n",
    "encoded_train = encode_texts(train_texts)\n",
    "encoded_val = encode_texts(val_texts)\n",
    "encoded_test = encode_texts(test_texts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbd3d27ae9653dac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}  # 确保不修改原始数据\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 创建Dataset\n",
    "train_dataset = TextDataset(encoded_train, train_labels)\n",
    "val_dataset = TextDataset(encoded_val, val_labels)\n",
    "test_dataset = TextDataset(encoded_test, test_labels)\n",
    "\n",
    "# 创建DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7b20cde4beb4484",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2. Training the Model\n",
    "Download the pre-trained BERT model and fine-tune it on the emotion classification task."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b53adb1f4012f78d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 使用Focal Loss作为损失函数\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=3.0, alpha=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma \n",
    "        self.alpha = alpha \n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        inputs: logits\n",
    "        targets: 真实标签\n",
    "        \"\"\"\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # 计算概率\n",
    "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            at = self.alpha[targets]\n",
    "            F_loss = at * F_loss\n",
    "        \n",
    "        return F_loss.mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73ce7d36290fea8c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, optimizer, scheduler, device, epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_f1score = []  \n",
    "    val_f1score = []\n",
    "    \n",
    "    # 如果需要使用带权重的交叉熵损失函数：\n",
    "    # 类别的样本数量(训练集）\n",
    "    class_counts = torch.tensor([1400, 708, 294, 855])\n",
    "    # 计算每个类别的权重（以最小类别样本数的倒数作为基础）\n",
    "    weights = class_counts.min().float() / class_counts.float()\n",
    "    weights = weights.to(device)\n",
    "    custom_loss_function = CrossEntropyLoss(weight=weights) # 使用带权重的交叉熵损失\n",
    "    # custom_loss_function = FocalLoss(alpha=weights, gamma=3.0) # 使用Focal Loss\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        all_train_preds = []  \n",
    "        all_train_labels = []\n",
    "        # 打印当前学习率\n",
    "        print('Learning rate: ', optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()} \n",
    "            # 这行代码遍历从DataLoader迭代器返回的每个批次数据中的所有键值对。这里的batch是一个字典，它的键（k）是字符串，比如'input_ids'、'attention_mask'和'labels'，值（v）是对应的数据张量。{k: v.to(device) for k, v in batch.items()}这部分代码的作用是：\n",
    "            # 对于字典中的每个键值对，将值（即张量）移动到指定的device（例如，GPU或CPU）。\n",
    "            \n",
    "            #使用BERT内置损失函数进行反向传播\n",
    "            outputs = model(**batch)  # **batch将字典解包为关键字参数,等价于model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])   \n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            \n",
    "            # # # 使用自定义损失函数进行反向传播\n",
    "            # outputs = model(**batch)\n",
    "            # logits = outputs.logits  # 获取模型的logits\n",
    "            # # 计算自定义损失\n",
    "            # loss = custom_loss_function(logits, batch['labels'].to(device))\n",
    "            # # 使用自定义损失进行反向传播\n",
    "            # loss.backward()\n",
    "            \n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # 梯度裁剪（防止梯度爆炸）\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step() # 更新学习率\n",
    "            model.zero_grad() \n",
    "            \n",
    "            # 打印当前学习率\n",
    "            # print('Learning rate: ', optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "            # train_preds = torch.argmax(logits, dim=1).flatten() # 使用bert损失函数时，需要注释掉这行代码\n",
    "            train_preds = torch.argmax(outputs.logits, dim=1).flatten()\n",
    "            \n",
    "            all_train_preds.extend(train_preds.cpu().numpy())\n",
    "            all_train_labels.extend(batch['labels'].cpu().numpy())\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        train_f1 = f1_score(all_train_labels, all_train_preds, average='macro')\n",
    "        train_f1score.append(train_f1)\n",
    "        \n",
    "        # 验证过程\n",
    "        model.eval()\n",
    "        total_val_loss = 0 # 每个epoch都会重新计算验证集的损失\n",
    "        val_accuracy = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # for batch in tqdm(val_dataloader, desc=\"Validating\"):\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}  \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch) \n",
    "                \n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).flatten()\n",
    "            labels = batch['labels']  # 获取标签进行准确度计算\n",
    "            # 将当前批次的预测和标签追加到列表中\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            val_accuracy.append(accuracy_score(labels.cpu().numpy(), preds.cpu().numpy()))\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # 计算f1-score\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        val_f1score.append(val_f1)\n",
    "        \n",
    "        # 使用验证集的Macro F1来更新学习率\n",
    "        # scheduler.step(val_f1)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss} | Val Loss: {avg_val_loss} | Val Accuracy: {np.mean(val_accuracy)}')\n",
    "        print(classification_report(all_labels, all_preds))\n",
    "        \n",
    "        # 保存最终模型\n",
    "        # if epoch == epochs - 1:\n",
    "        # torch.save(model.state_dict(), './NLP_data_cache/bert_model.pth')\n",
    "        \n",
    "    return train_losses, val_losses, train_f1score, val_f1score,model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ead208038845bd0a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def test(model, test_dataloader, device):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    test_accuracy = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    error_records = []  # 用于存储错误分类的记录\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for batch in test_dataloader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}  # 保持labels之外的数据移至设备\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "            outputs = model(**inputs)  # 进行预测\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()  # 获取预测结果\n",
    "            \n",
    "            test_accuracy.append(accuracy_score(labels, preds))\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "            \n",
    "            # 检查每个预测，并记录错误分类的实例\n",
    "            input_ids = inputs['input_ids'].cpu().numpy()\n",
    "            for input_id, pred, label in zip(input_ids, preds, labels):\n",
    "                if pred != label:\n",
    "                    decoded_sentence = tokenizer.decode(input_id, skip_special_tokens=True)\n",
    "                    error_records.append([decoded_sentence, pred, label])\n",
    "\n",
    "    avg_accuracy = np.mean(test_accuracy)\n",
    "    print(f\"Test Accuracy: {avg_accuracy}\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    # 将错误记录保存到CSV文件\n",
    "    df_errors = pd.DataFrame(error_records, columns=['Text', 'Predicted Label', 'True Label'])\n",
    "    df_errors.to_csv('model_errors.csv', index=False)\n",
    "\n",
    "    print(f\"Saved {len(error_records)} error records to model_errors.csv\")\n",
    "\n",
    "    return all_preds, all_labels, avg_accuracy, error_records"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "881e9aecc538aa47",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-06\n",
      "Epoch 1/100 | Train Loss: 1.3762292978810329 | Val Loss: 1.3522655268510182 | Val Accuracy: 0.4296875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60       160\n",
      "           1       0.00      0.00      0.00        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.43       374\n",
      "   macro avg       0.11      0.25      0.15       374\n",
      "weighted avg       0.18      0.43      0.26       374\n",
      "\n",
      "Learning rate:  4.2178276747990053e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | Train Loss: 1.3327336229530036 | Val Loss: 1.3103701968987782 | Val Accuracy: 0.4296875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60       160\n",
      "           1       0.00      0.00      0.00        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.43       374\n",
      "   macro avg       0.11      0.25      0.15       374\n",
      "weighted avg       0.18      0.43      0.26       374\n",
      "\n",
      "Learning rate:  2.4471741852422842e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | Train Loss: 1.288319207873999 | Val Loss: 1.267398864030838 | Val Accuracy: 0.4296875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60       160\n",
      "           1       0.00      0.00      0.00        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.43       374\n",
      "   macro avg       0.11      0.25      0.15       374\n",
      "weighted avg       0.18      0.43      0.26       374\n",
      "\n",
      "Learning rate:  7.269952498697736e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | Train Loss: 1.2515550758324416 | Val Loss: 1.227423717578252 | Val Accuracy: 0.4296875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60       160\n",
      "           1       0.00      0.00      0.00        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.43       374\n",
      "   macro avg       0.11      0.25      0.15       374\n",
      "weighted avg       0.18      0.43      0.26       374\n",
      "\n",
      "Learning rate:  9.045084971875716e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Train Loss: 1.2253376245498657 | Val Loss: 1.203137030204137 | Val Accuracy: 0.4322916666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60       160\n",
      "           1       0.00      0.00      0.00        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       1.00      0.01      0.02        89\n",
      "\n",
      "    accuracy                           0.43       374\n",
      "   macro avg       0.36      0.25      0.16       374\n",
      "weighted avg       0.42      0.43      0.26       374\n",
      "\n",
      "Learning rate:  1.4644660940673246e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 | Train Loss: 1.2006813907155804 | Val Loss: 1.1786839067935944 | Val Accuracy: 0.4348958333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.99      0.60       160\n",
      "           1       0.00      0.00      0.00        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.60      0.03      0.06        89\n",
      "\n",
      "    accuracy                           0.43       374\n",
      "   macro avg       0.26      0.26      0.17       374\n",
      "weighted avg       0.33      0.43      0.27       374\n",
      "\n",
      "Learning rate:  2.0610737385377081e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 | Train Loss: 1.1706491422419454 | Val Loss: 1.1461372872193654 | Val Accuracy: 0.47277462121212116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.98      0.63       160\n",
      "           1       1.00      0.03      0.06        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.52      0.19      0.28        89\n",
      "\n",
      "    accuracy                           0.47       374\n",
      "   macro avg       0.49      0.30      0.24       374\n",
      "weighted avg       0.58      0.47      0.35       374\n",
      "\n",
      "Learning rate:  9.455032620942173e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 | Train Loss: 1.139038417853561 | Val Loss: 1.1012381811936696 | Val Accuracy: 0.5506628787878788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.69       160\n",
      "           1       0.96      0.26      0.41        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.43      0.28      0.34        89\n",
      "\n",
      "    accuracy                           0.55       374\n",
      "   macro avg       0.48      0.38      0.36       374\n",
      "weighted avg       0.58      0.55      0.48       374\n",
      "\n",
      "Learning rate:  6.545084971875023e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 | Train Loss: 1.097483804997276 | Val Loss: 1.063983182112376 | Val Accuracy: 0.579308712121212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       160\n",
      "           1       0.94      0.35      0.51        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.42      0.31      0.36        89\n",
      "\n",
      "    accuracy                           0.58       374\n",
      "   macro avg       0.48      0.41      0.40       374\n",
      "weighted avg       0.59      0.58      0.53       374\n",
      "\n",
      "Learning rate:  6.155829702431616e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 | Train Loss: 1.058019503658893 | Val Loss: 1.0286634018023808 | Val Accuracy: 0.6209753787878788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.96      0.75       160\n",
      "           1       0.85      0.47      0.61        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.49      0.38      0.43        89\n",
      "\n",
      "    accuracy                           0.62       374\n",
      "   macro avg       0.49      0.45      0.45       374\n",
      "weighted avg       0.60      0.62      0.58       374\n",
      "\n",
      "Learning rate:  5.000000000000335e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 | Train Loss: 1.0208650015148462 | Val Loss: 0.9864489138126373 | Val Accuracy: 0.6664299242424242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.96      0.79       160\n",
      "           1       0.80      0.57      0.66        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.55      0.47      0.51        89\n",
      "\n",
      "    accuracy                           0.67       374\n",
      "   macro avg       0.50      0.50      0.49       374\n",
      "weighted avg       0.62      0.67      0.63       374\n",
      "\n",
      "Learning rate:  9.938441702974615e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train Loss: 0.981016968979555 | Val Loss: 0.9471043646335602 | Val Accuracy: 0.7014678030303031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82       160\n",
      "           1       0.77      0.66      0.71        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.58      0.55      0.57        89\n",
      "\n",
      "    accuracy                           0.70       374\n",
      "   macro avg       0.52      0.54      0.52       374\n",
      "weighted avg       0.65      0.70      0.67       374\n",
      "\n",
      "Learning rate:  3.454915028125515e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 | Train Loss: 0.946818016907748 | Val Loss: 0.9218060423930486 | Val Accuracy: 0.7118844696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.94      0.82       160\n",
      "           1       0.78      0.67      0.72        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.61      0.57      0.59        89\n",
      "\n",
      "    accuracy                           0.71       374\n",
      "   macro avg       0.53      0.55      0.53       374\n",
      "weighted avg       0.66      0.71      0.68       374\n",
      "\n",
      "Learning rate:  5.449673790582083e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 | Train Loss: 0.9190933949807111 | Val Loss: 0.8950554629166921 | Val Accuracy: 0.7182765151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83       160\n",
      "           1       0.78      0.67      0.72        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.60      0.61      0.60        89\n",
      "\n",
      "    accuracy                           0.72       374\n",
      "   macro avg       0.53      0.55      0.54       374\n",
      "weighted avg       0.67      0.72      0.69       374\n",
      "\n",
      "Learning rate:  7.938926261464614e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 | Train Loss: 0.8872249962068072 | Val Loss: 0.8645081917444865 | Val Accuracy: 0.7182765151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.82       160\n",
      "           1       0.77      0.68      0.72        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.62      0.63      0.62        89\n",
      "\n",
      "    accuracy                           0.72       374\n",
      "   macro avg       0.53      0.56      0.54       374\n",
      "weighted avg       0.66      0.72      0.69       374\n",
      "\n",
      "Learning rate:  8.535533905933706e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 | Train Loss: 0.8577562780941234 | Val Loss: 0.8378563970327377 | Val Accuracy: 0.7298768939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       160\n",
      "           1       0.74      0.72      0.73        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.65      0.63      0.64        89\n",
      "\n",
      "    accuracy                           0.73       374\n",
      "   macro avg       0.54      0.57      0.55       374\n",
      "weighted avg       0.67      0.73      0.70       374\n",
      "\n",
      "Learning rate:  9.54915028125249e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train Loss: 0.8333176093942979 | Val Loss: 0.8211604456106821 | Val Accuracy: 0.7298768939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       160\n",
      "           1       0.74      0.72      0.73        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.66      0.63      0.64        89\n",
      "\n",
      "    accuracy                           0.73       374\n",
      "   macro avg       0.54      0.57      0.55       374\n",
      "weighted avg       0.67      0.73      0.70       374\n",
      "\n",
      "Learning rate:  2.73004750130317e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train Loss: 0.8092747389101514 | Val Loss: 0.8039637158314387 | Val Accuracy: 0.7220643939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       160\n",
      "           1       0.74      0.69      0.72        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.63      0.63      0.63        89\n",
      "\n",
      "    accuracy                           0.72       374\n",
      "   macro avg       0.53      0.56      0.54       374\n",
      "weighted avg       0.67      0.72      0.69       374\n",
      "\n",
      "Learning rate:  9.755282581477175e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 | Train Loss: 0.7880389894924912 | Val Loss: 0.7830263326565424 | Val Accuracy: 0.7336647727272728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83       160\n",
      "           1       0.76      0.73      0.74        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.62      0.66      0.64        89\n",
      "\n",
      "    accuracy                           0.73       374\n",
      "   macro avg       0.54      0.57      0.55       374\n",
      "weighted avg       0.68      0.73      0.70       374\n",
      "\n",
      "Learning rate:  5.78217232520097e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train Loss: 0.7637729352595759 | Val Loss: 0.7701236754655838 | Val Accuracy: 0.7310606060606061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       160\n",
      "           1       0.76      0.71      0.73        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.63      0.64      0.63        89\n",
      "\n",
      "    accuracy                           0.73       374\n",
      "   macro avg       0.54      0.57      0.55       374\n",
      "weighted avg       0.67      0.73      0.70       374\n",
      "\n",
      "Learning rate:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 | Train Loss: 0.744415657193053 | Val Loss: 0.7565276523431143 | Val Accuracy: 0.7362689393939394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       160\n",
      "           1       0.74      0.73      0.74        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.64      0.69      0.66        89\n",
      "\n",
      "    accuracy                           0.74       374\n",
      "   macro avg       0.54      0.58      0.56       374\n",
      "weighted avg       0.68      0.74      0.71       374\n",
      "\n",
      "Learning rate:  5.782172325201916e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 | Train Loss: 0.7260236307686451 | Val Loss: 0.7420068631569544 | Val Accuracy: 0.7414772727272728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       160\n",
      "           1       0.75      0.74      0.75        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.67      0.65      0.66        89\n",
      "\n",
      "    accuracy                           0.74       374\n",
      "   macro avg       0.55      0.58      0.56       374\n",
      "weighted avg       0.68      0.74      0.71       374\n",
      "\n",
      "Learning rate:  9.755282581482778e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train Loss: 0.7106129518326592 | Val Loss: 0.7290402700503668 | Val Accuracy: 0.7376893939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       160\n",
      "           1       0.74      0.75      0.74        97\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.66      0.69      0.67        89\n",
      "\n",
      "    accuracy                           0.74       374\n",
      "   macro avg       0.54      0.58      0.56       374\n",
      "weighted avg       0.68      0.74      0.71       374\n",
      "\n",
      "Learning rate:  2.7300475013037224e-07\n",
      "Epoch 24/100 | Train Loss: 0.6899725245494469 | Val Loss: 0.7277507980664571 | Val Accuracy: 0.7324810606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       160\n",
      "           1       0.75      0.69      0.72        97\n",
      "           2       0.50      0.04      0.07        28\n",
      "           3       0.61      0.73      0.67        89\n",
      "\n",
      "    accuracy                           0.73       374\n",
      "   macro avg       0.67      0.58      0.57       374\n",
      "weighted avg       0.72      0.73      0.71       374\n",
      "\n",
      "Learning rate:  9.549150281254335e-08\n",
      "Epoch 25/100 | Train Loss: 0.6728357143846213 | Val Loss: 0.7141583561897278 | Val Accuracy: 0.7350852272727272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       160\n",
      "           1       0.74      0.71      0.73        97\n",
      "           2       0.50      0.04      0.07        28\n",
      "           3       0.64      0.71      0.67        89\n",
      "\n",
      "    accuracy                           0.74       374\n",
      "   macro avg       0.67      0.59      0.57       374\n",
      "weighted avg       0.72      0.74      0.71       374\n",
      "\n",
      "Learning rate:  8.535533905932716e-07\n",
      "Epoch 26/100 | Train Loss: 0.661466511441212 | Val Loss: 0.702043871084849 | Val Accuracy: 0.7402935606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       160\n",
      "           1       0.74      0.75      0.74        97\n",
      "           2       0.67      0.07      0.13        28\n",
      "           3       0.64      0.72      0.68        89\n",
      "\n",
      "    accuracy                           0.74       374\n",
      "   macro avg       0.71      0.60      0.60       374\n",
      "weighted avg       0.74      0.74      0.72       374\n",
      "\n",
      "Learning rate:  7.938926261466695e-07\n",
      "Epoch 27/100 | Train Loss: 0.6458604008543725 | Val Loss: 0.6992025127013525 | Val Accuracy: 0.7350852272727272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       160\n",
      "           1       0.73      0.71      0.72        97\n",
      "           2       0.67      0.07      0.13        28\n",
      "           3       0.62      0.72      0.67        89\n",
      "\n",
      "    accuracy                           0.74       374\n",
      "   macro avg       0.71      0.59      0.59       374\n",
      "weighted avg       0.73      0.74      0.71       374\n",
      "\n",
      "Learning rate:  5.449673790583456e-08\n",
      "Epoch 28/100 | Train Loss: 0.6311104288872551 | Val Loss: 0.6915767143170038 | Val Accuracy: 0.7455018939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       160\n",
      "           1       0.74      0.72      0.73        97\n",
      "           2       0.75      0.11      0.19        28\n",
      "           3       0.64      0.73      0.68        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.74      0.61      0.61       374\n",
      "weighted avg       0.75      0.75      0.73       374\n",
      "\n",
      "Learning rate:  3.454915028125293e-07\n",
      "Epoch 29/100 | Train Loss: 0.6227636804767683 | Val Loss: 0.6861772040526072 | Val Accuracy: 0.7455018939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       160\n",
      "           1       0.74      0.72      0.73        97\n",
      "           2       0.80      0.14      0.24        28\n",
      "           3       0.64      0.74      0.69        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.75      0.62      0.62       374\n",
      "weighted avg       0.75      0.75      0.73       374\n",
      "\n",
      "Learning rate:  9.938441702981417e-07\n",
      "Epoch 30/100 | Train Loss: 0.6112475035821691 | Val Loss: 0.6814889088273048 | Val Accuracy: 0.7481060606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       160\n",
      "           1       0.74      0.72      0.73        97\n",
      "           2       0.83      0.18      0.29        28\n",
      "           3       0.64      0.75      0.69        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.76      0.63      0.64       374\n",
      "weighted avg       0.76      0.75      0.74       374\n",
      "\n",
      "Learning rate:  5.000000000002125e-07\n",
      "Epoch 31/100 | Train Loss: 0.5937099439256331 | Val Loss: 0.6721350029110909 | Val Accuracy: 0.7481060606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       160\n",
      "           1       0.73      0.71      0.72        97\n",
      "           2       0.71      0.18      0.29        28\n",
      "           3       0.65      0.74      0.69        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.73      0.63      0.64       374\n",
      "weighted avg       0.75      0.75      0.74       374\n",
      "\n",
      "Learning rate:  6.155829702431169e-09\n",
      "Epoch 32/100 | Train Loss: 0.5860456140602336 | Val Loss: 0.6719702705740929 | Val Accuracy: 0.7481060606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       160\n",
      "           1       0.73      0.71      0.72        97\n",
      "           2       0.75      0.21      0.33        28\n",
      "           3       0.64      0.75      0.69        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.74      0.64      0.65       374\n",
      "weighted avg       0.75      0.75      0.74       374\n",
      "\n",
      "Learning rate:  6.545084971878562e-07\n",
      "Epoch 33/100 | Train Loss: 0.573601814753869 | Val Loss: 0.6667773624261221 | Val Accuracy: 0.7481060606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       160\n",
      "           1       0.73      0.71      0.72        97\n",
      "           2       0.75      0.21      0.33        28\n",
      "           3       0.64      0.75      0.69        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.74      0.64      0.65       374\n",
      "weighted avg       0.75      0.75      0.74       374\n",
      "\n",
      "Learning rate:  9.455032620939153e-07\n",
      "Epoch 34/100 | Train Loss: 0.5625760453004464 | Val Loss: 0.6610325326522192 | Val Accuracy: 0.7507102272727272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       160\n",
      "           1       0.73      0.71      0.72        97\n",
      "           2       0.70      0.25      0.37        28\n",
      "           3       0.65      0.75      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.73      0.64      0.66       374\n",
      "weighted avg       0.75      0.75      0.74       374\n",
      "\n",
      "Learning rate:  2.0610737385381182e-07\n",
      "Epoch 35/100 | Train Loss: 0.5530827615190955 | Val Loss: 0.6597455739974976 | Val Accuracy: 0.7701231060606061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       160\n",
      "           1       0.77      0.71      0.74        97\n",
      "           2       0.77      0.36      0.49        28\n",
      "           3       0.69      0.76      0.72        89\n",
      "\n",
      "    accuracy                           0.77       374\n",
      "   macro avg       0.76      0.68      0.70       374\n",
      "weighted avg       0.77      0.77      0.76       374\n",
      "\n",
      "Learning rate:  1.4644660940672193e-07\n",
      "Epoch 36/100 | Train Loss: 0.5397419914895413 | Val Loss: 0.6576205392678579 | Val Accuracy: 0.7649147727272728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       160\n",
      "           1       0.77      0.71      0.74        97\n",
      "           2       0.67      0.36      0.47        28\n",
      "           3       0.68      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.73      0.67      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.045084971878971e-07\n",
      "Epoch 37/100 | Train Loss: 0.530122442280545 | Val Loss: 0.6516582866509756 | Val Accuracy: 0.7623106060606061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       160\n",
      "           1       0.76      0.71      0.73        97\n",
      "           2       0.62      0.36      0.45        28\n",
      "           3       0.67      0.76      0.72        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.72      0.67      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  7.269952498705212e-07\n",
      "Epoch 38/100 | Train Loss: 0.5217089387131673 | Val Loss: 0.650434690217177 | Val Accuracy: 0.7623106060606061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       160\n",
      "           1       0.76      0.71      0.73        97\n",
      "           2       0.62      0.36      0.45        28\n",
      "           3       0.67      0.76      0.72        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.72      0.67      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  2.447174185242743e-08\n",
      "Epoch 39/100 | Train Loss: 0.5157642196498665 | Val Loss: 0.6502381886045138 | Val Accuracy: 0.7623106060606061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       160\n",
      "           1       0.77      0.71      0.74        97\n",
      "           2       0.62      0.36      0.45        28\n",
      "           3       0.67      0.76      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.72      0.67      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  4.21782767479757e-07\n",
      "Epoch 40/100 | Train Loss: 0.5077415278144911 | Val Loss: 0.6456737394134203 | Val Accuracy: 0.7611268939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       160\n",
      "           1       0.77      0.71      0.74        97\n",
      "           2       0.62      0.36      0.45        28\n",
      "           3       0.68      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.72      0.67      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  1.0000000000003246e-06\n",
      "Epoch 41/100 | Train Loss: 0.5001062613491919 | Val Loss: 0.6437795981764793 | Val Accuracy: 0.7585227272727272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       160\n",
      "           1       0.77      0.71      0.74        97\n",
      "           2       0.62      0.36      0.45        28\n",
      "           3       0.67      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.72      0.67      0.69       374\n",
      "weighted avg       0.76      0.76      0.75       374\n",
      "\n",
      "Learning rate:  4.2178276748027524e-07\n",
      "Epoch 42/100 | Train Loss: 0.49366285578877317 | Val Loss: 0.645825537542502 | Val Accuracy: 0.7623106060606061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.76      0.72      0.74        97\n",
      "           2       0.61      0.39      0.48        28\n",
      "           3       0.67      0.78      0.72        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.72      0.68      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  2.4471741852431074e-08\n",
      "Epoch 43/100 | Train Loss: 0.4790291469178948 | Val Loss: 0.6450774148106575 | Val Accuracy: 0.7585227272727272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       160\n",
      "           1       0.76      0.71      0.73        97\n",
      "           2       0.65      0.39      0.49        28\n",
      "           3       0.67      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.73      0.68      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  7.269952498694828e-07\n",
      "Epoch 44/100 | Train Loss: 0.4685669897818098 | Val Loss: 0.6403513352076212 | Val Accuracy: 0.7533143939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       160\n",
      "           1       0.76      0.72      0.74        97\n",
      "           2       0.58      0.39      0.47        28\n",
      "           3       0.66      0.75      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.71      0.68      0.69       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  9.045084971875987e-07\n",
      "Epoch 45/100 | Train Loss: 0.4664168454268399 | Val Loss: 0.6415651738643646 | Val Accuracy: 0.7597064393939394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.76      0.72      0.74        97\n",
      "           2       0.61      0.39      0.48        28\n",
      "           3       0.66      0.76      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.72      0.68      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  1.4644660940683715e-07\n",
      "Epoch 46/100 | Train Loss: 0.45919202881700855 | Val Loss: 0.6472855160633723 | Val Accuracy: 0.7663352272727272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       160\n",
      "           1       0.79      0.70      0.74        97\n",
      "           2       0.67      0.43      0.52        28\n",
      "           3       0.67      0.76      0.72        89\n",
      "\n",
      "    accuracy                           0.77       374\n",
      "   macro avg       0.74      0.69      0.71       374\n",
      "weighted avg       0.77      0.77      0.76       374\n",
      "\n",
      "Learning rate:  2.0610737385384125e-07\n",
      "Epoch 47/100 | Train Loss: 0.44824716916271284 | Val Loss: 0.6361664781967798 | Val Accuracy: 0.7559185606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       160\n",
      "           1       0.78      0.72      0.75        97\n",
      "           2       0.52      0.43      0.47        28\n",
      "           3       0.67      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.68      0.69       374\n",
      "weighted avg       0.76      0.76      0.75       374\n",
      "\n",
      "Learning rate:  9.455032620950298e-07\n",
      "Epoch 48/100 | Train Loss: 0.4418055945459534 | Val Loss: 0.6457031120856603 | Val Accuracy: 0.7599431818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       160\n",
      "           1       0.79      0.69      0.74        97\n",
      "           2       0.57      0.46      0.51        28\n",
      "           3       0.68      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.69      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  6.545084971874745e-07\n",
      "Epoch 49/100 | Train Loss: 0.4409725284751724 | Val Loss: 0.6399561191598574 | Val Accuracy: 0.7611268939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       160\n",
      "           1       0.78      0.72      0.75        97\n",
      "           2       0.55      0.43      0.48        28\n",
      "           3       0.68      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.69      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  6.155829702437103e-09\n",
      "Epoch 50/100 | Train Loss: 0.4312878180952633 | Val Loss: 0.6372587829828262 | Val Accuracy: 0.7533143939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       160\n",
      "           1       0.77      0.72      0.74        97\n",
      "           2       0.52      0.43      0.47        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.68      0.69       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  5.00000000000103e-07\n",
      "Epoch 51/100 | Train Loss: 0.423193345905519 | Val Loss: 0.6405188689629236 | Val Accuracy: 0.7585227272727272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       160\n",
      "           1       0.78      0.71      0.74        97\n",
      "           2       0.52      0.43      0.47        28\n",
      "           3       0.68      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.68      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.938441702968919e-07\n",
      "Epoch 52/100 | Train Loss: 0.4182479434153613 | Val Loss: 0.6490532880028089 | Val Accuracy: 0.7443181818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       160\n",
      "           1       0.77      0.69      0.73        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.65      0.75      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.68      0.68       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  3.4549150281248565e-07\n",
      "Epoch 53/100 | Train Loss: 0.40962638194654505 | Val Loss: 0.6383001059293747 | Val Accuracy: 0.7533143939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       160\n",
      "           1       0.77      0.72      0.74        97\n",
      "           2       0.50      0.43      0.46        28\n",
      "           3       0.68      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.68      0.69       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  5.449673790586994e-08\n",
      "Epoch 54/100 | Train Loss: 0.4071546655659582 | Val Loss: 0.6433160627881686 | Val Accuracy: 0.7559185606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       160\n",
      "           1       0.76      0.70      0.73        97\n",
      "           2       0.50      0.43      0.46        28\n",
      "           3       0.68      0.75      0.72        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.68      0.69       374\n",
      "weighted avg       0.76      0.76      0.75       374\n",
      "\n",
      "Learning rate:  7.938926261463051e-07\n",
      "Epoch 55/100 | Train Loss: 0.3963933179483694 | Val Loss: 0.6450263534983 | Val Accuracy: 0.7481060606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       160\n",
      "           1       0.76      0.70      0.73        97\n",
      "           2       0.46      0.43      0.44        28\n",
      "           3       0.67      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.68      0.68      0.68       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  8.535533905950491e-07\n",
      "Epoch 56/100 | Train Loss: 0.39190519630324605 | Val Loss: 0.639074370265007 | Val Accuracy: 0.7481060606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       160\n",
      "           1       0.76      0.71      0.73        97\n",
      "           2       0.44      0.43      0.44        28\n",
      "           3       0.69      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.68      0.68      0.68       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  9.549150281264774e-08\n",
      "Epoch 57/100 | Train Loss: 0.38421645088523043 | Val Loss: 0.6409959942102432 | Val Accuracy: 0.7507102272727272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       160\n",
      "           1       0.77      0.70      0.74        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.67      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  2.7300475013004285e-07\n",
      "Epoch 58/100 | Train Loss: 0.37846964962926566 | Val Loss: 0.6433013081550598 | Val Accuracy: 0.7495265151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.78      0.69      0.73        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  9.755282581489141e-07\n",
      "Epoch 59/100 | Train Loss: 0.3768762867240345 | Val Loss: 0.6399492820103964 | Val Accuracy: 0.7559185606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       160\n",
      "           1       0.78      0.72      0.75        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.69      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  5.78217232520426e-07\n",
      "Epoch 60/100 | Train Loss: 0.37029482307387335 | Val Loss: 0.6403822551170985 | Val Accuracy: 0.7559185606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       160\n",
      "           1       0.77      0.72      0.74        97\n",
      "           2       0.46      0.46      0.46        28\n",
      "           3       0.68      0.75      0.72        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  0.0\n",
      "Epoch 61/100 | Train Loss: 0.36648259604094074 | Val Loss: 0.651106171309948 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.79      0.69      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.70      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  5.782172325204734e-07\n",
      "Epoch 62/100 | Train Loss: 0.3550192161517985 | Val Loss: 0.6500782345732053 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.79      0.69      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.70      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  9.755282581487371e-07\n",
      "Epoch 63/100 | Train Loss: 0.3508036931355794 | Val Loss: 0.6509662196040154 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.78      0.70      0.74        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  2.7300475013033475e-07\n",
      "Epoch 64/100 | Train Loss: 0.3486064003378737 | Val Loss: 0.649093729754289 | Val Accuracy: 0.7495265151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.77      0.70      0.74        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.67      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  9.549150281250026e-08\n",
      "Epoch 65/100 | Train Loss: 0.34478546642497476 | Val Loss: 0.6498568331201872 | Val Accuracy: 0.7495265151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.77      0.70      0.74        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.67      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  8.53553390593685e-07\n",
      "Epoch 66/100 | Train Loss: 0.33484962480325325 | Val Loss: 0.6511189316709837 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.78      0.70      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.70      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  7.938926261470776e-07\n",
      "Epoch 67/100 | Train Loss: 0.3299301185590379 | Val Loss: 0.6505036527911822 | Val Accuracy: 0.7495265151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.77      0.70      0.74        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.67      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.75      0.75      0.75       374\n",
      "\n",
      "Learning rate:  5.44967379059057e-08\n",
      "Epoch 68/100 | Train Loss: 0.32835979438295554 | Val Loss: 0.6502047876516978 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.78      0.71      0.74        97\n",
      "           2       0.48      0.46      0.47        28\n",
      "           3       0.67      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.69      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  3.454915028124726e-07\n",
      "Epoch 69/100 | Train Loss: 0.31770850469668704 | Val Loss: 0.6620951145887375 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.79      0.70      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.65      0.74      0.69        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.70      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  9.938441702979297e-07\n",
      "Epoch 70/100 | Train Loss: 0.3144122258413072 | Val Loss: 0.6627237076560656 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.78      0.70      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.70      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  5.000000000004171e-07\n",
      "Epoch 71/100 | Train Loss: 0.31007909394946753 | Val Loss: 0.6620937536160151 | Val Accuracy: 0.7547348484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       160\n",
      "           1       0.78      0.70      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  6.155829702423629e-09\n",
      "Epoch 72/100 | Train Loss: 0.3051949137566136 | Val Loss: 0.6611464594801267 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.78      0.70      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.70      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  6.545084971872611e-07\n",
      "Epoch 73/100 | Train Loss: 0.2983349373235422 | Val Loss: 0.672404482960701 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       160\n",
      "           1       0.79      0.69      0.74        97\n",
      "           2       0.54      0.50      0.52        28\n",
      "           3       0.65      0.74      0.69        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.69      0.70       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  9.455032620943837e-07\n",
      "Epoch 74/100 | Train Loss: 0.29521461503178464 | Val Loss: 0.6758702620863914 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       160\n",
      "           1       0.80      0.70      0.75        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.76      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  2.0610737385394655e-07\n",
      "Epoch 75/100 | Train Loss: 0.292868463139908 | Val Loss: 0.6741216232379278 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.80      0.70      0.75        97\n",
      "           2       0.54      0.50      0.52        28\n",
      "           3       0.65      0.75      0.70        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  1.464466094065578e-07\n",
      "Epoch 76/100 | Train Loss: 0.28593648977431596 | Val Loss: 0.6762652595837911 | Val Accuracy: 0.7547348484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.80      0.70      0.75        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.75      0.70        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.045084971896508e-07\n",
      "Epoch 77/100 | Train Loss: 0.2846388545106439 | Val Loss: 0.6843510170777639 | Val Accuracy: 0.7651515151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       160\n",
      "           1       0.81      0.70      0.75        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.67      0.80      0.73        89\n",
      "\n",
      "    accuracy                           0.77       374\n",
      "   macro avg       0.71      0.71      0.71       374\n",
      "weighted avg       0.77      0.77      0.77       374\n",
      "\n",
      "Learning rate:  7.269952498698239e-07\n",
      "Epoch 78/100 | Train Loss: 0.27475954825971644 | Val Loss: 0.6662094270189604 | Val Accuracy: 0.7547348484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.77      0.71      0.74        97\n",
      "           2       0.52      0.54      0.53        28\n",
      "           3       0.68      0.73      0.70        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  2.4471741852451545e-08\n",
      "Epoch 79/100 | Train Loss: 0.2724364285229468 | Val Loss: 0.6766279662648836 | Val Accuracy: 0.7547348484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.79      0.70      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  4.217827674805675e-07\n",
      "Epoch 80/100 | Train Loss: 0.2630064884821574 | Val Loss: 0.6783401568730673 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.79      0.70      0.74        97\n",
      "           2       0.52      0.50      0.51        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.999999999993522e-07\n",
      "Epoch 81/100 | Train Loss: 0.26332981248988824 | Val Loss: 0.6773492321372032 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.78      0.71      0.75        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.68      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  4.2178276747984696e-07\n",
      "Epoch 82/100 | Train Loss: 0.25276621500504953 | Val Loss: 0.6888097996513048 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       160\n",
      "           1       0.80      0.67      0.73        97\n",
      "           2       0.48      0.50      0.49        28\n",
      "           3       0.66      0.75      0.70        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.69      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  2.4471741852431594e-08\n",
      "Epoch 83/100 | Train Loss: 0.25506365416096705 | Val Loss: 0.6851319993535677 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       160\n",
      "           1       0.80      0.69      0.74        97\n",
      "           2       0.52      0.50      0.51        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  7.269952498708627e-07\n",
      "Epoch 84/100 | Train Loss: 0.24928712990938448 | Val Loss: 0.6751270021001498 | Val Accuracy: 0.7547348484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.77      0.72      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.68      0.73      0.70        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.045084971867748e-07\n",
      "Epoch 85/100 | Train Loss: 0.2411394766805803 | Val Loss: 0.6818008770545324 | Val Accuracy: 0.7599431818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.78      0.71      0.75        97\n",
      "           2       0.52      0.50      0.51        28\n",
      "           3       0.68      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  1.4644660940712866e-07\n",
      "Epoch 86/100 | Train Loss: 0.2419474439732 | Val Loss: 0.6870398968458176 | Val Accuracy: 0.7625473484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       160\n",
      "           1       0.80      0.71      0.75        97\n",
      "           2       0.54      0.50      0.52        28\n",
      "           3       0.66      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.70      0.71       374\n",
      "weighted avg       0.77      0.76      0.76       374\n",
      "\n",
      "Learning rate:  2.0610737385393726e-07\n",
      "Epoch 87/100 | Train Loss: 0.24286203400469294 | Val Loss: 0.6865949183702469 | Val Accuracy: 0.7625473484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       160\n",
      "           1       0.79      0.72      0.75        97\n",
      "           2       0.54      0.50      0.52        28\n",
      "           3       0.67      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.70      0.71       374\n",
      "weighted avg       0.77      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.455032620927904e-07\n",
      "Epoch 88/100 | Train Loss: 0.23716752333383934 | Val Loss: 0.6980604057510694 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       160\n",
      "           1       0.79      0.68      0.73        97\n",
      "           2       0.47      0.50      0.48        28\n",
      "           3       0.67      0.76      0.71        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.69      0.70      0.69       374\n",
      "weighted avg       0.76      0.75      0.76       374\n",
      "\n",
      "Learning rate:  6.545084971887292e-07\n",
      "Epoch 89/100 | Train Loss: 0.23094568675493493 | Val Loss: 0.6915615399678549 | Val Accuracy: 0.7625473484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       160\n",
      "           1       0.79      0.72      0.75        97\n",
      "           2       0.54      0.50      0.52        28\n",
      "           3       0.68      0.75      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.70      0.71       374\n",
      "weighted avg       0.77      0.76      0.76       374\n",
      "\n",
      "Learning rate:  6.1558297024240074e-09\n",
      "Epoch 90/100 | Train Loss: 0.22109790657665215 | Val Loss: 0.6933925126989683 | Val Accuracy: 0.7599431818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       160\n",
      "           1       0.78      0.71      0.75        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.68      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  5.000000000003451e-07\n",
      "Epoch 91/100 | Train Loss: 0.22008283728478 | Val Loss: 0.6927846471468607 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       160\n",
      "           1       0.77      0.72      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.68      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.938441702988216e-07\n",
      "Epoch 92/100 | Train Loss: 0.21290739077855558 | Val Loss: 0.7002218638857206 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       160\n",
      "           1       0.78      0.71      0.75        97\n",
      "           2       0.52      0.50      0.51        28\n",
      "           3       0.67      0.73      0.70        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  3.454915028131403e-07\n",
      "Epoch 93/100 | Train Loss: 0.21201955132624684 | Val Loss: 0.7055978402495384 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       160\n",
      "           1       0.79      0.70      0.74        97\n",
      "           2       0.52      0.50      0.51        28\n",
      "           3       0.67      0.74      0.71        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  5.4496737905958614e-08\n",
      "Epoch 94/100 | Train Loss: 0.2086828277245456 | Val Loss: 0.7096550911664963 | Val Accuracy: 0.7521306818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       160\n",
      "           1       0.80      0.69      0.74        97\n",
      "           2       0.50      0.50      0.50        28\n",
      "           3       0.66      0.73      0.69        89\n",
      "\n",
      "    accuracy                           0.75       374\n",
      "   macro avg       0.70      0.69      0.69       374\n",
      "weighted avg       0.76      0.75      0.75       374\n",
      "\n",
      "Learning rate:  7.938926261466452e-07\n",
      "Epoch 95/100 | Train Loss: 0.20646451534155538 | Val Loss: 0.702083095908165 | Val Accuracy: 0.7599431818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       160\n",
      "           1       0.79      0.72      0.75        97\n",
      "           2       0.52      0.54      0.53        28\n",
      "           3       0.69      0.72      0.70        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.71      0.71       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  8.535533905942362e-07\n",
      "Epoch 96/100 | Train Loss: 0.1963750236466819 | Val Loss: 0.7173085535566012 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       160\n",
      "           1       0.81      0.69      0.74        97\n",
      "           2       0.52      0.50      0.51        28\n",
      "           3       0.65      0.74      0.69        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.549150281240983e-08\n",
      "Epoch 97/100 | Train Loss: 0.19863810879634877 | Val Loss: 0.7103949338197708 | Val Accuracy: 0.7625473484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       160\n",
      "           1       0.78      0.72      0.75        97\n",
      "           2       0.54      0.50      0.52        28\n",
      "           3       0.67      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.70      0.71       374\n",
      "weighted avg       0.77      0.76      0.76       374\n",
      "\n",
      "Learning rate:  2.730047501301464e-07\n",
      "Epoch 98/100 | Train Loss: 0.19224153210719427 | Val Loss: 0.7196899230281512 | Val Accuracy: 0.7625473484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       160\n",
      "           1       0.79      0.71      0.75        97\n",
      "           2       0.54      0.50      0.52        28\n",
      "           3       0.67      0.74      0.70        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.71      0.70      0.71       374\n",
      "weighted avg       0.77      0.76      0.76       374\n",
      "\n",
      "Learning rate:  9.75528258147953e-07\n",
      "Epoch 99/100 | Train Loss: 0.19518090521588044 | Val Loss: 0.7290214772025744 | Val Accuracy: 0.7729640151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       160\n",
      "           1       0.81      0.70      0.75        97\n",
      "           2       0.56      0.50      0.53        28\n",
      "           3       0.67      0.80      0.73        89\n",
      "\n",
      "    accuracy                           0.78       374\n",
      "   macro avg       0.73      0.71      0.72       374\n",
      "weighted avg       0.78      0.78      0.78       374\n",
      "\n",
      "Learning rate:  5.782172325206998e-07\n",
      "Epoch 100/100 | Train Loss: 0.18393179927678668 | Val Loss: 0.7326560740669569 | Val Accuracy: 0.7573390151515151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       160\n",
      "           1       0.81      0.70      0.75        97\n",
      "           2       0.52      0.50      0.51        28\n",
      "           3       0.65      0.72      0.68        89\n",
      "\n",
      "    accuracy                           0.76       374\n",
      "   macro avg       0.70      0.70      0.70       374\n",
      "weighted avg       0.76      0.76      0.76       374\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertForSequenceClassification, get_linear_schedule_with_warmup, \\\n",
    "    DistilBertForSequenceClassification, DistilBertConfig,BertConfig\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# BERT\n",
    "# 加载预训练的BERT模型，指定分类数为4（你的情况下是0, 1, 2, 3四种情感）\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
    "# # config = BertConfig.from_pretrained('bert-base-uncased', hidden_size=360)\n",
    "# # model = BertForSequenceClassification(config=config)\n",
    "# # 创建一个更小的BERT配置\n",
    "# config = BertConfig(\n",
    "#     # hidden_size=256*2,                # 减小隐藏层尺寸，原始值为768\n",
    "#     # num_hidden_layers=4*2,            # 减少隐藏层数，原始值为12\n",
    "#     # num_attention_heads=4*2,          # 减少注意力头数，原始值为12\n",
    "#     # intermediate_size=1024*2,         # 减小前馈网络的尺寸,原始值为4096\n",
    "#     hidden_dropout_prob=0.1,        # 可以调整dropout，原始值为0.1\n",
    "#     attention_probs_dropout_prob=0.1, # 可以调整attention dropout，原始值为0.1\n",
    "#     num_labels=4\n",
    "# )\n",
    "# model = BertForSequenceClassification(config=config)\n",
    "\n",
    "# Distil BERT\n",
    "# 创建一个自定义的DistilBERT配置\n",
    "# config = DistilBertConfig(\n",
    "#     # n_layers=6,  # 默认为6，这里减少到4层\n",
    "#     # dim=256*2,  # 默认为768，这里减小到256(hidden_size，所有层的隐藏状态的尺寸)\n",
    "#     # hidden_dim=1024*2,  # 注意力层后面的前馈层的尺寸，默认为3072(4倍于dim)\n",
    "#     # n_heads=8,  # 默认为12\n",
    "#     dropout=0.2,  # 增加dropout比率，原始默认为0.1\n",
    "#     attention_dropout=0.1,  # 增加注意力层的dropout，原始默认为0.1\n",
    "#     num_labels=4  # 设置输出标签数，针对分类任务\n",
    "# )\n",
    "# # 使用自定义配置初始化DistilBert模型\n",
    "# model = DistilBertForSequenceClassification(config=config)\n",
    "\n",
    "# # # 加载DistilBERT预训练模型，这里假设我们是做一个分类任务，类别数为4\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-6, weight_decay=0.001)\n",
    "epochs = 100\n",
    "total_steps = len(train_loader) * epochs\n",
    "\n",
    "# 使用线性学习率调度器\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=total_steps)\n",
    "\n",
    "# 使用余弦退火调整学习率\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=0.4*epochs) \n",
    "# scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=1, eta_min=0) # T_0是第一个周期的迭代次数，T_mult是周期之间的倍数，eta_min是学习率的最小值\n",
    "\n",
    "# 使用 验证集\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "# 开始训练、验证和绘制损失曲线\n",
    "train_losses, val_losses, train_f1score, val_f1score, model = train(model, train_loader, val_loader, optimizer, scheduler, device, epochs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T01:22:22.242481Z",
     "start_time": "2024-04-28T00:50:33.165711Z"
    }
   },
   "id": "cb203bd9b0a44883",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.807318376068376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       558\n",
      "           1       0.82      0.82      0.82       358\n",
      "           2       0.67      0.60      0.64       123\n",
      "           3       0.77      0.78      0.78       382\n",
      "\n",
      "    accuracy                           0.81      1421\n",
      "   macro avg       0.78      0.77      0.77      1421\n",
      "weighted avg       0.80      0.81      0.80      1421\n",
      "\n",
      "Saved 276 error records to model_errors.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "([3,\n  0,\n  3,\n  1,\n  1,\n  0,\n  3,\n  3,\n  1,\n  0,\n  0,\n  3,\n  2,\n  0,\n  0,\n  3,\n  1,\n  3,\n  0,\n  0,\n  0,\n  3,\n  3,\n  2,\n  2,\n  1,\n  3,\n  3,\n  3,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  2,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  1,\n  0,\n  0,\n  1,\n  1,\n  1,\n  1,\n  3,\n  1,\n  1,\n  2,\n  0,\n  3,\n  3,\n  2,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  2,\n  0,\n  3,\n  0,\n  0,\n  2,\n  0,\n  0,\n  0,\n  0,\n  3,\n  2,\n  2,\n  1,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  0,\n  1,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  1,\n  3,\n  1,\n  0,\n  1,\n  0,\n  2,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  3,\n  3,\n  0,\n  0,\n  2,\n  0,\n  3,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  2,\n  1,\n  0,\n  0,\n  1,\n  1,\n  1,\n  0,\n  3,\n  3,\n  3,\n  1,\n  3,\n  0,\n  0,\n  3,\n  1,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0,\n  3,\n  3,\n  2,\n  0,\n  0,\n  1,\n  3,\n  0,\n  3,\n  0,\n  0,\n  1,\n  1,\n  1,\n  0,\n  3,\n  0,\n  1,\n  3,\n  0,\n  1,\n  1,\n  2,\n  0,\n  2,\n  3,\n  1,\n  3,\n  1,\n  0,\n  0,\n  3,\n  3,\n  0,\n  3,\n  3,\n  3,\n  0,\n  0,\n  0,\n  2,\n  3,\n  0,\n  1,\n  1,\n  0,\n  0,\n  3,\n  2,\n  1,\n  0,\n  0,\n  1,\n  1,\n  0,\n  0,\n  3,\n  3,\n  1,\n  3,\n  2,\n  0,\n  1,\n  3,\n  0,\n  0,\n  3,\n  0,\n  2,\n  3,\n  3,\n  3,\n  3,\n  0,\n  2,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  1,\n  1,\n  0,\n  3,\n  0,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  1,\n  3,\n  0,\n  0,\n  3,\n  0,\n  1,\n  2,\n  3,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  2,\n  0,\n  1,\n  2,\n  0,\n  3,\n  0,\n  0,\n  3,\n  3,\n  1,\n  0,\n  1,\n  3,\n  3,\n  3,\n  0,\n  0,\n  2,\n  1,\n  0,\n  0,\n  3,\n  1,\n  3,\n  0,\n  0,\n  2,\n  3,\n  3,\n  3,\n  2,\n  1,\n  3,\n  3,\n  0,\n  1,\n  0,\n  0,\n  3,\n  3,\n  3,\n  0,\n  1,\n  3,\n  3,\n  0,\n  2,\n  0,\n  3,\n  0,\n  1,\n  3,\n  0,\n  3,\n  0,\n  3,\n  3,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  3,\n  2,\n  3,\n  0,\n  2,\n  3,\n  0,\n  3,\n  1,\n  3,\n  3,\n  1,\n  2,\n  1,\n  3,\n  0,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  3,\n  0,\n  2,\n  0,\n  0,\n  1,\n  0,\n  2,\n  3,\n  1,\n  0,\n  0,\n  3,\n  1,\n  3,\n  0,\n  0,\n  3,\n  0,\n  3,\n  3,\n  3,\n  3,\n  1,\n  0,\n  2,\n  0,\n  1,\n  0,\n  3,\n  1,\n  1,\n  3,\n  1,\n  1,\n  3,\n  0,\n  0,\n  0,\n  3,\n  2,\n  3,\n  0,\n  1,\n  0,\n  2,\n  3,\n  0,\n  3,\n  1,\n  1,\n  1,\n  3,\n  0,\n  0,\n  2,\n  1,\n  1,\n  0,\n  3,\n  0,\n  0,\n  3,\n  1,\n  3,\n  0,\n  3,\n  3,\n  3,\n  1,\n  2,\n  2,\n  3,\n  0,\n  0,\n  1,\n  1,\n  0,\n  3,\n  3,\n  0,\n  2,\n  3,\n  3,\n  3,\n  3,\n  1,\n  0,\n  0,\n  1,\n  3,\n  2,\n  0,\n  0,\n  3,\n  0,\n  0,\n  2,\n  1,\n  1,\n  3,\n  1,\n  0,\n  0,\n  1,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  3,\n  0,\n  0,\n  1,\n  1,\n  3,\n  3,\n  3,\n  0,\n  1,\n  1,\n  1,\n  1,\n  3,\n  3,\n  3,\n  2,\n  0,\n  1,\n  1,\n  0,\n  3,\n  3,\n  3,\n  3,\n  0,\n  2,\n  3,\n  0,\n  1,\n  0,\n  0,\n  3,\n  1,\n  1,\n  0,\n  0,\n  3,\n  1,\n  0,\n  0,\n  1,\n  0,\n  0,\n  1,\n  0,\n  3,\n  1,\n  0,\n  0,\n  0,\n  3,\n  3,\n  0,\n  3,\n  1,\n  3,\n  1,\n  3,\n  1,\n  0,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  1,\n  3,\n  3,\n  0,\n  1,\n  3,\n  2,\n  0,\n  0,\n  2,\n  0,\n  1,\n  2,\n  3,\n  1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  3,\n  3,\n  1,\n  1,\n  1,\n  1,\n  2,\n  0,\n  1,\n  3,\n  0,\n  0,\n  0,\n  1,\n  1,\n  1,\n  3,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  3,\n  1,\n  2,\n  0,\n  1,\n  0,\n  0,\n  1,\n  1,\n  1,\n  0,\n  0,\n  3,\n  0,\n  1,\n  3,\n  1,\n  1,\n  1,\n  1,\n  0,\n  1,\n  2,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  1,\n  1,\n  0,\n  3,\n  1,\n  0,\n  0,\n  3,\n  3,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  1,\n  0,\n  0,\n  3,\n  3,\n  1,\n  3,\n  0,\n  1,\n  3,\n  3,\n  1,\n  1,\n  3,\n  0,\n  0,\n  2,\n  3,\n  3,\n  1,\n  1,\n  0,\n  0,\n  3,\n  1,\n  0,\n  3,\n  2,\n  1,\n  0,\n  1,\n  0,\n  1,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  3,\n  1,\n  3,\n  1,\n  3,\n  1,\n  0,\n  1,\n  0,\n  2,\n  3,\n  0,\n  0,\n  3,\n  2,\n  2,\n  3,\n  1,\n  3,\n  0,\n  3,\n  3,\n  0,\n  3,\n  0,\n  0,\n  3,\n  1,\n  2,\n  3,\n  0,\n  1,\n  3,\n  0,\n  3,\n  1,\n  1,\n  0,\n  2,\n  0,\n  1,\n  3,\n  0,\n  3,\n  3,\n  1,\n  0,\n  1,\n  2,\n  3,\n  0,\n  0,\n  1,\n  0,\n  2,\n  0,\n  0,\n  0,\n  3,\n  0,\n  1,\n  0,\n  1,\n  0,\n  3,\n  1,\n  3,\n  1,\n  2,\n  1,\n  1,\n  1,\n  3,\n  0,\n  0,\n  0,\n  2,\n  1,\n  1,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  2,\n  1,\n  0,\n  0,\n  0,\n  0,\n  3,\n  3,\n  0,\n  1,\n  1,\n  1,\n  2,\n  2,\n  3,\n  3,\n  0,\n  3,\n  1,\n  1,\n  0,\n  0,\n  0,\n  1,\n  1,\n  1,\n  0,\n  0,\n  1,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  3,\n  0,\n  1,\n  0,\n  1,\n  3,\n  3,\n  0,\n  3,\n  3,\n  3,\n  1,\n  3,\n  2,\n  3,\n  1,\n  1,\n  0,\n  3,\n  0,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  2,\n  3,\n  0,\n  0,\n  0,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  0,\n  1,\n  0,\n  1,\n  3,\n  1,\n  0,\n  1,\n  0,\n  3,\n  1,\n  0,\n  3,\n  1,\n  0,\n  1,\n  3,\n  1,\n  0,\n  0,\n  0,\n  0,\n  1,\n  1,\n  0,\n  1,\n  0,\n  3,\n  0,\n  2,\n  0,\n  0,\n  0,\n  2,\n  0,\n  3,\n  0,\n  1,\n  3,\n  1,\n  3,\n  2,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  3,\n  0,\n  0,\n  3,\n  1,\n  1,\n  0,\n  0,\n  3,\n  3,\n  0,\n  3,\n  3,\n  3,\n  3,\n  0,\n  0,\n  0,\n  0,\n  3,\n  1,\n  0,\n  0,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  1,\n  2,\n  3,\n  0,\n  1,\n  0,\n  3,\n  3,\n  3,\n  3,\n  2,\n  1,\n  3,\n  0,\n  1,\n  3,\n  1,\n  3,\n  1,\n  0,\n  1,\n  3,\n  0,\n  2,\n  0,\n  2,\n  1,\n  2,\n  3,\n  0,\n  0,\n  0,\n  2,\n  0,\n  3,\n  3,\n  1,\n  2,\n  3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  3,\n  3,\n  3,\n  0,\n  1,\n  0,\n  3,\n  0,\n  2,\n  0,\n  3,\n  ...],\n [3,\n  0,\n  3,\n  1,\n  1,\n  0,\n  3,\n  3,\n  3,\n  0,\n  0,\n  3,\n  3,\n  0,\n  0,\n  3,\n  1,\n  0,\n  0,\n  0,\n  0,\n  3,\n  3,\n  2,\n  2,\n  1,\n  1,\n  0,\n  3,\n  1,\n  3,\n  1,\n  0,\n  0,\n  0,\n  0,\n  2,\n  2,\n  0,\n  3,\n  2,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  3,\n  3,\n  2,\n  3,\n  1,\n  0,\n  3,\n  3,\n  2,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  3,\n  2,\n  2,\n  1,\n  0,\n  0,\n  1,\n  3,\n  0,\n  0,\n  0,\n  1,\n  1,\n  3,\n  3,\n  1,\n  1,\n  0,\n  1,\n  1,\n  1,\n  3,\n  0,\n  0,\n  0,\n  1,\n  3,\n  1,\n  0,\n  1,\n  0,\n  2,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  3,\n  3,\n  1,\n  0,\n  2,\n  1,\n  0,\n  1,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  3,\n  1,\n  0,\n  0,\n  1,\n  1,\n  1,\n  2,\n  3,\n  3,\n  0,\n  3,\n  3,\n  0,\n  0,\n  3,\n  2,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0,\n  0,\n  3,\n  0,\n  1,\n  3,\n  1,\n  3,\n  0,\n  3,\n  0,\n  2,\n  1,\n  1,\n  1,\n  0,\n  3,\n  0,\n  1,\n  0,\n  0,\n  2,\n  1,\n  2,\n  0,\n  0,\n  0,\n  1,\n  1,\n  1,\n  0,\n  0,\n  3,\n  3,\n  0,\n  3,\n  3,\n  3,\n  3,\n  0,\n  0,\n  2,\n  3,\n  2,\n  1,\n  1,\n  0,\n  0,\n  3,\n  1,\n  0,\n  0,\n  0,\n  1,\n  1,\n  0,\n  0,\n  3,\n  3,\n  1,\n  3,\n  2,\n  1,\n  1,\n  3,\n  0,\n  0,\n  3,\n  0,\n  2,\n  3,\n  3,\n  3,\n  3,\n  0,\n  2,\n  3,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  1,\n  1,\n  0,\n  3,\n  0,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  1,\n  3,\n  0,\n  0,\n  3,\n  0,\n  1,\n  1,\n  3,\n  0,\n  3,\n  1,\n  0,\n  2,\n  0,\n  2,\n  0,\n  3,\n  1,\n  0,\n  3,\n  0,\n  0,\n  3,\n  3,\n  1,\n  0,\n  3,\n  3,\n  3,\n  3,\n  3,\n  0,\n  2,\n  3,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  3,\n  3,\n  1,\n  3,\n  2,\n  1,\n  3,\n  1,\n  0,\n  1,\n  0,\n  0,\n  3,\n  1,\n  3,\n  0,\n  1,\n  3,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  1,\n  3,\n  3,\n  3,\n  0,\n  3,\n  3,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  3,\n  2,\n  3,\n  0,\n  2,\n  2,\n  3,\n  3,\n  1,\n  3,\n  3,\n  1,\n  0,\n  1,\n  3,\n  0,\n  1,\n  1,\n  2,\n  0,\n  3,\n  0,\n  1,\n  3,\n  3,\n  0,\n  1,\n  0,\n  1,\n  0,\n  1,\n  1,\n  3,\n  0,\n  0,\n  0,\n  0,\n  2,\n  0,\n  0,\n  1,\n  0,\n  2,\n  3,\n  1,\n  0,\n  2,\n  3,\n  1,\n  3,\n  0,\n  2,\n  3,\n  0,\n  3,\n  1,\n  3,\n  3,\n  1,\n  0,\n  2,\n  0,\n  1,\n  1,\n  3,\n  1,\n  1,\n  3,\n  1,\n  1,\n  3,\n  0,\n  0,\n  0,\n  0,\n  2,\n  3,\n  0,\n  1,\n  0,\n  2,\n  3,\n  0,\n  1,\n  1,\n  1,\n  1,\n  3,\n  0,\n  0,\n  2,\n  1,\n  1,\n  0,\n  3,\n  1,\n  0,\n  3,\n  1,\n  3,\n  0,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  1,\n  0,\n  0,\n  1,\n  1,\n  0,\n  3,\n  3,\n  0,\n  2,\n  3,\n  1,\n  0,\n  3,\n  3,\n  3,\n  0,\n  3,\n  3,\n  2,\n  3,\n  0,\n  2,\n  3,\n  0,\n  0,\n  1,\n  1,\n  3,\n  1,\n  0,\n  0,\n  1,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  3,\n  0,\n  3,\n  0,\n  0,\n  1,\n  1,\n  3,\n  3,\n  3,\n  0,\n  1,\n  1,\n  1,\n  1,\n  3,\n  3,\n  3,\n  2,\n  0,\n  2,\n  1,\n  0,\n  3,\n  3,\n  3,\n  3,\n  0,\n  2,\n  3,\n  0,\n  1,\n  0,\n  0,\n  2,\n  1,\n  1,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  0,\n  1,\n  0,\n  3,\n  1,\n  0,\n  0,\n  0,\n  3,\n  1,\n  3,\n  3,\n  0,\n  0,\n  1,\n  3,\n  1,\n  0,\n  1,\n  1,\n  3,\n  0,\n  0,\n  0,\n  3,\n  0,\n  1,\n  3,\n  3,\n  0,\n  1,\n  1,\n  1,\n  3,\n  0,\n  2,\n  0,\n  1,\n  2,\n  3,\n  1,\n  2,\n  2,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  3,\n  3,\n  1,\n  1,\n  1,\n  0,\n  2,\n  0,\n  1,\n  3,\n  0,\n  1,\n  0,\n  1,\n  1,\n  1,\n  3,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  3,\n  0,\n  0,\n  1,\n  1,\n  1,\n  2,\n  2,\n  1,\n  0,\n  0,\n  2,\n  3,\n  1,\n  0,\n  3,\n  3,\n  0,\n  1,\n  3,\n  1,\n  2,\n  1,\n  1,\n  0,\n  1,\n  2,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  1,\n  1,\n  0,\n  3,\n  1,\n  0,\n  0,\n  0,\n  3,\n  1,\n  1,\n  3,\n  0,\n  0,\n  0,\n  3,\n  1,\n  0,\n  1,\n  0,\n  0,\n  3,\n  3,\n  1,\n  3,\n  0,\n  1,\n  3,\n  3,\n  1,\n  1,\n  3,\n  0,\n  0,\n  3,\n  2,\n  3,\n  1,\n  3,\n  0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  2,\n  1,\n  0,\n  1,\n  0,\n  1,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  3,\n  1,\n  3,\n  1,\n  0,\n  1,\n  0,\n  2,\n  3,\n  0,\n  0,\n  3,\n  2,\n  2,\n  3,\n  1,\n  0,\n  3,\n  3,\n  3,\n  0,\n  3,\n  3,\n  0,\n  3,\n  1,\n  1,\n  3,\n  0,\n  1,\n  3,\n  3,\n  3,\n  1,\n  1,\n  0,\n  2,\n  1,\n  0,\n  3,\n  0,\n  3,\n  3,\n  1,\n  0,\n  2,\n  1,\n  0,\n  0,\n  0,\n  1,\n  0,\n  2,\n  0,\n  0,\n  0,\n  3,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  1,\n  3,\n  1,\n  1,\n  1,\n  1,\n  1,\n  3,\n  0,\n  0,\n  0,\n  2,\n  0,\n  1,\n  3,\n  1,\n  3,\n  1,\n  0,\n  0,\n  2,\n  1,\n  1,\n  0,\n  0,\n  3,\n  3,\n  3,\n  3,\n  1,\n  1,\n  1,\n  2,\n  2,\n  0,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  1,\n  1,\n  2,\n  0,\n  1,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  1,\n  0,\n  3,\n  0,\n  3,\n  0,\n  0,\n  3,\n  0,\n  0,\n  3,\n  3,\n  2,\n  1,\n  3,\n  1,\n  0,\n  1,\n  1,\n  0,\n  0,\n  3,\n  1,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  2,\n  3,\n  0,\n  0,\n  0,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  0,\n  2,\n  3,\n  1,\n  3,\n  1,\n  0,\n  1,\n  0,\n  3,\n  1,\n  0,\n  0,\n  1,\n  0,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  1,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  2,\n  0,\n  3,\n  3,\n  0,\n  0,\n  2,\n  0,\n  1,\n  1,\n  1,\n  0,\n  2,\n  0,\n  3,\n  3,\n  0,\n  3,\n  0,\n  0,\n  1,\n  3,\n  3,\n  0,\n  0,\n  3,\n  1,\n  1,\n  2,\n  0,\n  3,\n  3,\n  3,\n  3,\n  3,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  1,\n  1,\n  3,\n  3,\n  3,\n  0,\n  1,\n  2,\n  0,\n  0,\n  0,\n  0,\n  3,\n  3,\n  1,\n  3,\n  2,\n  1,\n  3,\n  0,\n  1,\n  0,\n  1,\n  3,\n  1,\n  0,\n  1,\n  2,\n  0,\n  2,\n  0,\n  2,\n  0,\n  2,\n  2,\n  0,\n  0,\n  0,\n  2,\n  0,\n  3,\n  3,\n  1,\n  2,\n  3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  3,\n  3,\n  3,\n  0,\n  1,\n  3,\n  0,\n  0,\n  2,\n  0,\n  3,\n  ...],\n 0.807318376068376,\n [['@ user @ user # cmbyn does screen august 4 & amp ; 6 at # miff', 1, 3],\n  ['yes # depression & amp ; # anxiety are real but so is bein # grateful & amp ; # happiness \\\\ ni choose how i wanna live my life not some disorder',\n   2,\n   3],\n  [\"that moment when people say you don't need medicine, it's mind over matter. you need to stop doing that. # bipolar\",\n   3,\n   0],\n  [\"i'm so nervous i could puke + my body temp is rising ha ha ha ha ha\",\n   3,\n   1],\n  ['i cannot see a rational way of bearing a grudge to him for that. i do not. maybe because i do not live by netflix and i do not care...',\n   3,\n   0],\n  ['@ user is it just me that thinks it looks boring?', 0, 3],\n  ['@ user no # racism, no # hatred, no # sectarianism... only yes to love',\n   0,\n   2],\n  ['yukwon no video do zico the world is shaking', 1, 3],\n  ['but, i have offended so many people with the idea that conflicts and value judgments are separate that we need to have a talk.',\n   0,\n   2],\n  [\"when you should be working, but you're shopping amazon prime deals instead...\",\n   1,\n   0],\n  ['@ user rumor has you are # wellendowed # awesome! truth is you are a # big # notsomuch so you know a bunch of # gaypeople # sow',\n   1,\n   0],\n  [\"omg we're eating drinking in a restaurant and so is a baby!!! quell horror # yummymummiesau\",\n   1,\n   0],\n  [\"hello phy6 i'm stressing over u ayuku na?? ¿\", 1, 3],\n  ['are you always looking for quotes of your days? then follow @ user to learn more! \\\\ n # quote # doubleviz',\n   1,\n   2],\n  ['@ user huhu kak help me through all of this', 1, 3],\n  [\"let's start all over again..... \\\\ n # feels # lover # happiness # loyalty # truth\",\n   2,\n   1],\n  ['@ user is the man', 2, 1],\n  [\"request mri 2 years ago, neuro only requested last year, i'm still waiting on appointment # mssucks # healthcarefail\",\n   3,\n   0],\n  ['@ user improve on the makeup dear to avoid reduction in viewership...',\n   2,\n   3],\n  [\"@ user i don't know my mouth was burning the whole time\", 0, 3],\n  ['how i drink two 40s and im still somewhat sober?', 3, 1],\n  [\"damn twitter making everybody mad, it's hilarious\", 0, 1],\n  ['# work not to', 0, 3],\n  ['the patients were increasingly protected during heart attacks, chains have encouraged smoke, anger and hundreds of new hospitals.',\n   0,\n   1],\n  ['i feel so intimidated talking to chicken now that i know how pretty she is',\n   0,\n   1],\n  ['@ user ( c ) grew with resentment for herself and the world around her. \\\\ n \\\\ nher spine tingled as she heard the incessant clicking of a ( c )',\n   3,\n   0],\n  ['you know your ( numerous ) meds have kicked in when you find stupid things highly amusing # bpdproblems # keeptalkingmh # mentalhealth',\n   0,\n   1],\n  [\"don't grieve over things so badly..\", 2, 3],\n  ['this nightmare is nearly over gang gang gang', 0, 2],\n  [\"i haven't had to speak maltese in over two years and now have relatives calling me about the trip and it's terrible\",\n   3,\n   0],\n  ['@ user i know', 1, 3],\n  ['@ user shocked as well. but bc i cheer for another club in the swiss league …',\n   1,\n   2],\n  ['signs of incipient faggotry are the arsehole quivering and puckering.',\n   3,\n   0],\n  [\"' if you try to get rid of # fear and # anger without knowing their meaning, they will grow stronger and return.'\\\\ n ― deepak chopra\",\n   2,\n   0],\n  ['@ user im sorry i voted jeans & lt ; / 3 u look banging who tf needs food anyway when ur a student existential dread feeds us',\n   0,\n   1],\n  ['hey @ user would it be safe to assume that this is the most disappointing # madden in years in your opinion?',\n   0,\n   3],\n  ['humble yourself in the sight of the lord. if we have died in christ, then how can we be offended? a dead person cannot feel anything, right?',\n   0,\n   2],\n  ['@ user @ user yeah you have not been the perfect patient like i was # dread',\n   3,\n   0],\n  ['come on blues # stateoforigin # origin # nswblues # nsw', 1, 2],\n  ['i think that nuclear weapon and cyber weapon are big threats, but i think that the bigger threat is scalar weapon... \\\\ n # scalar # threat',\n   2,\n   0],\n  ['watching # scottishopenherochallenge from last night... smoke, flames, tense sound effects and lively commentary.. # boring # dull # shite',\n   3,\n   0],\n  ['faint glimpse of the circling stars. presently, as i went on, still gaining velocity, the palpitation of night and day merged into one',\n   3,\n   1],\n  [\"@ user bro no you don't you'll be so dissapointed in me il let you read it next time you're down here tho\",\n   0,\n   3],\n  [\"don't justify terrorism as communal hatred. # amarnathterrorattack is sheer act of cowardice. let's unite together against terrorism. luv all\",\n   0,\n   2],\n  ['john 14 : 27 \\\\ nlet not your heart be troubled, neither let it be afraid. # peace # afraid',\n   2,\n   1],\n  ['@ user at least smile a little holy crap twiggy.', 1, 0],\n  ['# sleep is my # drug. my bed is my dealer. my # alarm is the # cops. # school is the # jail. # teamfollowback',\n   0,\n   1],\n  [\"so, if you have a really tiny penis, get help, but please don't try to compensate on the road # bigcar # tinypenis # roadrage\",\n   3,\n   0],\n  ['codes? lyft codes? we got em! use : oath # great deals are here for you now # loveislove',\n   2,\n   1],\n  ['# amarnathterrorattack @ user @ user cn u plz ans wt u r afrd of or wt stpng u to end # terrorism wn who',\n   0,\n   3],\n  ['@ user @ user it is indeed time 4 you 2 create the ghost filter # canwegetaghostfilter??? # snapchat # ghostfilter # re',\n   1,\n   2],\n  ['@ user awe feels or que :, (', 1, 3],\n  ['to be really knowledgeable and really petty is such a delight to behold.',\n   2,\n   1],\n  ['filled with sophisticated glum', 1, 3],\n  [\"but damn the sight of them getting scared af makes me feeel sooo bad! which they should feel afraid cause if their mom don't come n it them\",\n   0,\n   3],\n  ['from the archives... strikeforce champ ronda rousey 301 # chirp # church # mayhemmiller # naked # rip # rondarousey # twitter',\n   1,\n   3],\n  ['@ user yessss waiting for an epi is for the birds. it sucks. im waiting for walking dead new',\n   3,\n   0],\n  [\"@ user @ user it ruins my frigging night each night at 9pm. mrs loves it, i've been early to bed for a month.\",\n   3,\n   0],\n  [\"my main concern are the children and his wife thats if she is still stuck with him and if she is, then she's strong af. jeez\",\n   2,\n   3],\n  ['@ user been there done that', 3, 1],\n  ['@ user i coloured my hair bright red and had a dodgy fringe. # dreadful # nophotos # thankgoodness # betterblonde',\n   3,\n   1],\n  ['i finally got my drivers permit # yes # readytodrive # nervous # scared',\n   3,\n   1],\n  [\"getting up for work is so much harder when charles doesn't have to\", 2, 3],\n  ['@ user looking at babies just makes me cross my legs and wince', 3, 1],\n  ['@ user id argue that sakura space is the best of the franchise and its not on your list. # dissapointed',\n   0,\n   3],\n  [\"@ user it used to scare me too... but it's better this way.\", 3, 2],\n  ['another blow for students as the su have shunned wildcats for fear they will offend dr. dre.',\n   0,\n   3],\n  [\"have you ever spoke in tongues, don't be afraid.\", 2, 0],\n  [\"quote of the day comes from queen cersei herself @ user'power hungry people are fearful, otherwise why wouldn't you just chill? '\",\n   3,\n   2],\n  ['@ user homyghad', 1, 3],\n  ['i was so scared!.. i thought i lost another daughter tonight. # grateful',\n   3,\n   1],\n  ['the number of ppl who took it the wrong way is not that alarming, but srsly why do u think lyt dat man oy',\n   0,\n   1],\n  [\"@ user @ user @ user i confess i didn't watch last week. # bad are you going to do an episode on accessibility?\",\n   0,\n   3],\n  ['over 9 hours, 6 trains and 7 stations only to be back where i started # nightmare',\n   3,\n   0],\n  ['@ user : we need more mutual # trust to increase # security & amp ; fight # terrorism & amp ; # radicalization in europe # osce17aut # diplomacy140',\n   0,\n   2],\n  [\"you won't reach a # goal you hide in a drawer. keep it in front of your face at all times. # wednesdaywisdom\",\n   0,\n   2],\n  [\"yikes got my first job interview next week, haven't had one in years\",\n   3,\n   1],\n  ['attention seeker chris uhlmann highly aroused over the attention he drew to himself now enjoying some fists of fury time @ user @ user',\n   0,\n   1],\n  ['alien newborn - alien : resurrection ( sideshow collectibles ) - this thing really was an abomination! # horror # aliens # figures',\n   3,\n   0],\n  ['strapless wedding dresses look awful on most people. \\\\ njulianne hough looked great',\n   3,\n   1],\n  ['every time i fart my dog jumps in fear hahahaha yass', 0, 1],\n  ['the good thing about being a pessimist is that when i have low expectations all the time, i am pleasantly surprised more often. # pessimist',\n   2,\n   3],\n  ['you grieve for those who should not be grieved for ; \\\\ n # kissableslovesmshopmag \\\\ nalloutdenimfor kissmarc',\n   2,\n   3],\n  ['@ user u make my heart flutter', 3, 1],\n  [\"@ user # tuesdaythoughts # horror damn it's tough to chose. but i will go to camp crystal lake but not as\",\n   3,\n   1],\n  ['it bugs me that people concern themselves so much with what other people choose to do with their money',\n   3,\n   0],\n  ['although i laugh and i act like a clown beneath this mask i am wearing a frown my tears are falling like rain from the sky',\n   1,\n   3],\n  [\"trying not to be annoyed but i keep getting told i'm on lists for things and then everyone's on the list except for me\",\n   0,\n   3],\n  [\"if people tweeting about # loveisland we're as passionate about other topics the world would be a much better place! # dull\",\n   1,\n   3],\n  ['damn i just walked up to the train station and i literally died', 0, 3],\n  ['too many of us are not living our # dreams because we are living our # fears.',\n   3,\n   2],\n  ['each of ye separate fallen ; if we quickening his wrath upon us, will only cause our pain to be more unbearable in that pit.',\n   0,\n   3],\n  ['10 / 10 do not recommend burning your scalp in the sun. my parting is glowing red and it burns where ’ s a cap when you need one?',\n   2,\n   0],\n  [\"if the blues were whiskey, i'd stay drunk all the time\", 0, 3],\n  [\"it's 6 : 30 in the morning and i'm dry ass up\", 0, 3],\n  [\"@ user i remember when ron reagan said tear down that wall. trump is so afraid of'others'he obviously doesn't feel safe.\",\n   3,\n   0],\n  ['really wanna dye me hair a bright colour but iv spent all this time growing the dye out',\n   1,\n   2],\n  ['@ user @ user there might be a spec of hope at the end of this horrific tunnel',\n   3,\n   2],\n  ['nice one # ee so much for data protection, not impressed that you can talk to someone the opposite sex who guessed my password,',\n   1,\n   0],\n  ['# merkel has supported all # israeli # terror initiatives opposing the # palestinian bid for membership at the # un.',\n   0,\n   3],\n  ['important read on the difference between # pleasure and # happiness and the relationship between # digitaltechnology # addiction & amp ; # depression',\n   3,\n   1],\n  ['@ user we were warned. and now we basically only have the choice between trump, pence, ryan, et al for potus',\n   0,\n   3],\n  [\"it's kind of shocking how amazing your rodeo family is when the time comes that you need someone\",\n   1,\n   0],\n  ['duty calls.', 3, 0],\n  [\"the wildest shit just happened at work i'm astounded\", 3, 0],\n  ['@ user video n / a', 1, 3],\n  ['seems like the only time spent sober these past few days was when i was sleeping. and even then i was waking up faded lol',\n   3,\n   1],\n  ['shall rest by day, a fiery gleam by night ;', 2, 1],\n  ['i keep it real.. sorry if you get offended', 0, 3],\n  [\"kokobop is such a weird name \\\\ nbut i remember that it is said to be more lit that growl and it is # exo so i'm accepting the name\",\n   1,\n   2],\n  [\"@ user and i'm serious, 20 - 23 july, singapore, holiday ( and accompany my friend for job interview ), with one of my friend.\",\n   1,\n   2],\n  ['@ user # 더쇼 # got7 # 니가하면 rthrc # ifyoudo # mad treeq', 1, 0],\n  ['13 ) mutual whos always online - @ user bc we have to bully her to get to sleep',\n   0,\n   1],\n  [\"@ user @ user @ user @ user and i apologised like 15 times and you're still holding a grudge, can't help thag\",\n   0,\n   3],\n  ['@ user every # girl # nightmare ha ha ha ( ~. ~ )!!', 3, 1],\n  ['there is at least one alternate universe where trump stayed a democrat, beat hrc for the nom, and got elected as a democratic president.',\n   0,\n   2],\n  ['@ user # love lights # up old tasks will soon going and!!! # serious',\n   1,\n   2],\n  ['@ user hahahahahahahah a want to move out as well', 1, 3],\n  ['love u so much but u always get angry at', 0, 3],\n  ['@ user @ user sort it out @ user', 1, 2],\n  [\"# amazon's # primeday debut in # india was # disappointing, maybe next year it will get better.. glad it's finally here though!\",\n   3,\n   0],\n  ['batman like to enrage the heat on the new dimity frock and proposed marriage to me! polly shaw will lay me a cbgb crazy balled',\n   0,\n   1],\n  ['@ user it chases them away, girl. or matlakala.', 0, 1],\n  [\"@ user it really is. and it was a normal thing a few years ago but it should've stayed in the past by now.\",\n   2,\n   3],\n  ['@ user said, “ surely the # bitterness of # death is past. ” [ 2 / 2 ]',\n   3,\n   2],\n  ['post vacation blues are so real', 1, 3],\n  ['how the jeff am i gonna cope @ kc. diagnosed myself with 3 serious illnesses this morning & amp ; spent £22 on ailments from the chemist',\n   3,\n   0],\n  ['no matter how much @ user lights up the forest, they end up getting lost \\\\ n # zescoforest \\\\ n # ssbola',\n   3,\n   1],\n  ['i was so confused but then my inner fujoshi was screaming and like i was trying so hard not to smile or laugh',\n   1,\n   3],\n  [\"shaking about your 2 bills on snapchat you're obviously new to money\",\n   0,\n   1],\n  [\"it's # nationalfrenchfryday and i'm working at mcdonald's. # frightened\",\n   3,\n   0],\n  [\"@ user @ user'i'm dismayed at the uk decision to pull out of the eu and i've urged may to rejoin'- european leaders\",\n   3,\n   0],\n  ['who knew magnus bane with teary eyes and trembling lips would be my downfall',\n   0,\n   3],\n  [\"@ user @ user @ user @ user i didn't say it because you left the party and game in a huff\",\n   0,\n   3],\n  ['thankful for... job, healthy, sober, happy as hell about things... still have a panic attacks every time i put my sunglasses on.',\n   2,\n   1],\n  ['# being a # terrible # mother makes me uncomfortable.', 0, 3],\n  ['@ user 3. home alone 4. fast and furious', 0, 1],\n  ['@ user @ user with all the other stuff going on in houston # crime you spend your time bullying the homeless # wonderful',\n   1,\n   0],\n  ['after all of the disney animated films are remade in live action, will they just reanimate them again?',\n   1,\n   2],\n  ['1 samuel 18 : 15 \\\\ nand when # saul saw that he had great # success, he stood in # fearful # awe of him.',\n   2,\n   1],\n  ['also, been kind of silent on s11 of the x - files because i am terrified that cc is going to screw it up! actually i know he will... # dreading',\n   3,\n   0],\n  [\"# colorfabb # ngen worst filament for me : ( good finish but so fragile :'( cc @ user\",\n   3,\n   0],\n  [\"she'll leave you with a smile\", 2, 1],\n  ['@ user @ user @ user @ user @ user being # gay is not an # whatsupwiththat # nike # adidas #??',\n   1,\n   0],\n  [\"@ user'call to action by tv host john oliver, who urged viewers to leave comments expressing their displeasure at the fcc's policies.\",\n   0,\n   3],\n  ['@ user truly dreadful', 0, 3],\n  [\"chicks i don't even talk to look up to me. # flattered\", 0, 1],\n  ['@ user haha nightmare', 0, 3],\n  [\"@ user - - been a damn sight better!'grisk poked grillby's chest, a low snarl leaving him.\",\n   0,\n   3],\n  [\"internet waiting 15 minutes for my snapchat to update and it's only a fraction done.\",\n   3,\n   0],\n  ['@ user wait, i saw this tweet and thought he was joking... he was serious??',\n   1,\n   0],\n  [\"let's do an action for # amaranthyatra stand against this type of # shamless # activity give a one voice to against # terrorism # india\",\n   0,\n   2],\n  [\"@ user it just reminds us of the 90s & amp ; early 00s.'i'll have a pinot grigio'still makes us shudder.\",\n   1,\n   3],\n  [\"@ user tried it once. poured into the sink. didn't bother to make tasting notes : - ) looks like cheap sake, tasted like it too...\",\n   1,\n   0],\n  ['@ user # crap sorry but doesn ’ t work', 3, 0],\n  ['even the devil was once an angel. # tuesdaythoughts # change # think # devil # angels # anxiety # wordsofwisdom',\n   3,\n   2],\n  ['going to bed with dry and clean hair. # blessing', 2, 1],\n  ['@ user @ user @ user @ user @ user bitch played every role she ever did exactly the same. # dull',\n   3,\n   0],\n  [\"mood : kinda bitter bc lee hi didn't appear in jaewon debut mv\", 3, 0],\n  [\"you can treat someone like a king, a queen, like they're the center of your universe and they will still shit on you lol \\\\ n \\\\ n # mood # pessi\",\n   0,\n   3],\n  ['just finished playing mystic messenger. and i didnt expect the amount of angst in it! \\\\ n # mysticmessenger # feels',\n   1,\n   2],\n  [\"@ user what are the current statistics concerning'backdoor abortions '. if alarming, what preemptive measures are in place?\",\n   0,\n   3],\n  ['@ user @ user you really need better source info and avoid the fake news, it has clouded even the obvious',\n   3,\n   0],\n  ['@ user that brown waist coat was a no', 3, 1],\n  ['@ user inside job so modi can show more tantrums', 3, 0],\n  ['when you put vienesse whirls in the same tub as the horrid cherry bakewell # grim',\n   0,\n   3],\n  ['suicide blast killed 11 people in cameroon. # bomb # attack # security # explosion',\n   0,\n   3],\n  ['isis was not defeated in # mosul. it just changed its address to # libya. # egypt # sinai',\n   2,\n   0],\n  ['one day someone will change ur perspective from bitter to sweet from broken to complete',\n   3,\n   2],\n  ['and my mind and my soul. who made him substitute for my brothers and near me for all the beautiful days and i found you lost and grabbed',\n   3,\n   1],\n  ['another chunk of # antarctic the size of # wales broke off. the # glee of knowing humans deserve their # extinction. # climatechange',\n   3,\n   0],\n  [\"@ user i don't have a tv in my room\", 0, 3],\n  [\"@ user everyone in the world uses the word # terror so it serves his own purpose, that's not only in the # gcc the case...\",\n   0,\n   3],\n  ['summer sale! bogo 50 % off everything in our retail showroom! valid thru 7 / 15 mix & amp ; match... equal or lesser value # bogo # ragegra',\n   0,\n   1],\n  [\"a bitter woman says'all men are the same'\\\\ n \\\\ na wise woman decides to stop choosing the same kind of men.\",\n   0,\n   2],\n  [\"i'm really upset that it's been 5 years and you still haven't followed me back @ user why you do this to me solana??\",\n   0,\n   3],\n  ['studio window open - terrible smell of cooking from somewhere', 3, 0],\n  [\"@ user i'd never leave the couch again! # excited and # weary\", 3, 1],\n  ['@ user ya one time i was like hey daddy queue up with me i can make you wild growth and he was like nice try lulu abuser',\n   1,\n   0],\n  [\"pretty upset with people bashing @ user @ user cast of'the know'catering to kids instead of gamers? lost respect..\",\n   0,\n   3],\n  [\"3 hours of hell again. # anxiety. at this point i'm convinced i'll never get an on site job again or play keyboards live.\",\n   3,\n   0],\n  ['boom pagod', 1, 0],\n  [\"@ user im terrific thanks. \\\\ ni hope you managed to get even if it's just 40 winks of. it was a crushing defeat. he was so dejected\",\n   3,\n   1],\n  ['chad and sarah is honestly me and my ex 10 years ago # cbb # horrifying',\n   3,\n   0],\n  ['does # fear of # missions still have a hold on you? are you so busy looking for opportunities you cannot see anything else? matthew 10 : 27 - 33',\n   3,\n   2],\n  ['@ user @ user @ user i believe ur mekka n madina also dikling which u kiss. a dark dirty one',\n   1,\n   0],\n  ['dro and his teeth are still fine tho # insecure', 3, 2],\n  ['update : one person dead & amp ; another in serious condition after home invasion in flint. incident happened in college cultural center area.',\n   0,\n   3],\n  ['@ user hey you lost your credibility ( not that you had any ) also we told you so #',\n   3,\n   0],\n  ['@ user do the thing enrage all the people who cannot do the thing', 0, 2],\n  ['@ user that rap reminds me of when the kids were small and they would prepare a performance # cute # crap',\n   0,\n   1],\n  ['i thought he cried over some of his relative death or something but when i know the truth. i just wanna burst out',\n   3,\n   1],\n  ['@ user omg why', 0, 3],\n  [\"as horrid as it will be to see him move on, let's not rewrite history, he's been our best servant under hughes, none have out shone him\",\n   0,\n   2],\n  ['im not naive not to notice the way you looked at me, your seductions and discreet moves but you scare me honey to tell you quite frankly.',\n   2,\n   0],\n  [\"@ user @ user yip. coz he's a miserable huffy get\", 3, 0],\n  ['no one wants the chubby, scarred toy. # hurting', 0, 3],\n  [\"@ user @ user billy joel is in huge danger, he's so brave # inspiring\",\n   2,\n   1],\n  ['mothafuckas wanna adopt the dark, but i was born in it', 2, 0],\n  [\"9. so to summarize... aman, norwood and mitchell clearly lead the field in resources, though mitchell's burn rate is alarming.\",\n   2,\n   0],\n  [\"when you get paid and you instantly start buying crap online that you don't need..\",\n   0,\n   3],\n  [\"racing all around the seven seas \\\\ nchasing all the girls and making robberies \\\\ n'causing panic everywhere they go \\\\ nparty - hardy on titanic...\",\n   0,\n   1],\n  ['school duties. good night ppl', 1, 3],\n  ['@ user thing is tho my pout was actually serious', 0, 2],\n  ['a little positivity for a dreary tuesday. from my little jar of positivity now available in my # etsy store # selfhelp # handmadehour #',\n   1,\n   2],\n  ['love getting 5 hours of sleep, and then getting woken up to horrid allergies. oh good morning, world. # allergy # wonderful',\n   1,\n   0],\n  ['what will we do when # gots7 is over? im starting acknowledging # endoftheworld # gameofthrones # dontleaveusjustyet',\n   0,\n   3],\n  [\"i'll never delete someone off facebook. it gives them a satisfaction that someone intimidated and i most certainly am not.\",\n   0,\n   2],\n  ['one arm around my waist, hand down my crouch to pull me towards yourself with. you behind my back, jeans around your ankles you inside',\n   0,\n   1],\n  ['@ user september? really?', 1, 3],\n  ['@ user i am so stressed today i have time so if they drop it, it would be so nice.',\n   1,\n   3],\n  ['@ user then dont disappoint them', 2, 3],\n  ['cyclist slams breaks to pace it to traffic lights. i slam car breaks & amp ; tell him careful nearly ran him over = all the cussing # charming # bulwell',\n   1,\n   0],\n  ['@ user are u going to see her in the airport?', 3, 1],\n  [\"the # eclipse is boring. check out @ user, or @ user, or @ user, or @ user these shows aren't boring.\",\n   0,\n   2],\n  ['@ user i love ur angry comments', 0, 1],\n  [\"you choose your mood on weather you're going to be a # blessing or be rude..\",\n   0,\n   2],\n  ['@ user guess who got a ghd no need to dread coming up and getting ready in mine with my boots straighter',\n   2,\n   1],\n  [\"@ user'my own mistakes?'grisk asked - well, more of a growl'my mistakes meant that i could / learn / from them and improve! '\",\n   0,\n   2],\n  ['@ user @ user @ user @ user ring a ring of roses isto do with the plague, im sure that will offend someone',\n   3,\n   0],\n  [\"@ user i want to snatch that beanie tbh i'm kinda scared as well\", 3, 1],\n  [\"@ user no offense but one of my friend watches you and calls you his'synpie'which i have no idea why but, he watches your videos\",\n   0,\n   1],\n  [\"i start my day thanking my stars. then i see my colleague walk away early ( notice period - honeymoon scenes ) and i wonder'why god why! '\",\n   1,\n   3],\n  [\"@ user @ user @ user @ user it's excellent! # grippedbyfear # fearful # fearsome # fearfearfear\",\n   2,\n   1],\n  ['@ user at one point this is what i wanted rba sa? hahaha pero di jud oy di jud what if ga humss ta?',\n   1,\n   3],\n  [\"@ user @ user where's the picture?\", 3, 0],\n  ['@ user you do know when most people refer to the hair as “ lawn ” they mean down there right??',\n   0,\n   3],\n  ['@ user ya, writes horror so everything today in the world looks normal to this dark individual',\n   3,\n   0],\n  ['an ignominious end... they changed everything from analog to digital! ikr? everyone who still had an analog phone * had * to',\n   0,\n   3],\n  ['thank you, @ user for using the afghanistan policy of # 44... he was pretty smart! \\\\ n \\\\ np. s. do not look directly at the sun! # bad',\n   0,\n   2],\n  [\"@ user i hope didn't scare other people who owned this figure that he will move at midnight\",\n   3,\n   2],\n  [\"i forgive everyone. it's rare for me to hold a grudge.\", 0, 2],\n  [\"# moist people aren't # offended by a little typo.\", 0, 2],\n  [\"@ user @ user go ahead & amp ; # coon. would love to see you get hit by a man. i bet you wouldn't find it funny # blackhatematters\",\n   1,\n   0],\n  ['i woke up too moody who gon die today', 3, 0],\n  [\"why is an alarm clock going'off'when it actually turns on? # alarm # alarmclock # thursdaythoughts\",\n   3,\n   0],\n  ['@ user indeed \\\\ nalways a # worry for our # homeland # gibraltar # spain \\\\ n # tale or # foretelling # future \\\\ n # great # short # story',\n   1,\n   2],\n  [\"@ user # f3roswell # preblast \\\\ ni've been handed the keys to roswell area park. see you in the gloom. be ready to slip & amp ;\",\n   3,\n   1],\n  ['in this state of # terror, you are far more susceptible to # addiction. \\\\ n \\\\ nalso more likely to spend your # money in attempt to feel better.',\n   3,\n   0],\n  [\"huddling before flames \\\\ ndon't let poetry scare you \\\\ nproduction is wild \\\\ n # haiku\",\n   1,\n   2],\n  [\"reminds me a little of monster ( though on a tiny scale ) and it has one of the most genuinely horrific villains i've ever seen\",\n   1,\n   2],\n  ['when you took off for expo but the flight you need is sold out so no expo for me',\n   1,\n   3],\n  ['one chair is having the munchies. are alpacas edible? # afraid # whatthefac # salientfac # salient2017',\n   3,\n   0],\n  [\"i dont know if i'm able to take care of kids or not. duduk dengan anak sepupu ( boy ) pun dah menguji kesabara\",\n   3,\n   1],\n  ['@ user « crouch, as though she is about to attack. she launches herself into the air towards me and explode in tiny dazzling orbs of »',\n   1,\n   0],\n  ['@ user # bitter we all have bad experiences, this was 22 years ago... time to let it lie... @ user forever',\n   3,\n   2],\n  ['max @ user is lit af he rly put up w my dumb ass for abt two yrs ol boy deserves an award & lt ; 3 i lov him sm hes a',\n   0,\n   1],\n  [\"we are hard - pressed on everyside, yet't crushed ; we are perplexed but't in despair ; persecuted, but't forsaken ; struck down, but\",\n   2,\n   3],\n  ['house sitting for mil. feeding baby @ 3. 45 and cat starts scratching at door. mummy now needs a nappy : s # terrified # neveragain # nope',\n   3,\n   0],\n  ['words may sting. but silence is what breaks the heart.', 2, 3],\n  [\"depression & amp ; fear come when we're hyper - focused on what we don't have or who we're not instead all that we have and who we are! # content\",\n   3,\n   2],\n  [\"hello puss! puss puss puss! don't be afraid!\", 1, 2],\n  ['actually gunna miss america a lot', 1, 3],\n  [\"that moment you pour your heart and soul to a girl, she reads the message, but doesn't reply # love # relationship # help # idontknow\",\n   2,\n   3],\n  [\"' suddenly i can do so much, & amp ; it feels like my brother was holding my back in a way, & amp ; that feels like a horrible thing to say'# insights\",\n   3,\n   0],\n  ['it is a shameful thing to be weary of inquiry when what we search for is excellent. - marcus tulius cicero # aldubersaryin5days @ user',\n   3,\n   0],\n  [\"for every dark, there's a brighter.\", 1, 2],\n  [\"quick annoyingly vague scream into the void : aaaaaaaaaagh. i'm nervous, excited, terrified, trying not to get my hopes up\",\n   3,\n   0],\n  [\"i should've gotten an apartment with kenneth\", 1, 3],\n  [\"@ user just because you married money doesn't mean you have class it just means you are a high prices prostitute. # adorable\",\n   1,\n   0],\n  ['4 years in piece # coreymontheith # glee', 1, 3],\n  ['feeling full of existential dread? bash mass surveillance', 3, 0],\n  ['nicole : we have to go somewhere warm and tropical \\\\ nme : okay where? \\\\ nnicole : oakland \\\\ n \\\\ nwhy does no one in my life ever look at a map',\n   1,\n   3],\n  [\"thankful 4 mother nature's help with the'watering ', downside, my legs are protesting # ouch # snap # crackle # pop rice crispies 4 legs\",\n   0,\n   1],\n  ['jock! pakistani are firing on loc without reason. they r killing our pilgrims. # pmo thanks! v r safe! r v # warfools? # fearing pak nuke',\n   0,\n   3],\n  [\"with you, i'm lost in the moment. without you i'm lost in the world. # world # moment # lostinthemoment # you\",\n   3,\n   1],\n  [\"mom asked if i wanted acrylics & amp ; i said'no because you never know when someone gon let me tickle they pussy'she was deeply offended. lbvs\",\n   0,\n   3],\n  ['wanna hangout with mah bessy', 1, 3],\n  [\"@ user good to know i'm hard to offend when it comes to tmi shit lol\",\n   0,\n   1],\n  [\"@ user sorry to burst your bubble, but opposition research is part of every political campaign. doesn't matter where it comes from.\",\n   2,\n   3],\n  ['flatmates provocating pine pollen man', 1, 0],\n  ['grumpy af today # badsleep # grumpy', 3, 0],\n  [\"me and @ user snap streak is at 260, if that's not amazing i don't know what is # commitment\",\n   2,\n   1],\n  ['add me on snapchat : dfdf _ 66 \\\\ n # dick # pussy # nudes # horny # anal # ass # bigbooty # bobs # cock #',\n   0,\n   1],\n  [\"why would mourinho be talking about lacazette?? he doesn't worry about other club's players. that's klopp and wenger's job\",\n   2,\n   0],\n  ['. @ potus every other president has said you can really only govern foe 18 months until the re - elect. why are you focused on 2020 now? # scared',\n   3,\n   0]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用测试集进行最终评估\n",
    "test(model, test_loader, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T01:26:28.672803Z",
     "start_time": "2024-04-28T01:26:25.656761Z"
    }
   },
   "id": "6c07ec84487fda87",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x700 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 设置画板大小\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# 绘制损失曲线图\n",
    "# plt.subplot(1, 2, 1)  # 1行2列的第1个\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs',fontsize=20)\n",
    "plt.ylabel('Loss', fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# 显示图表\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T01:26:59.608363Z",
     "start_time": "2024-04-28T01:26:59.493628Z"
    }
   },
   "id": "4574f1806f78405c",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x700 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAJ+CAYAAABfFvq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC+qElEQVR4nOzddXiV9f/H8ed9ch1sLOhugZEiSBkgKoJiY3wV/ZlYKCYqttiB3diKCIqoiIAggoRId46Nse6dun9/DI5OBowxdjZ4Pa5r17b73PG+zwY7r/MpwzRNExERERERETkilkAXICIiIiIicixQuBIREREREakCClciIiIiIiJVQOFKRERERESkCihciYiIiIiIVAGFKxERERERkSqgcCUiIiIiIlIFFK5ERERERESqgMKViIhIAJmmGegSRESkiihciYgcobvvvpvWrVsf9GPgwIFHdI3JkyfTunVrdu7ceVSPqalefvllWrdufcDHBw0axJlnnnnAxz0eD7169eLWW2+t0PUGDhzI3XffDcDOnTtp3bo1kydPrvAxFbVkyRL+7//+z/99Ra9VVQ72O9uuXbtyj/nll18O+rP4r8mTJ3PRRRfRpUsXOnXqxJlnnsnzzz9Pfn5+Vd2GiEiNYQt0ASIitd0NN9zARRdd5P9+4sSJrF69mldeecW/zeFwHNE1+vfvz+eff05cXNxRPaa2Ou+883j22WdZs2YNbdu23e/xOXPmkJmZyYgRIw773HFxcXz++ec0atSoKkot48svv2Tjxo3Vcq0DGTFiBOeff/5+2w3D2G/bggULGDNmTIXP/corr/D6669z5ZVXcv3112O321m5ciVvv/028+bN47PPPsNutx9R/SIiNYnClYjIEWrUqFGZF8N16tTB4XDQuXPnKrtGnTp1qFOnzlE/prYaNmwYL7zwAlOnTi03XE2ZMoX69etz0kknHfa5q/pnWVOutU9CQsIhr5mfn88bb7zBO++8Q3h4OIWFhYc8r8vl4q233uKqq67i9ttv928/6aSTaNasGTfeeCMzZ87kjDPOONJbEBGpMdQtUESkmixcuJDWrVvz2WefMWDAAE466STmzZsHlLZgnHvuuXTu3JmOHTtyzjnnMH36dP+x/+3id/fdd3PllVfy9ddfM2jQIDp06MDQoUOZM2fOER0DsGzZMi699FI6d+5M//79+eCDD7jyyisP2eVt5syZXHLJJSQlJdGhQwcGDx7MpEmT9rv/BQsWcNVVV9GpUydOOukknnrqKTwej3+/kpISnnjiCXr37k1SUhL33HMPJSUlB712XFwcffv25bvvvsPn85V5LDs7m19//ZVzzz0Xi8XCzp07ueuuu+jTpw/t27enV69e3HXXXWRlZZV77vK66q1du5b//e9/JCUlMWDAAKZOnbrfcZmZmTz88MMMGDCADh060KNHD2688cYyP49vvvmG5ORk//nLu9bWrVsZPXo0vXv3pnPnzlx22WUsWbJkv/p++OEHRo8eTVJSEt27d+e+++6joKDgoM9bRX311Vd89dVXjBs3jpEjR1bomPz8fIqLi8sdU9avXz9uu+02GjZs6N9WUFDAE088Qd++fencuTPnnnsus2bN8j/u9Xr5+OOPOfvss+nYsSP9+/fnmWeeKfO7cffdd3PFFVfw4IMP0q1bN4YPH47H48Hn8/Hmm29y2mmn0aFDBwYNGsRHH310BM+IiEj51HIlIlLNnn/+eR5++GFKSkro3LkzH3/8MY8++ig33XQTY8eOJTs7m7feeos777yTzp07U69evXLPs3LlStLS0hg9ejRhYWG8+OKLjB49mrlz5xIZGVmpYzZt2sSVV15Jhw4deO6558jKyuK5554jNzf3oGOaZs+ezY033sjll1/OzTffTHFxMZMmTeKRRx6hXbt2dOnSxb/vmDFjuOSSS7jmmmuYPXs27777Lo0bN/Z3rbzzzjuZO3cut956K02bNuXzzz9n2rRph3xeR4wYwa+//srChQvp1auXf/v333+P1+vlvPPOo6ioiMsvv5zo6GgefPBBwsPDWbJkCa+++ipOp5NHHnnkkNfZvXs3I0eOpFGjRkyYMIH8/HyeeeYZMjIy/PuYpsn//d//kZOTwx133EHdunVZs2YNL774IuPGjePdd9/lhhtuIDMz09+FtFGjRvu1CG3cuJELLriAxo0bc//992O32/nwww+54oorePfdd+nRo4d/3wcffJDzzjuPiRMn8vfff/P8889Tp04d7rjjjoPej8/nKxNu97HZ/nmJMHDgQC688EKCg4N5+eWXD/kcQWnLaadOnXjnnXdIS0vjtNNOo0uXLtSpUwe73c51111XpoZRo0axadMmRo8eTfPmzfn222+56aabeO+99+jZsyfjxo1jypQpjBo1ih49erB69WpeffVV1qxZw9tvv+3vxrh48WIMw+Dll1+moKAAm83GuHHjmDx5Mv/3f/9HUlISf/75J48//ji5ubnceOONFbofEZGKULgSEalmF110EYMHD/Z/v2PHDq666qoyL/IaNGjAueeey9KlSw8YrvLy8pg8ebK/S2JISAgjR47kjz/+YNCgQZU65o033iAsLIy3336b4OBgAJo1a1ZmTFl5Nm7cyLBhw7jvvvv825KSkujZsyd//vlnmXB1/vnn+++1V69ezJw5k9mzZ3PRRRexYcMGfvzxR8aNG8ell14KwMknn8zZZ59dZmxSefr3709sbCxTp04tE66mTJlC7969SUxMZM2aNSQkJPDkk0/6n4MTTzyRFStWsGjRooOef5/3338fj8fDW2+9RUxMDABNmzblggsu8O+TlpZGcHAwY8eOpVu3bgD07NmTnTt38tlnnwGl3Un/24X0v+HqlVde8Qeq8PBw/32eddZZTJgwgS+//NK/b79+/Rg7dqz/eZ0/fz6zZ88+ZLiaOHEiEydO3G/7nDlzSEhI8NdaGS+99BJ33nknU6ZMYcqUKRiGQcuWLTn11FO58sor/W8CzJ07l6VLlzJx4kROOeUUoPTnsm3bNv744w9iYmL46quvuPXWW7n++usB6N27N3Fxcdx1113MnTuXfv36AaWTlzz88MM0btwYgC1btvDFF19w++23c+211wLQp08fDMPgjTfe4JJLLiE6OrpS9yci8l8KVyIi1ey/M63t626Xl5fH1q1b2bp1KwsWLADA7XYf8Dx16tQp86J33wvhoqKiSh/zxx9/0K9fP3+wgtKQVL9+/YPe06hRo4DScLB9+3a2bNnCihUryr2HpKSkMt8nJCT4Q8XixYsB/C+wASwWC4MGDTpkuLLZbAwdOpQvvviChx56CKfTyebNm/n777956aWXAGjbti2ffPIJPp+PHTt2sHXrVjZs2MDmzZvLbb0pz5IlS+jcubM/WAF06tSpTAiOj4/nww8/BGDXrl1s27aNTZs2sXTp0oP+TP9r0aJFDBgwwB+s9t3nmWeeyauvvlqm299/x00lJCSQnJx8yGtccMEFZYLhPv++v8pKSEjgo48+YuPGjcydO5eFCxfy559/MnHiRL744gs+/vhjmjRpwuLFi7Hb7QwYMMB/rGEYfPrppwB88sknAJx99tllzn/mmWdyzz33sHDhQn+4CgoKKvM7/scff2CaJgMHDizzMx44cCCvvfYaS5Ys4dRTTz3iexURAYUrEZFq998Xrdu3b2fcuHH88ccf2Gw2mjVr5g9gB1sD6d8BCP6Z3e2/Y44O55jMzMxyX1TXrVv3gOfcd9yDDz7IzJkzMQyDxo0b07Vr13LvISgoqMz3FovFv09OTg7AfhNxHOr6+4wYMYJ3332XWbNmccYZZzBlyhTq1KlTZir89957jzfeeIOsrCxiY2Np3749wcHB5OXlVegaOTk5NGjQYL/t/61x6tSpPPfcc6SkpBAVFUWbNm32u/eKXCs2Nna/7bGxsZimWWY68//+bP/9vB5MXFwcJ5xwwmHVdbhatGhBixYtuOqqq3C73UyePJnx48fz3HPP8dJLL5GdnU1UVBQWS/lDwff9Xvz3ObbZbERHR5f52cXExJSZ6TA7OxvggN1ad+/efSS3JiJShsKViEgA+Xw+rr32Wux2O1988QXt2rXDZrOxcePGcidJONoSEhLKjB3aJyMjg6ZNmx7wuDFjxrBp0ybee+89unTpgsPhoKioqEy3tYrY1z0rPT29TEvQvhfIh9K8eXOSkpKYNm0agwcPZurUqQwbNsw/3fe0adN48sknueOOOxgxYoQ/xN1yyy3+lraK1Jienr7f9n/XuHjxYsaOHcvIkSO5+uqr/S2ETz/9dJnJKA4lMjKy3Gvt2bPHX0taWlqFz1edPvjgA1577TV+/fXXMsHPbrdz4YUXMmfOHH9rZHh4ONnZ2fh8vjIBa82aNXg8Hn/3wT179pQJtm63m6ysrIN264uIiPDXExoaut/jB+p2KyJSGZotUEQkgLKystiyZQsjRoygY8eO/kkE5s6dCxy8Fepo6N69O3Pnzi0zA9uaNWsOuRDxkiVLGDRoECeeeKJ/Ta/K3MOJJ54IwIwZM8ps//XXXyt8jvPOO4958+Yxf/58UlJSyqxttWTJEsLDw7n22mv9waqgoIAlS5ZUuM4TTzyRZcuWlWnx2LhxIzt27PB/v2zZMnw+H6NHj/YHK6/Xy++//w7885wcqKVmn+7du/Prr7+WaZnxer18//33nHDCCUe8ftrR1KJFC7Kyssqdlc/r9bJjxw5atWoFQLdu3XC73WVmrjRNk/vuu4/XXnvNP3HHfyc22TdZyb5W0vJ0794dKP23dsIJJ/g/srOzeeGFFyoc3EVEKkItVyIiARQTE0P9+vX5+OOPSUhIICIignnz5vHBBx8ABx8/dTRcd911TJ8+nVGjRnHVVVeRm5vLiy++iGEY5S4qu0/Hjh2ZNm0a7du3JyEhgWXLlvHGG29gGMZh3UPjxo258MILef755/F4PLRt25Zvv/2WdevWVfgcQ4YM4fHHH+eRRx4hKSmJ5s2bl6nz008/5cknn2TAgAGkpaXxzjvvkJ6efsAZFv/riiuu4KuvvuLqq6/m5ptvxuv18sILL5RZDLdjx44AjB8/nvPOO4/c3FwmTZrE2rVrgdKxaWFhYURERJCens6cOXPKXZ/rpptuYu7cuVx++eVce+21OBwOJk2axI4dO3j77bcr/JwEQu/evTnrrLN47rnnWLduHYMGDaJOnTqkpqby2WefkZqaygsvvACUTtKxb9r9W265hcaNGzNt2jTWr1/PAw88QIsWLRg+fDivvPIKxcXF9OzZkzVr1vDKK6/Qs2dPTj755APW0apVK4YOHcoDDzxAcnIyHTp0YMuWLTz//PM0aNCAJk2aVM8TIiLHBbVciYgE2MSJE4mPj+fuu+/m1ltv5a+//uK1116jWbNm/gkeqkvjxo155513KCkpYfTo0Tz//PNcc8011K1bt9wuVfs8+eSTdOrUiUceecS/OOzDDz9Mnz59DvseHnzwQa655homTZrETTfdRHFxcZlpuw8lNDSUM844g61bt3L++eeXeWz48OHceOON/PDDD1xzzTW89NJLdOvWjfHjx5OdnX3ISTOgtCvep59+SoMGDbj77rt5/PHHueSSS2jTpo1/n31Thy9btoxrrrmGJ554gnr16vHKK68A+LsGnnvuudSvX58bb7yRKVOm7Hetli1b8sknnxAbG8u9997LnXfeiWmafPjhh5VaELm6TZgwgfHjx5Oamsr999/PlVdeydNPP03Dhg2ZPHmyP/harVbeeustBg8ezMsvv8wNN9zAli1bePvtt/0ToDz22GPcdNNNfP/991x77bV8/PHHXHbZZbz11luHbAF84okn+N///sdnn33GqFGjeP311xkyZAjvvvsuVqv1qD8PInL8MMyKjHYVEZHjwoIFC7Db7f7pw6F0MoHevXtz1113cfnllwewOhERkZpN3QJFRMRv1apVvPTSS9x+++20b9+erKws3n33XcLDwznrrLMCXZ6IiEiNpnAlIiJ+V111FS6Xi08//ZSUlBRCQkLo0aMHTz311H7To4uIiEhZ6hYoIiIiIiJSBTShhYiIiIiISBVQuBIREREREakCClciIiIiIiJVQOFKRERERESkCihciYiIiIiIVAFNxX4IGRl5aD5FEREREZHjl2FATEz4IfdTuDoE00ThSkREREREDkndAkVERERERKqAwpWIiIiIiEgVULgSERERERGpAhpzdQR8Ph9eryfQZYjsx2KxYLFYMQwj0KWIiIiIHDcUriqppKSIrKw9gGa7kJrJ4QgiIqIONps90KWIiIiIHBcUrirB5/ORlbUHhyOIsLBItQ5IjWKaJl6vh/z8bDIyUomLa6DfUREREZFqoHBVCaVdAU3CwiJxOJyBLkekHE6sViuZmbvxeNzY7Y5AFyQiIiJyzNOEFkdArQFSkxmG/nmLiIiIVCe9+hIREREREakCClciIiIiIiJVQOFKRERERESkCmhCi+PEhAmP89NPPwDg9Xpxu90EBQX5H3/mmZfo1CnpsM55xx2j6dSpM5dfftVh13PTTdeycuXf2O1lpwmPja3Lp59OLrPts88mMW/eXF555c0Dns/lcvHuu28ya9bPZGVl4nQ66dQpiWuuuYEmTZoedn0iIiIiIofLME1TCzUdRHp6Hv99htxuFxkZKcTEJPpnYTNNk2KPr1prC7JZKjWpxvTp03j33Tf56qtpR6GqirnppmtJSurK1Vf/3wH3KSoq4u23X+fzzz+mc+cuBw1XTz31GDt2bOO++x4iMbEeeXl5vPvum/z88w98+uk3hIeHH43bqNHK+z0VERERkcNnGBAbe+jXk2q5qgKmaTLqs+X8vSu3Wq/bqV4Eb13UqUpmLUxJ2cX55w/lwgsv5fvvp3LaaYMZPfp23nxzIr///htpaWk4nU5OOeU0br31TgzDKBOQHnvsIRwOB3v27GHZsiVERUVzwQUXc/75F1W6piuvvJi2bdszbNgItm7dfNB9V6z4i0GDhpCYWA+A8PBwbrzxFgoK8snMzCA8PJyioiJee+0lZs2aicfjpkOHjowZcw8JCYnk5GTz+uuv8vvvc/F4PLRvfwI333w7DRs2Kve5ueOOscyc+SMfffQeqakp1K/fkOuuu4kePU6s9P2KiIiISO2mMVdV5FiZlL2wsJBp037i2mtv4IsvPuGPP+bz4ouv8/PPc3nyyWeZMuVrliz5s9xjp0+fxvnnX8gPP8zi0ksv55VXnmfPnrRK1/Lyy2/w0EOPER0dfch9Tz11EO+99xaPPfYQM2Z8z/bt27DZbNx774M0btwEgOeee4o1a1bzzjsfMXXqT9SpE8ODD94LwH333cWuXTt5992PmTz5exo1asItt1xPQUF+uc/NggXzeOaZJ7jttruYPn0WV1/9f9x3311s3ryp0vcrIiIiIrWbWq6qgGEYvHVRp1rTLfBgzjjjTOx2O3a7nbPPHs4ZZ5xFdHQd0tPTKSkpISQk9ICBKSmpG927l7bcnHXWOTzzzBMkJ++kbt24cvf/+OMP+PLLT8tse/319/xjpOLi4itc95VXjqJFi1bMmPE9r7zyAtnZWcTG1uXii0dy4YWX4na7+eWXn3jyyeeIj08A4Oabbyc5eQfJyTv566+lfPTRF8TExAJw/fU38/PPP7BgwXzatz9hv+fm66+/YNiwEXTu3AWA3r1Ppnfvk/n226+57ba7Kly3iIiIiBw7FK6qiGEYBNutgS7jiMXG1vV/XVxcxPPPP82yZUuJi4ujVas2mKbJgYbpxcTE+L+22Up/tXy+AwfOSy+94qBjrg5Xnz596dOnLwDJyTuZM2cWr7/+CqGhofTq1QeXy0VCQoJ///DwcNq0acfKlX8DUK9eff9jVquVuLgEUlJS/OHq389NamoKy5YtYcqUr/zbvF4vXbt2r7L7EREREZHaReFKyvh3S9hTTz1GREQE3347A6fTic/n44wzBgSwuvJt3bqFq666lLff/pBmzVoAUL9+Ay655HJWrVrB+vXrGDJkKA6Hg927U2nUqAkAWVmZTJr0ARdffBlQGsiaNWsOlAal3btTiY2N9V/n389N3bpxDBp0JpdddqV/W2pqKk6n8yjfrYiIiIjUVBpzJQdUUJCPw+HAarVSWFjAq6++SEFBAW63O9ClldG4cRNat27DhAmPs3r1SkpKSiguLmbBgvksXbqEvn0HYLFYGDToTN55503S0/dQUlLCm2++xqpVK4iNjaVXr968+OIzZGSkU1JSzGuvvYzP56V375PLvebQocP56qvPWLNmFQBr165m1KiRzJz5Y3XeuoiIiIjUIGq5kgO69dY7efrpxzjjjAGEhIRy0kl96NnzJDZv3hjo0sowDIMJE17igw/eYfz4caSnp2GxWGnZshXjxj1Ct249ALj55tt4882JXHPNFRQXF5OU1JVHH30KgAceGM9rr73MVVeNpKioiPbtO/Dii68TERFJQUHBftccMOBUioqKePzxh9m9ezcRERFccMEljBhxYbXeu4iIiIjUHFrn6hAqus6VSE2j31MRERGpjYrdXj5ftovF27O585QWNIoODnRJWudKREREREQCJ7vIzadLk9mVU8yAlrGc3KwOduuBRyV5fSbfr9rNG79vJS3fBcCm9IIaEa4qSuFKRERERESqTH6Jh48X7+TTpckUuLwAzFiTRp0QO2e2i2foCQk0qRPi3980TX7bnMkrv21hS0YhAAnhTq7v04T+LWLKvUZNpXAlIiIiIiJHrNDl5fNlyUxavJPcYg8ALeuG0q1hFD+t20NGgYuPFu/ko8U7SaofwbCOicSHO3l9/lb+Ss4FIDLIxv96NmJE53o4bbVv7j2FKxERERERqbRit5evl6fwwaIdZBWVzirdtE4I/9e7MQNaxmIxDEb3bcr8LZlMWZHK71syWZacy7K9gQrAabNwUZf6XNG9IeFBtTei1N7KRURERESk2pmmyfasIv7YmsUf27JYsiObIrcPgIZRQVxzUmNObx2H1fLPGqE2q4V+LWLp1yKWtLwSpq1KZeqKVFLzSji7fQLXnNSY+PDav16owpWIiIiIyHGuwOVhT74Lt9eHYRhYDLBgYBj4Q9KGPQWlgWprJrtyS8ocXy/CydUnNmZI+3hs/wpV5YkLL933fz0bYZqUCWG1ncKViIiIiEgtlV/iYcOeAtan5bN+Tz7r0wrYmlmI02YhKthOdIidqGA7kcF2ooPtRATZyHd5ScsrYU9+CWl5LtLyS/wTT1SUzWLQuX4EJzapw4lNomlZNxSLcXghyWIYcOzkKkDhSkRERESkVlmyI5sv/9rF2t35JOcUl7tPscdHTrGHbVlFFT5vqMNKkN2KaZr4TPyffaaJzzSJC3NyYpNoejaOpmvDKEIc1qq6pWOGwpUEXHp6OqGhoQQH1541DERERESq29bMQl6eu4W5mzLKbE8Id9IqLoxWdUNpFRdGs5gQPD6T7CK3/yOrsPRzTrGHMIeVuHAncWFO6oY5/F8rLB05havjxG233UhwcAiPPz5hv8emTv2Gt956ja+//g6Hw1Hu8Skpuzj//KF8+eVUEhPrcdppJ/PMMy/RqVPSfvsuXbqY0aOvY968xYesKzMzg4svHs6HH35OcHAwH374LsuX/8Wzz750+Dd5CDfddC0rV/6N3W4vsz02ti6ffjq5zLbPPpvEvHlzeeWVNw94PpfLxbvvvsmsWT+TlZWJ0+mkU6ckrrnmBpo0aVrl9YuIiEjt5zNNNqQV8OeObJbsyCajwEX3RtH0axFDh8TwcrvWZRe6eWvBNr7+OwWvz8RqwPCOiZzSqi4t64YSGWwv50oSCApXx4kRIy7i3nvHkJGRTkxMbJnHpkz5imHDzjtgsCrPzz//ViV1lZSUUFT0T3P15ZdfVSXnPZDLLvsfV1/9fwd8vKioiLfffp3PP/+Yzp27HPRczz8/gR07tvHii6+RmFiPvLw83n33TW666Ro+/fQbwsPDq7p8ERERqWV8psnmjEKWbM9m8Y5slu7M8a8Btc+a3fl8+OcO6oTYOblZDH1bxNCjURQWw+DzZcm8u3A7+SWlY6JOblaH0X2b0SQmpLzLSYApXFUV0wRPxfu0VglbMFRw4GCvXr1JSEhk+vTvuOyyK/3bV65cwebNm3j66RfZunULEye+yMaNG8jOzqZevXpcf/1oevc+eb/z9enTjZdeep0uXbqRnp7OhAmPsWzZUiIjozj11NPL7Dtv3lwmTXqfnTt3UFRUSNu27Rk79n7q1avPZZddAMBll13APfeMY+vWLSxbtsTfYjR37mzef/9tdu7cQUxMDMOHj2DEiIuwWCw89thDOBwO9uzZw7JlS4iKiuaCCy7m/PMvquQTCldeeTFt27Zn2LARbN26+aD7rljxF4MGDSExsR4A4eHh3HjjLRQU5JOZmUF4eDhFRUW89tpLzJo1E4/HTYcOHRkz5h4SEhLJycnm9ddf5fff5+LxeGjf/gRuvvl2GjZs5G8pvPDCS/n++6mcdtpg7rhjLDNn/shHH71HamoK9es35LrrbqJHjxMrfb8iIiJy5FJzi9mUXkhqXjG780rYnVdCam7p57T8Etxes8z+oQ4rSQ0i6dowijohduZvzmT+lkwyC918uzKVb1emEmSzEB5kY0++C4BWdUO5tX8zujeKDsQtSgUpXFUF0yRq8nDsqYfuBleV3IndyR4+uUIBy2KxMHz4CL755itGjrwCY+8xU6Z8xcCBpxEbG8utt15Pnz79ePzxZzBNk9dee4lnn32y3HD1bw8+eA+RkVFMmTKdvLw87r77dv9jaWm7GTfubsaPf5I+ffqSk5PNvffeyfvvv8UDDzzCRx99wfnnD+Wjj74gMbEe77zzhv/YpUsXM27c3TzwwCP06zeATZs2cs89d2CaJhdeeCkA06dP4+mnn+fxxyfw3Xff8vzzT9O//0Dq1o2rzFPKyy+/QVxcPO+88wZbtx5831NPHcR7773F9u3b6Nq1O+3adaBRo8bce++D/n2ee+4ptm7dwjvvfER0dB2eeeYJHnzwXt544z3uu+8urFYr7777MWFhYbz11uvccsv1fPTR5/7jCwsLmTbtJ4qLi1mwYB7PPPMETz75HCec0Ik//vid++67izfeeI9mzZpX6n5FRETk8Lk8PpbtzOH3rZn8viWTrZkHf4PdabPQuX4E3RpG0a1RFG3iw8tMVz6kXTxur4+lO3KYuymDOZsy2J1XQnG+i9hQBzf0acKQdvHH1JTlxyqFq6pymFNPBsJZZw3jnXfeYOnSxXTt2p3c3BxmzZrJq6+WthI9/fQLxMbWxefzkZqaQnh4BHv2pB30nKmpKSxfvoxPP51MSEgoISGhXHXVtdxzzxgAoqPr8NFHX1C/fgMKCwtIS9tNZGQUe/bsOWS9338/lZNP7s8pp5wGQOvWbRg58kq++uozf7hKSupG9+4n7r2/c3jmmSdITt55wHD18ccf8OWXn5bZ9vrr7/nHSMXFxR+yrn2uvHIULVq0YsaM73nllRfIzs4iNrYuF188kgsvvBS3280vv/zEk08+R3x8AgA333w7yck7SE7eyV9/LeWjj77wd9O8/vqb+fnnH1iwYD7t258AwBlnnIndbsdut/P1118wbNgIf3fF3r1Ppnfvk/n226+57ba7Kly3iIiIlCp0eUnJLSY1t4SU3NJWJ4AQh5VQh5Vge+nnkL1fr99TwO9bMlm8PZtij89/HqsBzWJDSYwIIj7cSXy4k4R9nyOcxIY5D7n2k91qoWeTaHo2iWbMwOasTysgObeYXk2iCbZroonaQuGqKhhGaQtSDe4WCBAWFsagQUOYOvUbunbtznffTaVVq9a0bdsegA0b1nP33beTmZlB48ZNiYqKwjTNg55zX/jaFx4A6tdv8E+JNhs//zyDb7+djGEYNGvWnIKCAqzWQ/8nkZWVScuWrctsS0ysR2pqiv/7mJiYMtcC8Pl8HMill15x0DFXh6tPn7706dMXgOTkncyZM4vXX3+F0NBQevXqg8vlIiHhn+cmPDycNm3asXLl3wDUq1ff/5jVaiUuLoGUlBR/uIqNret/PDU1hWXLljBlylf+bV6vl65du1fZ/YiIiByLPD6TdWn5/LUzhxUpuSRnF5OSW0zOf8Y+HY7YUAe9mkRzUtM69GgcRURQ1U0qYRgGrePDaB0fVmXnlOqhcFVVDAPsNX9g4XnnXcjVV48kJyebqVO/YdSo0qCRnr6HcePu5rHHJvjDwuzZvzBnzq8HPV/duqUtPbt2Jftbf9LS/mntmjXrZ77++gtee+0dGjRoCMDzzz/Npk0bD1lrQkIiyck7y2zbtWvnfhNyBMLWrVu46qpLefvtD2nWrAVQGiovueRyVq1awfr16xgyZCgOh4Pdu1Np1KgJUBoYJ036gIsvvgwoDWT7uvR5vV52704lNvaf+zP+FZ7r1o1j0KAzy4yZS01Nxel0HuW7FRERqV2K3V5WpeaxbGcOfyXn8PeuXIrc5b/5Gu60kRDhJDEiiIRwJ4YBRW4vhS4vBa7Sz4V7v48Ld/oDVau6oWX+TouAwtVxp2nTZpxwQmdefvl5SkqK6d//FAAKCwvwer3+taa2bNnMe++9DYDb7T7g+RISEujR40Refvl5HnzwUdzu0unJ98nPz8diseB0OjFNk4ULFzBjxvc0bVoaKPbNUJifn7/fuc888xxuvHEUs2bN3DvmagMff/whQ4cOr5on4wg0btyE1q3bMGHC49x88+00b94S0zRZtmwJS5cu4ZFHnsRisTBo0Jm8886bNG3anPDwCN588zW2bNlEbGwsvXr15sUXn2HcuEf8Y658Pi+9e59MQUHBftccOnQ4L7zwDN26dadt2/asXbuaMWNGc8UVo45oEg8REZHaLr3Axd+7clm+N0it3Z2Px1e2902400an+hEk1Y+kaUxIaZiKcBLm1MthqTr6bToOjRhxAffcM4Zrrrne35WuUaMm3HDDLYwffz/FxcXUrRvP0KHDmTjxRTZt2khkZOQBz/fQQ4/x7LNPMmLE2YSGhjJkyNmsXr0SgDPOOIu///6Lyy67AKvVSqNGTbjggkv4+usvcLvd1KkTQ9++A7juuv9x8823lTlv+/YdePTRp3j33bd44onxREZGMmzYeVx66RVH78mpIMMwmDDhJT744B3Gjx9HenoaFouVli1bMW7cI3Tr1gOAm2++jTffnMg111xBcXExSUldefTRpwB44IHxvPbay1x11UiKiopo374DL774OhERkeWGqwEDTqWoqIjHH3+Y3bt3ExERwQUXXMKIERdW672LiIhUB9M0Sc0rodDlxeX1UeL2UeL14fL4KPH4yC5ysyIll+XJuSTnFO93fN0wB53rR5LUIJKk+pE0iw0pdw0pkapkmIcaVHOcS0/P47/PkNvtIiMjhZiYROz2iq8NJVKd9HsqIiK11bbMQsb/uJ6/d+VWaH8DaB4bSqf6EXSsV/pRPzJI3fakyhgGxMYeeg3TWtVylZGRwQMPPMCiRYuwWq0MHTqUsWPH+ltf/m3y5Mm8+eab7N69m1atWjFmzBi6d9fAfxEREZHq4vWZLNyWRYnHR++mdXDYLAfd32eafLlsFy//toUSjw+rxSDcacNps+C0WXBY9362WQh1WGkdF0bHehGckBhBeFCtelkrx6ha9Vt46623Eh8fz2+//UZ6ejrXX38977//PqNGjSqz3y+//MKDDz7ISy+9RN++ffnll1+45pprmDx5Ms2aNQtQ9SIiIiLHhz35JXy7IpUpK1L905vHhDq4oHM9zu2YSFTI/jPrpeQWM37GOhbvyAGgR6MoHhjUioSIoGqtXeRI1Jpugdu2beP0009n7ty5xMeXzlA3ffp0JkyYwK+/lp3R7rbbbiMoKIgnnnjCv23UqFG0bt2aO++887Cuq26BUlvp91RERKqTzzRZtC2Lr5en8NumDLx7Xz9FBtlw2CzsyXcBpQvqntkunou71KdJTAimaTJ1ZSrPz95MgctLkM3C6H7NOK9TosZISY1xzHUL3LBhA1FRUf5gBdC8eXN27dpFbm4uERER/u1er5eQkLLTolssFjZv3lxt9YqIiIgcD3KL3Xy7IpWvl6eUmViic/0Izu2UyMCWdbEaMHN9Oh8v3snatHwm/53C5L9T6NOsDj7T5PctWQB0qhfBg4Nb0zA6OFC3I3JEak24Kigo8E8Tvs++7wsLC8uEq0GDBjFu3DgGDRpEly5dmD17NgsWLKjyMVe1pNFPjlP6/RQRkaNpa0Yhny1L5vtVuyn2lK4hFeqwclb7eIZ3TKR5bGiZ/Qe3jWNQm7osS87hk8XJzN2UwbzNmQA4rAbX9W7CJV0bYLWotUpqr1oTrkJCQigqKiqzbd/3oaFl//GeeeaZZGZm8sADD5CTk0O/fv0466yz9ju+siyW0sGYXq8H0AKuUjO5XKV93K3WWvPPXEREqplpmuzOK2FTRiGb0wvYlllERJCNZrEhNIsJpWlMCMF2a5n9F27L4tOlyf7WJoCWdUO5MKkep7eJK7P/fxmGQZcGUXRpEMWOrCI+X5ZMSm4JN/Rpsl8YE6mNas2rrpYtW5KdnU16ejqxsbEAbNq0iYSEBMLDy/Z/3LNnDyeffDKXXXaZf9sFF1zA6aefXiW1WCxW7PYg8vOzsVqtGMbBZ74RqU6maeJylZCfn0VwcJj/zQARETk+TF2Ryuu/b8U0ITLYRmSQnYggG5HBdiKD7IQ6rOzKKWZzRgGbMwopcHkPeC4DSIwMollMCI2ig1mwNYstGYX+x05uHsPFXerTtWHkYU973jA6mDEDWxzBnYrUPLUmXDVp0oSuXbvy+OOPM378eLKyspg4cSIjRozYb98///yTJ554gs8++4zY2Fg+/fRTtmzZwvDhw6ukFsMwiIysQ0ZGKpmZu6vknCJVLTg4jIiIOoEuQ0REqtHXy3fx5MyN/u/TC1yHPMZqMWgcHUyzmFCa1Akmt9jjD16ZhW525RSz619jqULsVs7uEM+FSfU1NkrkP2rNbIEA6enpjB8/noULF2KxWBg2bBhjxozBarWSlJTEww8/zNChQwF45ZVX+OyzzygsLKR9+/bcc889tGvXrhLX3H+2wH1M08TjcR/JLYkcFVarTS1WIiLHmS+W7WLCrNJgdXGX+gxpF0dOkYecYjc5xR5yitzkFnvIK/GQEO6kWWyov0XKbi3/b0Z2oZtNe4PWtsxC6kcFc3b7eMKcteb9eZEqUdHZAmtVuAqEg4UrERERkZrg86XJPPPrJgBGdmvA6L5ND7ubnogc2DE3FbuIiIiI7O/Tpck8tzdYXd69ITed3ETBSiRAFK5EREREAmR9Wj4rU3LxmWDC3t4ypv97p81Cm7gwWtYNLbfr3idLdvL87NJ1PK/s0ZAb+ihYiQSSwpWIiIhINVuzO4+3ft/Gb3vXeToUh9WgdVw4HRJLP9olhPPrhnRemrsFgKtObMR1JzVWsBIJMI25OgSNuRIREZGq8t9QZTGge6MoQhw2DErHdRgYez9DbrGH1bvzyC32HPCco05sxLUKViJHlcZciYiIiFShlNxiUnNL8Ph8eHwmHq+Jx2fi9pZ+77RZiAyyl1lbKmjvgrrlhapBbeK46sRGNKkTctDrmqbJ9qwiVqXmsSolj5WpeaxPy8fjM7m2V2OuOanxUb93EakYtVwdglquREREjm8uj483ft/KR3/u5HBfEjhtFiKCbOzJL11v6nBC1cGUeHxkF7mJD3dW+hwiUnFquRIRERE5QpvSC3hg+lo27CkAoGFUEHarBZvFwLbv896PEo+PnOLStaRyitx4zdIQtCffVWWhah+nzaJgJVIDKVyJiIiI/IfPNPlsaTKv/rYFl9ckKtjOfae1pH/L2Aodb5omBS5v6QK+RR7qhNhJiAg6ylWLSKApXImIiIj8y+68Eh6esY4/t2cD0KdZHe47vRWxoY4Kn8MwDMKcNsKcNupHHqVCRaTGUbgSERGRY4rPNNmZXUyY00p0sL1Cs+j5TJOMAheLtmXz7K+byCvxEGSzcFv/ZgzvmKiZ+ESkQhSuRERE5JiRmlvMuB/WsWxnDlA6Nikh3EliRBAJEU7qRQYRE+ogq9DNrpxiduUWsyunmNTcYlzef6araJcQzvgzWtO4CsZHicjxQ7MFHoJmCxQREakdflqbxhMzN5Bf4sVqMfD5zMOa3c9qQHy4k7M6JPC/Hg2xWS1HrVYRqV00W6CIiIgcF/JLPDwzayPfr04DoENiOOPPaENChJPdeSWk5BaTkrP3c14JGfkuokPs1IsMol5EEPUig0iMdBIf5lSgEpEjonAlIiIiNYrPNNmVU8yGPQXkFXtoFhtC89hQgvcuyPtvf+/KZdz0tSTnFGMx4H89GzHqxEb+kNQgKpgGUcHVfQsicpxSuBIREZGAKXR5WZuWx8Y9BWzYU8Cm9AI2phdQ5PaV2c8AGkQF0aJuGC3rhtIyNpQNewp4549teE1IjHAy/ow2dG6gqflEJHA05uoQNOZKRESkauUVe/htcwaz1qfzx7YsSjy+/fZxWA2axYQSEWRjU0YhGQWuA55vcNs4xp7SgjCn3jMWkaNDY65ERESkxsgudDNnUzqzNqSzaFs2Ht8/71zGhTloHVfaItU8NpSWdcNoGB2MzfLP9OeZhS427ilt1dqwp4CNewoocnu5ulcjzmgbH4hbEhHZj1quDkEtVyIiIpWXXeTmiZ83MGdjOv+a6ZymMSEMbBnLwJaxtKwbqnWkRKRGU8uViIiIBNS6tHzu+nYVu3JLAGgdF+YPVE1itH6UiBx7FK5ERESkyv2wZjeP/bSBEo+P+pFBPHV2O1rHhwW6LBGRo0rhSkRERKqMx2fy0pzNfLo0GYCTmkbzyJA2RATZA1yZiMjRp3AlIiIiVSKz0MW9361hyY4cAK7q2ZBrT2qC1aLxVCJyfFC4EhEROcZ4fSY7s4toFB18WBNFuDw+Fu/IxgTCnba9H1bCnDacNkuZc/lMkxKPj2K3l2KPj53ZRTw8Yz2780oIsVt58IzWDGwZexTuTkSk5lK4EhEROYak5hZz73drWZGSS6PoYM7rlMhZ7eMP2i0vLa+Er/9O4ZvlKWQVucvdx241CHPY8JkmxR5fuWtTATSKDmbCOe1oFhNaJfcjIlKbaCr2Q9BU7CIiEigen4nL4yPEYa3Q/vM2Z/DQD+vIKfaU2e60WTitdV1GdEqkXUI4hmFgmiZ/78rl82W7mLUhHe/edafqhjmICXGQV+Ihv8RDXokH3yH+DjptFoJsFk5sEs3dp7bUYr4icsyp6FTsCleHoHAlIiKBUOT2cuOXf7N6dz6D29RlZLeGtKhbfmuQx+vjtflb+fDPnQC0jQ/jgUGt+HtXLl8vT2HDngL/vm3iwujXIoY5GzNYm5bv357UIJILk+rRr0VsmcV7TdOk0O0lr9hDfokXiwWCbFaC7BaCbFacNovGVInIMU/hqoooXImISHXzmSZ3T1vDrxvSy2w/qWk0l3dvSJcGkf7xT6m5xdz//VqW78oF4MKkeozu2wyHzQLgb6H6enkKM9fvwf2vlXydNguD28RxQVI9WsVpmnQRkQNRuKoiClciIlLdJs7bwnsLd2C3Gow9pQULtmbx64Z0f/e8dgnhXNatAU6bhYdnlHYDDHVYGTeoFQNb1T3gebML3UxblcqSHTkkNYjknBMSiArWFOkiIoeicFVFFK5ERORI7Mop5v7v1xBst3Lf6a2oFxl00P2nr97Ngz+sA+Chwa05s308ADuyivh4yU6+W7V7v8kk2sSF8cTZbWkQFXx0bkJE5DincFVFFK5ERKSy1qflM3rySjIKXEDp9ObjBrWi/wGmKF+enMP1X/6N22tyRY+G3HRy0/32ySx08cWyXXz11y5yij2c37ket/b7pxugiIhUPYWrKqJwJSIilbF4ezZjvl1FgctL89gQgu1WVqbkAfuPi4LSFq4rP15GVpGb/i1ieGpoOywHWaOqyO0lo8Cl1ioRkWqgcFVFFK5ERORwzVy3h3E/rMXtNUlqEMmz57Qn2G7h1XlbmbT4nxn9Hj+rtCtffomHqz/9i80ZhbSOC+OtizoRbK/Y9OsiInL0KVxVEYUrERE5HF8sS+aZWZswgQEtY3lkSBuc/2qh+vdaVKEOK/ee1pLpq9OYvyWT2FAH71+aRHy4M3A3ICIi+1G4qiIKVyIiUhGmafLa/K28t3AHACM6JTJmYIty14D67/TpUDot+hsXdqJ9wqH/eIuISPVSuKoiClciIgKla0/N25xJSk4xHp+J2+vD4zP9H5vTC/htcyYA1/duwv96NvSvRVUej8/kjflbeX9RaRh74qy2nNr6wNOoi4hI4ChcVRGFKxERMU2TZ3/dxOfLdh10P6sB95zWknNOSKzwuVen5lHi8ZHUIPJIyxQRkaOkouHKVg21iIiI1GqTFu/0B6v+LWIIsluxWQzsVgObxeL/um/zGDrVP7yQ1E7dAEVEjhkKVyIiIgcxY00aL83dAsCt/ZpxabcGAa5IRERqKq04KCIicgCLtmXx8Ix1AFzStb6ClYiIHJTClYiISDnWp+Vz19TVeHwmp7aqyy39mgW6JBERqeEUrkRERP4jJbeYWyavpMDlpWvDSB4+ozWWg8z8JyIiAgpXIiIiZeQUuRn99QrSC1w0jw1hwtD2OGz6cykiIoemvxYiInLMcXt9JOcU4TvMtTRScou5Y8oqtmYWERfm4MVzTyA8SHM/iYhIxegvhoiIHDOyCl1M/juFr/5KIb3ARZ0QO72a1uGkJtGc2CSaiCB7mf1N02RzRiGzN6bz64YM1qXlAxDutPHSeScQH+4MxG2IiEgtpUWED0GLCIuI1Hwb9uTz2dJkZqxJw+Ut/z9tiwEnJEbQu1kd2sSHsXh7DrM3prM9q6jMPp3qR3JL36a0T4yorvJFRKSGq+giwgpXh6BwJSJSM3l8JvM3Z/LZ0p0s3pHj3942PoyLu9anX/NYVqfmMX9LJr9vyWRzRmG557FbDXo2jqZ/ixj6No8hOsRRXbcgIiK1hMJVFVG4EhEJLNM0Sct3sTG9gM3pBWxML2DjngK2Zhb6W6msBgxoGctFXerTsV4ERjkz+6XmFvP7lkx+35LFhj35tE+MYEDLWE5qGk2oQ73kRUTkwBSuqojClYhIYOQVe3hxzmZ+3ZhObrGn3H0ig2ycc0IC53euR0JEUDVXKCIix4uKhiu9VSciIjXOom1ZPDxjHWn5LqC0ZapRdAjNY0NpUTeE5jGhtKgbSr3IIK0/JSIiNYbClYiIHFW7cor5bVMGoU4r/VvEEuY88J+eYreXV37bwufLdgHQMCqIu09tSaf6kTi11pSIiNRw6hZ4COoWKCJy+FJzi5m5Pp2Z6/awKjXPv91ps9C/RQxnto+ne6NobJZ/Wp3W7M5j3PS1bM0snb3vvE6J3NKvGcF2a7XXLyIi8m8ac1VFFK5ERComLa+Emev3MHPdHlak/BOoLAYkNYgkPd/Ftn9Nex4b6mBQmzjOaBvHb5szePuP7Xh9JjGhDh4Y1IreTesE4jZERET2c0yGq4yMDB544AEWLVqE1Wpl6NChjB07Fptt/y4mH3zwAR988AHZ2dnUr1+fm266iUGDBh32NRWuREQOzjRNvvwrhednb8LjK/0P0wC6NIzk1FZ1GdAylphQB6Zpsnp3PtNX7ebHtWnklDNJxSmtYrn7lJZEhdj3e0xERCRQjslwddlllxEfH88jjzxCeno6119/PcOGDWPUqFFl9pszZw733HMPkyZNolmzZvz444/ceuut/PzzzzRo0OCwrqlwJSJyYMVuL0/O3MD3q9MAOCExnMFt4xjYMpbYMOcBj3N7ffy+JZPvV6fx26YMguwW7hzYgjPaxpU7jbqIiEggHXOzBW7bto1FixYxd+5cgoODadiwITfccAMTJkzYL1xt3rwZ0zT9H1arFbvdXm4Ll4iIVE5yThF3fbua9XsKsBpwc99mXNK1foXCkd1qoV+LWPq1iCW/pLQF62ATXYiIiNQGteYv2YYNG4iKiiI+Pt6/rXnz5uzatYvc3FwiIiL8288880wmT57MkCFDsFqtGIbBhAkTSEhICETpIiLHnAVbM7n/+7XkFnuIDrbzxNlt6dowqlLnUqgSEZFjRa35i1ZQUEBwcHCZbfu+LywsLBOu3G43bdq04bHHHqNNmzZMmzaN++67j+bNm9O6detqrVtE5FjiM03eX7iD1+dvxQTaJ4Tz1NB2xIcfuAugiIjI8aLWLBoSEhJCUVFRmW37vg8NDS2z/ZFHHqFly5Z07NgRh8PBeeedR+fOnfnmm2+qrV4RkWNNXrGHu75dzWt7g9W5HRN588JOClYiIiJ71Zpw1bJlS7Kzs0lPT/dv27RpEwkJCYSHlx1ctmvXLlwuV5ltNpsNu12zT4mIVMbSndlc8uES5mzKwGE1uP/0ltxzWkscWthXRETEr9b8VWzSpAldu3bl8ccfJz8/nx07djBx4kRGjBix374DBw5k0qRJrFq1Cp/Px4wZM1i4cCFDhgwJQOUiIrWXx+vjtXlbuP6Lv0nNK6FhVBBvXdSZc05IDHRpIiIiNU6tmoo9PT2d8ePHs3DhQiwWC8OGDWPMmDFYrVaSkpJ4+OGHGTp0KB6Ph9dee41vvvmGnJwcGjduzG233cbJJ59ciWtqKnYROT7tzC7igelrWbl3QeCz28czZmALQhzWAFcmIiJSvY7Jda4CQeFKRI43pmny/erdTPhlE4VuL+FOG/ee1pJTW9cNdGkiIiIBccytcyUiIoenwOUhu8hNbrGH3CIPOcVucoo95Ba7yS/xYjHAajGwGAZWi4F17+fVqXnM2lA6vjWpQSTjz2hNQkRQgO9GRESk5lO4EhE5xuzJL+Hxnzcwb3Nmpc9htRj830mNubx7Q6yWQy8KLCIiIgpXIiLHDNM0mbE2jWdmbSK32AOA02YhMshGRJCdiCAbkcGln0P3jpvy+kx8Zulnr8/Ea5rYLAbDOibSPuHQ3R9ERETkHwpXIiLHgMxCF0/8vIHZGzMAaBsfxrjBrWkRG3qII0VERKSqKFyJiNRys9bv4YmZG8kucmO1GIw6sRFX9miIzVprVtsQERE5JihciYjUUjlFbibM2siPa/cA0CI2lIcGt6Z1fFiAKxMRETk+KVyJiNRCG/bkc8eUVaTklmAx4IoeDRl1YmMcNrVWiYiIBIrClYhILfPrhnQe/GEtRW4fDaKCeGRIGzokRgS6LBERkeOewpWISC1hmibv/LGdN37fBkCPRlE8flZbIoPtAa5MREREQOFKRKRWKHJ7GT9jHTPXly7ue2FSPW7t3xyb1qASERGpMRSuRERquNTcYsZ8u5p1afnYLAZjT2nBsI6JgS5LRERE/kPhSkSkBluenMNdU1eTWegmOtjO00Pb0blBZKDLEhERkXIoXImI1FDTV+/m0Z/W4/aatKwbynPD2pMQERToskREROQAFK5ERGoYn2ny2rytvL9oBwADWsby8BmtCbZbA1yZiIiIHIzClYhIDVLk9jJu+lpmb8wA4H89G3Jd7yZYDE1cISIiUtMpXImI1BC780q4Y8oq1qXlY7ca3H96K4a0iw90WSIiIlJBClciIjXAqtQ8xkxZRXqBi+hgOxPOaUen+pq4QkREpDZRuBIRCbCf1qYx/sf1lHh8NI8N4fnhHUjUxBUiIiK1jsKViEiAZBe5eWbWRn5cuweAPs3q8OiZbQh16L9mERGR2kh/wUVEAmDW+j089ctGMgvdWAy4okdD/u+kJlgtmrhCRESktlK4EhGpRpmFLib8spGZ69MBaBYTwrjBrWmfEB7gykRERORIKVyJiFQD0zT5ae0eJszaSE6xB6sBV/RsxNU9G+GwWQJdnoiIiFQBhSsRkSqQUeDi0Z/Wk13kxmIYWA2wWIy9XxvkuzysTMkDoGXdUB4c1JrW8WEBrlpERESqksKViMgRMk2Tx35az7zNmQfdz2YxuOrERlzZoyF2q1qrREREjjUKVyIiR+j71bv5bXMmdqvBfae1IsRhxWeaeH0mPhN8ponPNOlYL5JG0cGBLldERESOEoUrEZEjsDuvhGd/3QTAtb0ac2b7+ABXJCIiIoGifikiIpVkmiaP/rie/BIvHRLDGdm9YaBLEhERkQBSuBIRqaRv/k7hj21ZOG0WHhzcGpvWqBIRETmuKVyJiFRCck4RL8zZDMANfZrQpE5IgCsSERGRQFO4EhE5TD7TZPyM9RS5fSQ1iOSiLvUDXZKIiIjUAApXIiKH6Ytlu1i6M4dgu4Vxg1phMdQdUERERBSuREQOy7bMQl75bQsAo/s2o0GUplYXERGRUgpXIiIV5PH6eHjGeko8Pno0iuK8TomBLklERERqEK1zJSJyED7TZMWuXH5Yk8bMdXvIKfYQ6rDywKBWGOoOKCIiIv+icCUiUo6N6QX8uCaNH9emkZJb4t9eJ8TOvae1IiEiKIDViYiISE2kcCUiQmmXv79Tcvljaxa/bcpkY3qB/7FQh5X+LWM5o00cXRtFaT0rERERKZfClYgct3ZmF/HH1iz+2JrF4h3ZFLi8/sdsFoM+zeowqE0cfZrVIchuDWClIiIiUhsoXInIcWfhtiye/mUj27OKymyPCrbTs3EUJzaJpm/zGCKC7AGqUERERGojhSsROa7kFXt44Pu1ZBW5sVoMOtaLoFeTaE5sEk3ruDCtWSUiIiKVpnAlIseVNxdsI6vITZM6wbx3SRJhTv03KCIiIlVD61yJyHFjU3oBXy5LBmDMgBYKViIiIlKlFK5E5LhgmibP/LoJrwn9W8TQs0l0oEsSERGRY4zClYgcF2ZtSGfx9mycNgu39m8W6HJERETkGKRwJSLHvGK3lxdmbwbgsm4NqB8ZHOCKRERE5FikcCUix7wPFu0gNa+EhHAnV/RoGOhyREREZB/TDHQFVUrhSkSOack5RXz45w4Abu3fTIsBi4iI1AQ+L2Fz76PORydhS/s70NVUGYUrETmmvTB7My6vSbdGUQxsGRvockRERMTnJfyX2whe8QHWvB2Ez7odvO5AV1UlFK5E5Ji1cGsWszdmYDVgzIDmGFogWEREJLB8HsJn3kLQ+smYFhs+Rzi2jLUEL38z0JVVCYUrETkmebw+nvl1IwDnJ9WneWxogCsSERE5zu0LVhumYFps5A56jfw+DwMQ+ufzWHK2BbjAI6dwJSLHpE+WJLM1s4joYDvX9moc6HJERESOb1434T/dRNCGbzEtdnIHvYGr2RmUtDkfV/2TMDzFhM+5t9ZPcKFwJSLHnGkrU3nlty0A3HRyU8KDbAGuSERE5DjmdRPx840EbfquNFgNfhNXs0GljxkG+f2fxLQ6ceyYg3PDlICWeqT0ikNEjilTV6by6I/rMYHzOiVydof4QJckR8C+fQ7W3O0Ut78UDL0fKHI02VKXED77HrxRTSjsdC2exG6BLqn6mCa29JXYt8/B4srHtNjAYvN/3ve1u2FfvFGHsRC9aRI25x5se1ZQmHQ9ruZnQg0e/2vfOR9fSF28dVod3oGmCT5P6f/ThqXsPXpdRPx0A87NMzAtDnLPeBNXk1PLHO6NakZh15sJXfQMYfMewtWoP2ZQdBXcUfUzTLOWt70dZenpebW9dVLkuPHvYDWiUyJ3ndJCk1jUYvbtc4j87jIM00d+73EUdb420CWJHLOcG74l/JfbMbwl/m3uhK4Udr4WV9PBYDkGl7HwFOHYOR/H1pk4ts7EWpB6yENMWxBZ503FG9uuQpcI/utNwuaP93/vjutMwUn34a7fq9JlHy3Bf71F2PyHMQ0LRR2uoLDnnZjOiIMfZJo4ts4k9I8nsWWuK/uQYQGj9PfG8Ln3Bqu3cDU5pfxzeV1Efz4IW9YGitpeRP7AZ6ritqqMYUBsbPih96tN4SojI4MHHniARYsWYbVaGTp0KGPHjsVmK9sAN2rUKJYsWVJmW2FhIRdeeCHjx4/ncChcidQOU1ek8uhPpcHq/M71uHOgZgeszSw524j+cgiWkhwATIuDrPO/q/ALGhGpINMkZPELhC56FoCSJqfhC44haN1kDJ8LAG9EYwo7XU1xmwvBUcsnB/IUEbR+Co4tP+HY+RuGp9j/kGkLxtWwL97wBhg+T2lLjM+DYZZ+tmWsxZa5Dm9EY7LO/+6QLSu21CVEfXMehs9DSbPBOLbPxfAUAlDS+BQKet2NN6btUb3dinKum0zEzNFltvmC65Lf+wFKWg0vt7XNlvY3ob8/giN5wSHP77OHkTvoNdyNBxx0P9uuRUR/cy4A2cO/wl3vxMO4i6PrmAxXl112GfHx8TzyyCOkp6dz/fXXM2zYMEaNGnXQ47766iteeeUVvvjiC+Li4g7rmgpXIjXfv4PVBZ3rMUbBqnZzFxL99TnYMtbgjuuMLyQW59aZeOq0Juv878AWXLHzmD51JZTjh9eNNWsD9rS/se1ZgSVvB+4GfShuc/6BQ4CnmPBf7yRo/TcAFHb+Pwp63QsWK0ZBGsErPyB4xQdYSrIB8DkjKW53CUXtR+KLrGUTBXndBK39gpA/ny/TQuUNq4eryWmUNDm1tDXJFnTAUxjFWUR/MQRr3g5cjfqTc+YHB2zRM4qziP58MNb8ZIpbnE3e6RMxCvcQuvgFglZ9jGF6MTEoaXM+BT3uwBdev8pvuaLs2+cQ+f0VGD4PhZ1G4Wp8KmFz78OWvQkAV/1e5Pd9HG+dlgBY8nYRuvApgtZ9DYBpdVLUaRRFHa/CtDpKuwiaXgzTV/r/sGniC4oCe0iF6gn7dSzBqz/GE9WcrIt+AqvzqNz34TrmwtW2bds4/fTTmTt3LvHxpWMopk+fzoQJE/j1118PeNzmzZsZPnw477zzDt26HX7fYYUrkZrt2xUpPPrTBgAuTKrHHTV0PSv7roV4Q+PxRTYJdCk1m2kS/nPpbFK+4FiyLpiOaXVS59NTsRTtobDjVRScfIgeCF43YXPuIWj9N5S0HEph0vWHP35ApCYzfVgz12PfvRRb2gpse/7GlrG2TJc+/65WJyUtzqKo/Ug8Cd38LRBGUQaR06/GnroY02Ijv+9jpWMb/8tdSNDaLwle/ha2nK3+za5G/Shqf1np2BlL+UP4Lbk7ceyYjWP7HCwFqZiOcEx7KKYjHJ8jDNMehukIwxvZGFezMw7rzRBL7nYcW3/BG9UMd2IPsB/gTRfTh3PjNEIWPoMtp3SiI29YPYrbj6SkyamlLUeH8TfDtmclUV+fg+EtoaDraApPvKuca5pETP9f6ZtCkU3IvuAHTMc/L8qt2ZsJ/eMpnJu+92/zBdXBG9EQb0QjfOEN8EY0whvREF9ofGkrmqcYw1Nc+jP2f136eb/vvSVg+nA1PxNX44EHv5/dfxE15QIMTyHFLc8h77SXS38O3hJClr1JyOIXMLwlmBY7RZ2vxTQshPz1pv93rbjVcAp6jsUX0aDCz+GhGMXZ1PlkAJaiPRR0v53CHrdX2bmPxDEXrmbOnMl9993HwoUL/dvWrVvH0KFD+fPPP4mIKL9P6BVXXEGTJk14+OGHK3VdhSuRmmlXTjHfrUrlrQXbgZodrKwZa6nz2amYVif5Jz9McbtLa/SA5kAKXvYGYb8/gmmxkXPO57jr9QTAsW0Wkd9dDkD22ZNwN+pf/gncRUT8eB3Obb+U2VzSdBCFXW7Ak9D1aJYvclQYrjxsu5dhT1mMPXUJtt1Lsbjy9tvP54jAU7cDnron4Aupi3P9N9jTV/kf99RpTVGHy/DU7UjEzzdhzd2OzxFB7uA3cTfsc/AifF4cW2cSvOoj7NvnYFD64sgbGk9x24spbn8JPmc0jl0LsG8vDVT7Wj4qwpXYk7xTnj30G1CmSdDqjwmbN97fxc60OHAndMHdoA+uBr3xxHUGiw3HtlmELHza/xz4gmMo7HozRe1HHrSF6lCc674mYuYtAOSc8TauZoPLPO7/f8zqJPu8b/HU7VDueWypSwn944kKdaurrJJGAyjo8yDe6Bb7PWbN3kzU18OwFGfianAyOWd9AFZHmX0sudsJ++1BnFt/LrPdVa8nBb3H4YnrdFTqdm6YSsRPN5R2Cb945uFNInKUHHPh6ttvv+X5559n9uzZ/m3bt2/ntNNOY86cOSQkJOx3zOLFixk1ahQ///wzdevWrdR1Fa5EagbTNNmcUcivG9KZvTGDdWn5/sdqcrACCF7yCmF/POn/vrjlOaXTzjoO/Z/08cS+4zcip12KYfrI6/soxSdcWebxsLn3E7zifbwhcWRd9DNmcEyZx43ibCKn/w97yp+lQfak+3Ekz8e5eYZ/H1f9XhR2uRF3w34KuHLUWQp2Y0tbji1tOYbPizvuBDxxnfGF1Tvw759pYsndhj11MfaUJdhTF2PNWOsPM/7dbCG44zvjieuIp25H3HVPKO2q9+/WH9PElvYXQSsnEbTx2zLji6B0LFXOWR+U+8L7oPeVs43g1Z8QtOYzLEUZpZcyLGCxl2k9Mw0rnoQuuBr2wxPTGsNdiOHKx3Dnl3525WNx5eLYPAOLuwDTFkJ+7wcobj+y3OfHKEgj/Nc7/W+eeGLaYZRkYc1PKbOfzx6KL6wetqzSXg0+RzhFnf+Pok6jMB1hh3WvBxL624OE/P0OPnsY2ed/538O/z3OKq/fExR3uOyQ5zJKcrHk7sCatx1r7k4sudux5u3AmrsDS+Ge0q52ViemLaj0wxoE+762Bf3zmHXv97YgLIW7CVr1yd6JJGwUnXAlhd1uxQyKAkp/N6O+HoY1bwfuuh3JGfbFQZ8bx5afCJv3MKbVQcGJd+NqevrR/T/UNIn4/gqc22aRe9rLpeO+Aqzaw5XP52Pt2rWkpKSQn5/POeecA8COHTto2LDhEZ//559/5v777y+35Wrx4sWEh+9/s3feeSc2m40nnnii0tdVuBIJrB1ZRUxZkcrsjelszyryb7cYkNQgkjPaxjG0Q0KNDVYAkVPOx5G8AFf9k7DvWohhevFENiV30Ot467YPdHkVZ5rYdi8Dw4I3qimmM7LKTm3J3VE6gUVxFsVtLiBv4LP7/+H2FBH9xZnYstZT0nQQuWe87d/HUpBK5NRLsWWuw+eMJGfIe3jq9QDAmrmB4GWvE7T+69LuNYA7tgMFve7B3ahfld3Dcc3rxp76J5bCjAPu4oluXq0TkhiuvCp/A8NSkIpRnAXsm266dMpp07AABtbcbdh3L8eW9he2tOUHnH3OFxyLO64Tnr0fPkc49tTSIGVPXYKlKH2/Y7wRjXAndMWd0A1PQlc8MW0O2B2vPEZJDs51XxO8chK2rPW4E3uQc8bbmMF1KvlsAF4Xzs0zCFr1kb/1xRtWH1ejfrga9cPdoE+F/p+w5G4n/Jfbcez6AwBXw77kDXgGX3g9/z6OTd8TPvtuLMVZmFYnBSeOpajTKMDAmrMF+8752HfOx5E8H0txFrB3LFDH/1HY5caqn9bb6yZy6sU4dv2BJ6o52ed/Bz4P0Z8Pwpq/i+IWQ8k7/dWAvoljzd5M6PxHcW79CQBfUDQFPe+ipMVZRE25AFvGmtJui+dOwQyJPfQJTbN678dThGPn77ga9Tus3/WjpdrCVXZ2NhMnTmTy5MkUFBT4t69ZswaAc845B4/Hw3333cdJJ51U6ets3bqVQYMGMX/+fGJjS38Bpk+fzlNPPcWcOXP229/j8dCjRw9effVVevWq/HSXClcigZNR4GLEe3+SX+IFwG416Nk4mgEtYjm5eR2iQxyHOEMN4Cog9p0OGD43GZf+hqUog4ifbsCav6u0daXPw3vXcKq54RBKX6iGz7wV55Yf/dt8QdF4I5uU+XA17IsZcpg9BdxFRE0ehj19Fe64TmQP//qAXXase1YR/dVZGD43ef2forj9pVizNxM59RKseTvxhsSTc/ZH5b6It+TtInj5mwSv+hjDUxrUS5oOIr/Pg/giGh1ezQKuAhw7ZuPcPAPHtln+mR0PekiDkynsehPu+icdtd95S0EqYbPvwbn1Z4pbDiO/7yNH/MLalrqEkGWv4dj8434tSAdjGha80S1x7+2mZktbji1jDYbpPfhxFgeeuBNwJ3TDndAFT0I3fKFVtGafaWLJ2Vr6O1+F06tbcrdj+Dx4I5tW7mdr+gj++11CFzyB4S3B5wgnv8/DuJoNIuy3cf7JE9yx7ck79UW8MW0OeB5r+hpsmetw1++FLyzxCO7q4IzCPUR/cQbWglRKmg4qHd+19edyx1kFkn3HXMJ+ewhb1nqgdDp5w1OML7guWedNqX2TkwRItYSrTZs2MWrUKFJTU/n3aQzD8Ier7t27k5+fj2EYPPLII5x33nmVvRyXXHIJCQkJjB8/nqysLK6//noGDRrEzTffvN++q1at4oILLmDp0qU4nZWfZUThSiRwnv5lI1/+tYsmdYK5pldjTmpahzBn4N+9OhyOrTOJ/P5KvBGNybxsPlA6i1T4zFv9XVtqejdBa+Z6In4YhS17M6bFgS8oGmvh7nL39dlDKex+G0Udr9qv7355jMI9hM++G+eWH/EFx5B1/g9l3q0uT/Cy1wn7/VFMWzB5A58l7LcHsBRl4IlsQs7QTw4ZlIziLEIWv0jw3++VzthldVLY5UYKu1x/8JkITR+W/NTSF7nH4Jo/hiufoJUfErT2S7DY8YbXwxdWD19oIt7wxNKvg2Oxpy7FsWUGjh2/lekC5guOxRPdHCinO5fpxZa61B8q3PFdKOx6c+l6N1U1o6Np4lz7BWHzHsbiyi1TV16/x0oXbz2s8/lwbJtF8NLXcKT802vGFxwLmODzln7eOyOaYfrwhcSVtkjFd8YT1wl3bIf9py73FGFLX41991//dBl05+OJT9obprqVjtE5gjFBtZk1axPhv9yGffdSoLT7o+EpxDQspf9Ou99Wof9bqott9zKiJp/nn7b+UOOsAsbnIWjVJEIXPoOlJBufPYyc4V/VvDprsKMeroqKijjrrLNITk4mPDyckSNHcsIJJ3DDDTeUCVevv/467733Hjk5OTgcDr799luaNm1amUuSnp7O+PHjWbhwIRaLhWHDhjFmzBisVitJSUk8/PDDDB06FIAZM2Ywfvx4fv/990pd659rKlyJBMKOrCLOf38xXp/Ja+d3pFujqECXVCn7xgkVtb+M/P7/6qJs+gj+601C/3gSw+fB54zC1ag/rian1KiV6R0bvyPil9sxPIV4wxLJHfwmnvgkcBVgzd2GNWcL1pytWHO2Yt+9DFvGWgA80S3IP3k87oZ9yz2vUZhOyLLXCF75AYanuHQCi6GfVmxhTdNH5LcX40ie79/kju1AztmTKta1ZS9rxlrCfhuHI7n074Q3vCH5fcaVLphqGOB1YduzAvuuhdhTFmFP+RNLSQ6e6FbkDpp44HfOaxmjOIvgv98j+O93KtT69G/eiMaUNBtMSbPBeOK7HDR0WnJ3EPLX6wSt/swfyjwxbSjschMlLc46om4/lrxdhM++C8f22QC44zpR1Pk6Qv583v9ufXHzs8jv++ihf0e8LpwbviVk2ev+RVFNi53i1udS1Pk6/3TUchT5PAQve53QRc9h+Fx4IxqTe+qLeBIPf9bn6hC0+lPCf70ToMLjrALFKM4iaO2XuOr3rl3d0muAox6u3nrrLZ599lni4uL4/PPPSUxMpLCwkC5dupQJV1A68cTll1/O7t27ufjiixk3blxlLhkQClcigXHfd2v4ad0eejWJ5qXzTgh0OZUW/XFfbNmby51RCkq7G0X8dBPWvB3+baZhwRPfBVfjUyhpcsphTxVcJXweQhc8QchfbwDgqt+b3EET95tEogzTh3PtV4QteMw/yL2k+RDyTxrnn6bXKMok5K/XS1uN9nbNc8cnUdDr3ooFq70s+buI/uw0LCU5uOqfRO6QdyrX8meaODd+R+jv4/2D4l1767DvXrbfBAD+w6pq5kfTLF2o1GKr9p+xUZhOyPI3CVrxARZ3abd+T1QzipJuwBdSF0t+Cpb8XVgLUrDk7dr79W48Uc1wNRtMSbNBeOu0Oey6jYI0Qv5+m6AVH2Jxl05M4w2Jx5PYFXdc59IWnLodK7ZYrWkStPoTQuc/gsWdXzoWp8cdFHW+tvQ59ZYQ8ueLhCx9FcP04guqQ37fRylpcfY/U5KX5GLbswJb2nLsacux71qEpWgPULrwaXGHkRR1vPqodi+T8lkzN2DftZDiVsNr/OLFzrVfYniKDzgZh9R+Rz1cnX/++axcuZJHH33U39XvQOEKYMqUKdx99900adKEGTNmlHfKGknhSqT6rd2dx2WTlgEw6bIutI6rmtmdqpsldwcxH/XCNKxkXL0C01n+khH4PNhTl+DYNgvHtl/8rT/7mBb7gbtOmSaw98P857OBiYlR+gLTYis9x78/24NLx0lFt8AT3RJvdAu80S0wnZEYhelE/HSDv0WnMOl6Ck4cW+GWBaMkh5BFzxG84v3Sbne2IAq73AReV2nryN4X8u64ThT2uANXowGVejFiTV+NPWURxW0vOvIuVO5CQpa8Qsiy1/3de6B07Rl3Ynfc9XriTuyBLyyB8Flj/C0kxc3PIn/AUwcetO8twbnpB4LWfIY1dzt4SzC8bvC6MHxufwuON6IReQOfKR2LVAVsaX+Xvtgzvf6fORY7psUGVjuWgt0Erf3CHx49MW0p7DqakuZDqq3Lo1GcXbpI7fK3/RMQ7GMaFrx1WuOO74y3TmtMo/yanFt+wrHzNwDcCV3JG/hsuTPf2fasIPyX27FllL42KWlyKqYjorRbXjnThXtD4inqdDXF7Uce+N+tiBxXjnq42jeWavbs2f5FfQ8WrlJSUhgwYABOp5Ply5dX5pIBoXAlUv1u+upvFm7LZnDbOB4ZUnu7XgWtmkT47LtxJ/Yg+9zJFT7OkpeMY9uvOLb9gmPnPH8LT3XwhsRh+DxYijPx2UPJO+W5wx+rspc1fTVhvz2AY9fCMtvdsR1KQ1WTU2vcO7yW7C0ErfsaX1gC7sSepS/U/1vjf7p0esMbknv6q3gSupQ5T/Dqjwla8wWW4swKXdvEoLDrTRR2vx2s9srdwH9qOxR3XGcKu90S2J+Fp6h0/NHuZdjTSj//d2rtgzFtQRT0HFs6zu9gwdDrKg3QS17a77nxhjcoHSO1d/Y+d2I3sFZ+vLaIHHsqGq4q3cHZ5Sp9Z6+ik0U4HKWDDy2WKhq4KiLHpIXbsli4LRubxeC63rV7BiPH9tKZTF0HGHd0IL7w+hR3GElxh5HgLTno9NbA3vkDjL0vjo3SFivDKG3BMj3g85S+mPS6MXxu8LkxXAVYszdhzdqILWsj1qwNWAtSsRamAeCJak7uGW8f0fgSb2w7coZ9hXPDt4T+8SQ+ZxSF3W/F1XRQjQtV+/iimlLYc8zBdzIsFCVdh7teTyJ+uhFr7naivjmXgp534Y1sTPDKSf7WFABvWCLF7S4p/T2wOjGtjtLWJKsTc2+ICv3jKYLXfEbokpdx7JxH7mmvHPYMXkZhOhG/3OL/vStpcjqe2HalP3uf+5/fA58bDAslzc/E3aBP4H8WtmDc9Xvhrt+LfW8jWApSse3+C/vuZVhytx/wUNMRQVHS/1VsgVGrg8Iet1PSbDDBqz8unYBjb6A6aHdXEZHDUOlwFRcXx86dO1mzZk2FpjpfunSp/zgRkfL4TJNXf9sCwHmdEqkfeZCZ22o6nwf7ztIJF1xHspaS1XnI2fMO5mAN7+6Gfcp8b7jysGZtxFKUiaveiVUzxsEwKGk1jJKW5wT+RXwV88QnkXXBDMJmjyVo4zTCFjzuf8zEwNWoP8UdLsPVeOAhu1TmD3wGV6P+hM8ei333MqI/H0R+v8cpaX1uhWqx7/iN8Jm3YC1Mq7rxYAHkC03A1WxwueMUj5Q3th35fR+r8vOKiABUuhnpxBNPxDRN3njjjUPuW1xczMsvv4xhGPTs2bOylxSRY9wv69NZszufELuVq06s3esO2Xb/hcWVi88Zhadux0CXUyGmIxxPfFLp9NhVPXi8lr7IPxTTGUHe6RPJG/A0pi0YX3AsBV1vJvOy38k9+yNcTU+v8Fg1V4uzyLrwJ9yJPbC484mYOZrwmbdguPIOfJDXTeiCJ0rX+SpMw1OnNVnnT9egehGRAKl0y9WVV17J5MmTWbhwIaNHj2bs2LFER+8/dfDff//No48+yvr167FYLFx66aVHVLCIHJs8Xh+vzStttRrZvQF1asMCwQexb8IDV8OTj8k1keRfDIPidpdQ3HJY6fo7RzCluC+8PtnDviBkycuE/Pk8Qeu+xrF1Jr6w+viCojCDovE5934OisK5abp/PaCi9iPJ7/0g2Gtxi6+ISC1X6b8AzZs3Z8yYMTz11FP8/PPP/Pzzz2XC1UUXXcTOnTvJyPhnrMD1119P69atj6xiETkmTVmRyo7sYuqE2Lm0a4NAl3PEHDvmAuBueARdAqV2sYdUzXksNgq734arQR8ifr4Za97Og64/5XNEkDfgaVwtzqqa64uISKVV/u014H//+x9hYWE8+eSTFBQUkJn5z4xIf/31l/9rh8PB6NGjGTVq1JFcTkSOUYUuL28t2AbA1Sc2JsRRu1t6jOJsbGl/AeBqdHiTWYjs40nsTualc7BlrMUozsJSnF36uSTb/71pC6Kw6834IhoGulwREeEIwxWUrnd1xhlnMHXqVBYtWsT27dspKCggKCiIxMREunXrxrBhw4iNPcSK6CJy3Pp06U4yC93UjwxieMeEQJdzxOw752GYPjzRrfCFVX4yChGsTjxxnQJdhYiIVFClw9WCBQto1qwZ8fHxhIWFcckll3DJJZdUZW0ichzILnTz0Z87AbihTxPs1tq/XINjx94p2NVqJSIiclyp9KuYxx9/nIEDBzJlypQqLEdEjjfvLNxOgctL67gwTm1dN9DlHDnT/Nf6VhpvJSIicjypdLjauXMnPp+PpKSkqqxHRI4jO7OL+OqvXQCM7tsUyzEwdbQ1exPW/F2YVifueicGuhwRERGpRpUOVw5H6TTJTqezyooRkePLa/O24vGZnNgkmh6N91/KoTbaNwW7O7GHpsQWERE5zlQ6XJ155pmYpslbb71VlfWIyHFiVWoeP63bgwHcfHLTQJdTZex7p2B3NVKXQBERkeNNpSe0GDt2LLt37+aTTz5h/fr1nH766bRt25aoqKhDtmY1bKgpY0WOZ6Zp8vLczQAMaRdHq7iwAFdURbwlOJIXAOBqqMksREREjjeVDleDBg3CNE1M02Tx4sUsXry4QscZhsHq1asre1kROQb8viWLJTtycFgNruvdJNDlVBl7ymIMTxHekDi8MW0DXY6IiIhUs0qHq9TUVP/XpmlWSTEicuzz+kxe/q201eqCpPokRAQFuKKq4x9v1bAvHAOTc4iIiMjhqXS4euKJJ6qyDhE5Tny/ejeb0guJCLLxv57HVhdh/xTsGm8lIiJyXKp0uBo+fHhV1iEix4Fit5c35m8F4MoeDYkIsge2oCpkFKRhyyjt8uxqcHKAqxEREZFAqPRsgSIih+vzZbtIy3eREO7kgqT6gS6nyhjFWUTOuAYAd1wnzJDYAFckIiIigVDplqt/y87OZsqUKSxatIiUlBQKCwsJDg6mXr16JCUlMXToUOLj46viUiJSS2UXuXl/0XYAru/TBKft2Hhvx1KQSuTUS7FlrsPnjCS/72OBLklEREQCxDCPcDaKzz//nCeffJLi4mKg7OQWxt4B3U6nk7Fjx3LxxRcfyaUCIj09D83XIXLknp+9iU+WJNOybiiTLuuC5RiY8MGSvYWoaZdizd2ONySenKEf441pE+iyREREpIoZBsTGhh9yvyNquXr33XeZMGGCP1A1atSIZs2aERISQn5+Pps2bSI5OZni4mLGjx9PSUkJV1555ZFcUkRqoc0ZBXyxbBcAo/s2PSaClTV9NVFTL8VStAdvRGOyz/kUX0SjQJclIiIiAVTplqtNmzYxdOhQfD4fHTt25KGHHqJt2/3XdVm5ciWPPPIIy5cvx2azMXXqVJo1a3bEhVcXtVyJHJn8Eg9XfryMbVlFnNQ0mhfPPSHQJR0xW8qfRH53BRZXLp6YtmSf/TFmaFygyxIREZGjpKItV5Ue9PDBBx/g9Xpp06YNH374YbnBCqBDhw58+OGHtGvXDq/XyxdffFHZS4pILWOaJuN/XM+2rCLiwhw8OLh1oEs6Yo6tvxA19WIsrlzcid3JHv6VgpWIiIgAR9AtcOHChRiGwS233ILT6Tzovk6nk9GjR3Pdddcxf/78yl5SRGqZD//cya8b0rFbDZ4a2o46IY5Al3RIQSs/JHTBExjugnIfN0wfACWNB5I76A2wB1dneSIiIlKDVTpcpaamAtCpU6cK7b9vv+Tk5MpeUkRqkUXbspg4bwsAYwY0p0NiRIArOrTg5W8TNu+hQ+5X3OZ88vo/DdZjZ50uEREROXKVDldWqxUAl8tVof337WccAwPZReTgUnOLue/7tfhMOLt9PMM7Jga6pEMK/ustwuY/DEBhl5so6vi/cvczrQ7MoOjqLE1ERERqiUqPuWrcuDEAc+fOrdD++/Zr2LBhZS8pIrVAicfH2GlryC5y0yYujLtOaVHj31QJ/utNf7Aq6HYLBSeOxRcaX+6HgpWIiIgcSKXDVd++fTFNkxdffPGQXf2Sk5N58cUXMQyDfv36VfaSIlILPDNrI6tT84gMsvHU0HYE2a2BLumggpe9Qdj88UBpsCrsMaZ0SiARERGRw1TpcHX55ZcTERFBRkYG5513HpMmTWL37t1l9tm9ezcffvgh5513Hunp6YSGhnLFFVcccdEiUjN9uyKFKStSMYBHz2xDvciggNViTV9N8NLXsO+Yh+HKL3ef4GWvE/b7IwAUdLtVwUpERESOSKXXuQKYPXs2o0ePxuVy+bv9hISEEBISQmFhIYWFhUDpdMw2m41XX3211rVcaZ0rkYpZuzuPqz/9C5fX5PreTbjqxMAtqGvJ2Ub0l2diKckGwDQseGLa4knohjuhK+7Ebjg3fk/YgscAKOh+G4U97ghYvSIiIlKzVXSdqyMKVwDLli3j0UcfZdWqVQfcp127djz00EN07NjxSC4VEApXIoeWX+Jh5EdLSc4ppm/zGCac0w5LoFqAXAVEfz0UW+Y6vOENARNr3s4D7q5gJSIiIodSbeFqnzVr1rBo0SJSU1PJz88nJCSEevXq0a1bN9q3b18VlwgIhSuRgzNNk3u/W8PM9enUi3Dy0WVdiAgK0BTlpknEj/+Hc9N0vCFxZJ//Pb6wRCz5KdhSl2BPXYI9dTG2PSsxfG4KetxBYffbAlOriIiI1BrVHq7Kk5mZidvtJj4+/mhd4qhTuBI5uC//2sXTv2zEZjF4+6JOtA/gelYhi18kdOEETIud7GFf4knsVv6OniIsRZn4wutXb4EiIiJSK1U0XFV6Qot9FixYwBVXXME999yz32M///wz/fv3Z+TIkSxfvvxILyUiNcza3Xk8P3sTADf3bRrQYOXY8hOhCycAkN/v8QMHKwBbsIKViIiIVLkjClfvvvsuV111FYsWLWL9+vX7Pb59+3ZM02TJkiVceumlTJs27UguJyI1SH6Jh3u+W4Pba9KveQwXdwlcWLFmbiD859EAFJ1wBcXtLg5YLSIiInL8qnS4Wr58ORMmTMA0TerVq8c555yz3z4jR45k3LhxNGzYEI/Hw/3338/mzZuPqGARCTzTNHnspw3szC4mMcLJA4NaBWyhYKMkh4jpV2Fx5+OqdyL5vR8KSB0iIiIilQ5XH3zwAaZp0qFDB6ZMmcLll1++3z6JiYlccsklTJkyhXbt2uFyuXj//fePpF4RqQEm/53CzPV7sFoMHj+rLZHBAZrAwucl4qcbseVswRtWn9zBb4A1QLWIiIjIca/S4Wrx4sUYhsEdd9xBePjBB3eFhIRw2223YZom8+bNq+wlRaQGWJeWz3O/7h1ndXJTOgRwnFXowqdwbJ+NaQsid8g7mMExAatFREREpNLhKjMzE4A2bdpUaP927doBsGfPnspeUkQCLL/Ew73frcHlNTm5WR0u6Rq4cVbONZ8TsnQiAHkDnsFTt0PAahERERGBIwhX0dHRAGRlZVVo/8LCQqC0FUtEap8Sj487p65me1YRCeFOHhzcOmDjrOw75xM+eywABd1uoaTVsIDUISIiIvJvlQ5XzZs3B6jwDIDTp08vc5yI1B4er497pq1m8fZsQuxWnhzaLmDjrKxZm4iYcS2Gz0Nxy3Mo7DEmIHWIiIiI/Felw9U555yDaZq89dZb/Pjjjwfdd86cOUycOBHDMBgyZEhlLykiAeD1mTz4wzp+25yJ02bhueHtaZ9w6EX0jgajKJPI7y7HUpKDO6EreQOfLV3VT0RERKQGMEzTNCtzoMvl4uKLL2bVqlUYhkG3bt3o378/jRs3Jjg4mKKiInbs2MFvv/3GggULME2TFi1a8M0332C3157ZvNLT86jcMyRS+5mmyWM/b+DbFanYLAbPDGtP76Z1AlOMt4Soby/GnrIIb0QjskZM0wQWIiIiUi0MA2JjD/3mcqXDFUBqairXXHMNGzZsOOjYC9M0ad68OW+++Sb16wduAHxlKFzJ8co0TZ6fvZlPlyZjMeDxs9pySqu6gSqG8Jm3ELR+Mj5HBNnnfYu3TsvA1CIiIiLHnWoJVwAej4dJkybx3XffsWrVKv57uqZNm3Luuedy2WWXERQUdCSXCgiFKzlevT5/K+/8sR2ABwe34qz2CQGrJeTP5wld9CymxUbOWZNwN+wTsFpERETk+FNt4erf8vPz2b17Nzk5OQQHB5OQkOCfVbC2UriS49FHf+7gpblbALhzYAsuSKoXsFqc678h4uebAcjr/xTF7S8NWC0iIiJyfKpouLJV5UXDwsIICwurylOKSDVyeXy8tWAb7y/aAcCNfZoENFhZCnYT/uudABQmXadgJSIiIjValYarfysqKqKkpISoqKijdQkRqULLk3N49Kf1bM0sAuB/PRtyZc9GAa0pZMnLGJ5i3AldKeh1b0BrERERETmUww5XhYWFzJs3D6vVyimnnLLf4zNmzODVV19l48aNANSpU4eLL76Yq6++muDg4COvWESqVIHLw8TftvLlX7swgTohdsae0oKBgZq8Yi9LXjJBqz4prbHnXWBUeuUIERERkWpxWOHqq6++YsKECeTm5tKjR4/9wtXbb7/Ns88+C+Cf2CIjI4NXX32VOXPm8NZbb6klS6QGmb8lkyd+3sDuvBIAhnaI55Z+zYgICvxyCSGLX8TwuXDVPwl3g96BLkdERETkkCr8VvBnn33GAw88QE5ODqZpkp2dXebxNWvW8Nxzz2GaJqZpMnjwYB544AGuuOIKgoKCWLlyJQ888MARFZuRkcENN9xAt27d6NmzJ4899hgej6fcfRctWsT5559PUlIS/fr144033jiia4scS3KK3IybvpZbJ69kd14J9SKDeGXECTwwqHWNCFaWnK0ErfkcgIKedwa4GhEREZGKqVDLVWZmJs888wymaVKvXj3Gjh3LSSedVGaf5557Dp/Ph2EYXHvttdx2223+x8466ywuvfRSZs6cyeLFi+nWrVulir311luJj4/nt99+Iz09neuvv57333+fUaNGldlv06ZNXHvttTz44IMMGzaMdevWccUVV9C4cWMGDx5cqWuLHCtcHh+jJ69kdWoeFgMu6lKf63o3IdhuDXRpfqF/voBhenE16o8nsXugyxERERGpkAq1XH377bfk5+fTqFEjJk+ezKBBgwgP/2cqwszMTH7//XcMwyAqKorrr7++zPEnnHACI0aMwDRNvv/++0oVum3bNhYtWsSdd95JcHAwDRs25IYbbuDjjz/eb99PPvmEU045heHDh2MYBm3atOGzzz6ja9eulbq2yLHkhTmbWZ2aR2SQjXcu7sxt/ZvXqGBlzdyAc/1kQK1WIiIiUrtUKFz99ttvGIbBNddcU+6Yqd9//x2v1wvAaaedVu5iwaeffjoAixcvrlShGzZsICoqivj4eP+25s2bs2vXLnJzc8vs+/fff9OgQQNuv/12evbsyRlnnMGiRYuoWzewA/RFAu2ntWl8+dcuAB4e0oYOiREBrmh/IX8+h2H6KGk6CE9cp0CXIyIiIlJhFQpXW7aULiZ6oO58Cxcu9H/du3f5A8+bNm0KQFpa2mEVuE9BQcF+sw3u+76wsLDM9pycHD788EOGDh3K/PnzGT9+PE899RQzZsyo1LVFjgVbMwp59Kf1AFzVsyG9m9YJcEX7s6avJmjjNAAKetwR4GpEREREDk+FwlVmZiYAsbGx5T6+ZMkS/9fdu5c/PmJfa1ZRUdFhFbhPSEjIfsfu+z40NLTMdofDwSmnnEL//v2x2Wx0796dc845hx9++KFS1xap7YrcXsZOW02R20e3hpFce1KT6i3A5yVoxfs4Nv8Ie2cSLU/ootLZRotbnI03tl11VSciIiJSJSo0oYXNZsPlcpU7M19mZiabN2/GMAyaNWtGnTrlvxuekZEBQGRkZKUKbdmyJdnZ2aSnp/tD3qZNm0hISCgz/gtKuwu6XK4y27xer396eJHjiWmaPDlzA5szCokJdfDImW2xWoxqrSFo1STC594PgDuxB/l9HsIT17HMPra05Ti3/IhpWCjsfnu11iciIiJSFSrUcrUvzKSkpOz32Pz58/1f9+rV64DnWL58OQAxMTGHVeA+TZo0oWvXrjz++OPk5+ezY8cOJk6cyIgRI/bb96KLLuKXX37h22+/xTRN/vzzT6ZNm8Y555xTqWuL1GZTVqQyfXUaVgMeP6sNsaGOar2+4con9M/nATANC/aURUR/OYTwX27DUpDq3y904QQASloNx1unZbXWKCIiIlIVKhSuunTpAsCcOXP2e2z69On+r/v373/Ac3zzzTcYhkFSUtJhlviPl156CY/HwymnnMIFF1zAySefzA033ABAUlISU6dOBUpD3sSJE/nwww/p2rUr99xzD2PHjt1v0WORY9263fk8M2sjANf3aUqXBlHVXkPwX29gKUrHE9mEzJHzKG51LgBBa7+kzqSTCfnzBew75uLYPhvTsFLQ/bZDnFFERESkZjLMCvSVmzVrFjfccAPh4eF8+OGHtG3bFihttbrmmmswTZPY2FjmzJmDxbJ/XpsyZQp33303hmHw2muvHTSE1TTp6XkHGyIiUmPlFXu4bNJSknOK6dOsDs8Oa4/FqN7ugEZBGjGT+mB4CskZ9DquFmcBYNu9jLB5D2NPLTt7aFG7S8gf8HS11igiIiJyKIYBsbHhh9yvQmOuBg4cSOfOnfnrr7+44IIL6NWrF263mz///NO/cPCtt966X7BKS0vj448/5p133sEwDNq3b1+rgpVIbZVf4uHuaatJzimmXoSThwa3rvZgBRD65/MYnkLccZ1xNT/Tv90Tn0T2ud/g3DiN0AWPY83biWmxU9jtlmqvUURERKSqVKjlCkqD0lVXXcXGjRsx9r5I23foiBEjePTRR8vs/9RTT/H+++/794uMjOSDDz6gTZs2VVj+0aeWK6ltknOKuP2bVWzOKMRps/DmhZ1ol3Dod1qqmjVrE9GfDsQwvWQP+xJ3/QOMyfQUEbRuMt6IRrgbnly9RYqIiIhUQJW2XAHExcXx1Vdf8dlnn/Hrr7+yZ88e6tevz/DhwxkyZMh++zscDn/4aty4MS+++GKtC1Yitc3y5Bzu/HY1WUVuYkMdPDusfUCCFUDoH09imF5Kmpx64GAFYAumuP2l1VeYiIiIyFFS4ZarwzV//nzmz59Ply5d/OtN1UZquZLaYvrq3Tz603rcXpPWcWE8O6w98eHOgNRiS11C9NfnYBoWsi78GW9M64DUISIiIlIVKtpyddTC1bFC4UpqOp9p8tq8rby/aAcA/VvEMH5IG4Lt1sAUZJpEfXMe9pRFFLW9kPyBzwamDhEREZEqUuXdAkWk5ilye3nwh3X8uiEdgCt7NOT6Pk0CMnnFPo4tP2FPWYRpdVLY446A1SEiIiJS3RSuRGqpzRkF3P/9WjbsKcBmMbj/9Fac2T4+sEX5PIT+8QQARZ2uwRdWL7D1iIiIiFQjhSuRWsY0Tb5ansKLczZT4vERFWxnwtB2dG4QGejSCFrzObasjfiCoinsckOgyxERERGpVgpXIrVIRoGLR39az7zNmQCc2DiaBwe3IjYsMBNXAGD6sOTtxJaxjpBFzwFQ2O0WTGdE4GoSERERCQCFK5FaYv7mTMb/uI7MQjcOq8FNfZtxYVK96h1fZZrYUxZh27MCa8ZabJnrsGaux+Iu8O/iDW9IUYfLqq8mERERkRpC4Uqkhit2e3lp7ha+/GsXAM1jQ3h0SFta1A2t3kK8bsJn3U7Q+m/2e8i02PFGt8AT05bCrjeDNYAtaSIiIiIBonAlUoP9viWT537dxLasIgAu6lKfm05uitNmqd5CPEVEzLgO57ZfMC02XI1PwRPTBm+dNqWfI5uA1V69NYmIiIjUMApXIjXQ1oxCnp+zid+3ZAEQE+pg3KBWnNS0TrXXYpTkEvH9/3CkLMS0Oskd/CauJqdUex0iIiIiNZ3ClUgNklvs5q0F2/nyr114fSY2i8GFSfUZ1asRYc7q/+dqFKYTOW0k9vSV+Bzh5J75Pu56Pau9DhEREZHaQOFKpAbw+Ey++TuFN+ZvJafYA8DJzepwa//mNIoODkhNlrxkIqdejC17M77gGHLO/hhP3Q4BqUVERESkNlC4EgmwVSm5PPrTBjaml8641ywmhNv7N6dnk+iA1WTN2kjk1Iux5qfgDatPzjmf4o1qFrB6RERERGoDhSuRACl2e3nz9218vGQnPhMig2xce1ITzu2UiM1STdOrmyZGSTbWvGQs+buw5CVjzd9F0JrPsRRn4oluQc7QT/CF1aueekRERERqsQqFqwULFlTpRXv16lWl5xOpbZYn5zD+x/Vs3zsL4OC2cdzRvzlRIUdxxj2vC9ueldh3L8WWugRb+mqs+ckYnuJyd3fX7UjO2ZMwg6t/Eg0RERGR2sgwTdM81E5t2rTBqKKFSg3DYPXq1VVyruqQnp7HoZ8hkYopcnuZOG8rny9NxgRiQx3cfWpL+rWIqfJrGa587DvmYk9dgj11CbY9KzC8JeXu6wuOxRteH19YIt6w+nijmlLc+nxwVPNaWiIiIiI1kGFAbGz4IferUMvVwIEDmTVr1hEXJXIsyyx08dnSZIrdPsKcVkIdNsKcVsKcNkIdVgrdPl6as5nknNKWorPbx3Nb/+aEB1V971zH5h8Jm3MP1sK0Mtt9QdG4E7riie+KO74T3ohG+EITwBZU5TWIiIiIHG8q1HIFMGnSJB577DEA2rdvz1133VXpi/bo0aPSx1Y3tVxJRezMLuLmr1ewM7v8Lnb/Fh/u5N7TWlZ4zSqjOBswMYMOPcGFUZRB2G/jCNrwLQDe8Ia4GvUrDVQJXfFGNi1960VEREREKqxKW64ARo4cic1m46GHHmLVqlVs2bKFCy+88IiKFDkWrEvLZ/TXK8gsdFMvwsmpreMocHnIL/FQ4PJSUOIh3+WlyO2lV5M63NCnSYXXrLLtXkbktJEYrnxcjQdQ3HoErqangdVZdkfTxLlxGmFz78dSnIlpWClKuo6C7repVUpERESkmlS45WqfcePG8cUXXxAaGsoPP/xAXFzc0aqtRlDLlRzMkh3Z3DFlFQUuLy3rhvLSuR2IDXMe+sAKsKUuJXLapVhceWW2+5yRlLQ8h+LW5+GJ74KlMI2wOffi3PIjAJ6YNuQNfBZPXKcqqUNERETkeFfRlqvDDlcul4shQ4aQnJzMeeedx6OPPlrpImsDhSs5kFkb0rn/+zW4vSZdGkTy4oBg6v49EUvRHvCUYHhd4C39bHhLwOfB1fgUCk66F9Nx8H+c/w5Wrno9KejzEM6N3+Nc/zXW/BT/fp6o5liK0rGU5GBabBR2HU1h15vA6jjaty8iIiJy3Dhq4Qpg+vTp3H777dhsNn755Rfi4+MrVWRtoHAl5Zm8fBdP/bIRnwkDWsYyof1O6sy6Zb9WpvJ4w+qTN/BZ3A37lPu4LXUJkdNG+oNVzpkf/jNrn8+LPfl3gtZ+iXPzdP806u66Hckb+Aze2HZVdo8iIiIiUuqohiuA5ORkAGJiYggKOnbHdChcyb+Zpsnbf2znzd+3AXDuCXE8HPUD4X8+C4A7sTtF7S4BaxCm1YFpc4LViWl1YCnKJGzeQ1hzS48t6nAF+b3uLTPduS11CZFTL8Xizi8NVmd9BPaQcmsxXPk4Nv+A4XVR3PZCsGhNcBEREZGj4aiHq+OFwpXsY5omz/66ic+X7QLg+u4x3Jr/LM4tPwF7w1KfBw/eJc9VQNiCxwle+QEA3ojG5J3yHO56Pf8TrE4k56wPDxisRERERKT6KFxVEYUrAfD6TJ6cuYEpK1IBeOxEGxduvQdb9iZMi4P8fo9T3O6iCp/PvuM3wmeNwZqfjIlBcdsLcG78XsFKREREpAZSuKoiClfi8Zk8PGMdM9akYTHgra6pDFg3Dos7H29oArlnvIUnPumwz2u48gid9zDBaz7zb3PV70XOmR8oWImIiIjUIFUarp544gkMw2DMmDHYbMfXuA6Fq+Ob2+PlhamzKdm2kO7W9ZwZuY3o/A0AuOr1JHfQ65ghdY/oGo6tvxA670G80a3IPf0VBSsRERGRGqZKw1WbNm0wDIOlS5cSHBxc7j75+fkAhIWFHWapNZvC1fHHUpCKc+N3WHYtomTrH0T7Mvfbp7DjVRSc9ABY7QGoUERERESqU0XDVZU0QxUWFtKtWzcsFgurV6+uilOKVDtLzjZClk4kaO2XGD4XACGAy7RSEN0eZ+OeuBO74U7ojhl6bC+eLSIiIiKHr0r7+Gn4ltRG1ox1hCx9FeeGbzFMLwBrbG2ZWtSJlZbWXH7O2XRunIAnwHWKiIiISM12fA2gEvkXW9pyQpa8jHPzDP+2vHp9GZc1mG+ymhDutPHSeR3okBgRwCpFREREpLZQuJLjj7eE8Nn3ELT2CwBMDFzNz2B106u4djbsyXdRJ8TOS+eeQOv4Y2sMoYiIiIgcPQpXclwxirOJ+GEUjl1/YBoWSloNp7DLjczNjuWe71ZT5PbRNCaEF4Z3oF5kUKDLFREREZFaROFKjhv/3959h0dV5v0f/5yZ9B4YCAmEFhKqSKQpqHTBoIg/saJYYdc8rqLYZX0sq4+7a7nEBWwrWFhWQEBBigiiCCigNAvF0AUiSUhC6iSZ8/sjzEBMQJJMMsnM+3VdXEvOOTPnO3ivzof7Pt/bkntAkYvHye/4L3L4hyn38jdVEn+p5m45rBdX/SCHKfVpHaUXruyi8CD+rwEAAIDq4RskfIJf+mZFfnq7LIUZKguLVc4V78ke3UlTVqfpP9/9Kkka1S1Gjw1NlJ/V4uFqAQAA0BgRruD1AvYsU8SKe2SUFqnE1lW5V7yrgoBm+uuin7T6l0xJUurFbXVbn3gZhuHhagEAANBYVStc8cUTjU3w1rcV+vXTMmSquPUgnRg+XWZAmCYv/FFfpmXK32rof4d31PDO7FsFAACA2qlWuLrrrrtksVReMuVwOFy/Hzdu3FnfwzAMvfvuu9W5LVAjIRteUujGVyRJhV1vVt6lf5Msflq7J0tfpmXKz2Jo6pjuSm4V6eFKAQAA4A2qFa6+++67M55zzmpt3LjxjNeYpsnsF+qFYT+hkO+nSZLyLnpMhcmpkmGopMyhl1enSZJuuKAlwQoAAABuc07hKi4urq7rANwqYN/nMsqKVRqV4ApWkvTh5sM6cLxQTUL8deeFrT1cJQAAALzJOYWrVatW1XUdgFsF/rJYklTc4QpXsMrMt+vt9fslSf9zcTuFBdLPBQAAAO5Dz2l4HcOep4ADqyVJxQkjXcenf71P+fYydY4J0xXdYjxUHQAAALwV4Qpe59SSwPYqa9pZkvRz+gl98sNRSdKkQQmy8OwfAAAA3IxwBa8TmHZySWBC+ZJA0zT14qo0mZJGdG6u81vSxAIAAADuR7iCd7HnK2D/F5JOLQlcvuOYth3OVZCfRX+5pJ0nqwMAAIAXI1zBqwTuP7kkMLKtymxdVFhSpte+2iNJur1vazUPD/RwhQAAAPBWhCt4FWeXQPvJJYEzNxzUb3l2xUUEamyvVh6uDgAAAN6McAXvYc9XwP7ybQOKO1yhX3MK9cHGg5Kk+wYmKNCP4Q4AAIC6w7dNeI3A/StllBWrLKKNSm1dNeXLvbKXmerVOkqDOjT1dHkAAADwco0qXGVmZio1NVW9evVS37599dxzz6m0tLTKa++66y6dd955Sk5Odv366quv6rli1CdXl8AOV2jTwRyt2p0hiyFNGpggg9brAAAAqGN+7n7DvLw85efnKyQkROHh4W5974kTJyomJkZr1qxRRkaG7r77bs2cOVN33XVXpWt/+OEH/fvf/1afPn3cWgMaqJIC15LA/PYj9dKyNEnSNefHqUOzUE9WBgAAAB/hlnD11Vdfafbs2dq0aZPy8vJcx0NDQ5WcnKzrrrtOw4YNq9U99u/frw0bNuirr75ScHCw4uPjlZqaqn/+85+VwtXBgweVk5OjLl261OqeaDwC962UUVqksog2mne4qX7JSFNkkJ/+1K+Np0sDAACAj6hVuLLb7Xrssce0ZMkSSZJpmhXO5+Xl6euvv9bXX3+tESNG6P/+7/8UFBRUo3vt3r1bUVFRiomJcR1LSEjQ4cOHlZubq4iICNfx7du3KzQ0VPfff7+2b98um82m2267TWPGjKnRvdHwOZcE5ra5XK+v2y9JmtCvrSKD/T1ZFgAAAHxIrcLVo48+qqVLl8o0TTVp0kSDBw9WQkKCgoODlZeXp7S0NK1evVrHjx/XsmXLFBgYqBdeeKFG98rPz1dwcHCFY86fCwoKKoQru92uHj166P7771diYqK+/fZb/eUvf1FoaKguv/zymn9gNEwlBQrYv1KS9P6JZOUUlap90xD9v/NjPVwYAAAAfEmNw9VXX32lJUuWyDAM3XzzzXr44YcVEBBQ6Tq73a5//vOfev/99/Xxxx9r9OjRuvDCC6t9v5CQEBUWFlY45vw5NLTiMzWjR4/W6NGjXT9ffPHFGj16tJYuXUq48kIB+1fJKC1SUWgrvbozTJI0aVCC/Cw0sQAAAED9qXG3wHnz5kmSLrvsMk2ePLnKYCVJAQEBeuKJJzRixAiZpqm5c+fW6H6JiYnKzs5WRkaG61haWppatGhRqXHGvHnztHTp0grH7Ha7AgMDa3RvNGzOjYOXmxeqzDQ0sENT9WkT7eGqAAAA4GtqHK62bNkiwzB0xx13nNP1zuu2b99eo/u1bdtWPXv21PPPP6+8vDwdPHhQ06ZNq/I5qry8PD377LP66aef5HA4tHr1ai1evFjXX399je6NBqykUIEnlwS+fbyH/K2G7hvQ3sNFAQAAwBfVeFng8ePHJUnt2rU7p+vbtm0rSUpPT6/pLTVlyhQ988wzGjJkiCwWi0aPHq3U1FRJUnJysp5++mmNGjVKt956qwoKCnTPPfcoMzNT8fHx+vvf/65evXrV+N5omAL2r5RRWqjDRnNtN9vptp6t1Coq+I9fCAAAALhZjcNVSEiIcnNzlZGRUaGZxJk4l/P9vilFddhsNk2ZMqXKc5s3b3b93jAMpaamuoIXvFdg2qeSpE9K+sgWGqjb+sZ7uCIAAAD4qhovC0xKSpIkLVq06Jyu/+STTySVPzsFuEVZsQL2lS8JXFrWR3+5tJ1CA9y+LzYAAABwTmocri6//HKZpqm3335bq1atOuu1K1eu1Ntvvy3DMDRixIia3hKowP/o97KUFuiYGaGymB4a0bm5p0sCAACADzPM3+/8e47sdruuvvpqpaWlyTAMDRs2TMOGDVNCQoJCQkJUUFCgtLQ0LV++XCtXrpRpmmrfvr0+/vhj+fs3no1dMzJOqGZ/Qqhr1rV/V5Mtr+njsn6KuPZtdYv94+WpAAAAQHUZhmSzhf/xdTUNV5K0b98+3Xnnnfr1119lGGfeU8g0TcXFxWnmzJlq3bp1TW/nEYSrBuyDFDXL2aZ/BvyPbhv/mKerAQAAgJc613BV42WBUnkHwI8++ki33367IiIiZJpmpV/h4eG6/fbbtXDhwkYXrNBwGfYTapLzgyTJbHOJh6sBAAAAajFzVVJSUmF5n2ma2rlzp44cOaK8vDyFhISoZcuWSkpKksVSqwznUcxcNUz+e1coasnt2u9ori1XfK5+7Zp4uiQAAAB4qXOduapxa7U///nPMgxD//M//6Pk5GQZhqFOnTqpU6dONX1L4JwV/fKlJGm9eZ76t4r0cDUAAABALZYF/vjjj1q7dq3sdrs76wHOid+hryVJR6J7K8jf6uFqAAAAgFqEq8LCQknsW4X6ZxQck63gF0lSUMKlHq4GAAAAKFfjcNW1a1dJ0saNG91WDHAuLAfKZ61+crRRj8QED1cDAAAAlKtxuPrf//1fRUREaPLkyZo/f77y8vLcWRdwRnm7vpAkfW/trgRbiIerAQAAAMrVuFvgq6++qgMHDujTTz+VYRgyDENxcXGKiopSYGDgmW9oGPrggw9qXHB9o1tgA2Oa8nurt6JLjmpqi+d13TXjPF0RAAAAvFyddwucPn26a+Ng555Whw4d0qFDh/6gsDNvNgz8EUvufkWXHFWJaVWTJJ63AgAAQMNR43DVu3dvd9YBnBN7WnkL9s1mB/VMiPNwNQAAAMApNQ5X77//vjvrAM5JUdpqSdKuoGQNDwnwbDEAAADAaWrc0OJcHD9+XOnp6XV5C/gS0yFbxgZJkj3+Eg8XAwAAAFRU63C1fv163XrrrXrssccqnfvss880cOBA3Xzzzdq6dWttbwUfZ8n4WeGOHOWbgWrZuZ+nywEAAAAqqFW4euedd3THHXdow4YN2rVrV6XzBw4ckGma+u677zR27FgtWrSoNreDj8vdsVKS9J0667xWTT1cDQAAAFBRjcPV1q1b9c9//lOmaSouLk5XXXVVpWtuvvlmPfnkk4qPj1dpaakmT56sPXv21Kpg+C5z/xpJ0sHI3vK31umKVgAAAKDaavwN9d1335VpmurWrZsWLlyoceMq7zcUGxurm266SQsXLlSXLl1kt9s1c+bM2tQLX1VmV2zOZkmSXztasAMAAKDhqXG42rRpkwzD0KRJkxQefvYNtUJCQnT//ffLNE19/fXXNb0lfJjj8PcKVpEyzXAldGYbAAAAADQ8NQ5XWVlZkqROnTqd0/VdunSRJB07dqymt4QPy/qp/Hmrzdbz1LpJqIerAQAAACqrcbiKjo6WVN5u/VwUFBRIKp/FAqor6NfyGc8s24UyDMPD1QAAAACV1ThcJSQkSNI5dwBcsmRJhdcB58yer/jCnyRJIUmDPFwMAAAAULUah6urrrpKpmnqrbfe0vLly8967Zdffqlp06bJMAylpKTU9JbwUXlpX8tPZTpk2tQlqZunywEAAACq5FfTF44cOVIffPCBfvzxR02cOFG9evXSwIED1aZNGwUHB6uwsFAHDx7UmjVrtH79epmmqQ4dOuj66693Z/3wAbk7V0mSfgq6QMnB/h6uBgAAAKhajcNVQECApk6dqvHjx2v37t3atGmTNm3aVOW1pmkqISFBb7zxhvz9+XKM6on+bb0kqaBFPw9XAgAAAJxZrXZibdGihRYsWKBHH31UXbt2lVQepE7/1bZtW02aNEkfffSRWrZs6Zai4TvK8jPVuqR84+mmXQZ7uBoAAADgzAzTNE13vVleXp7S09OVk5Oj4OBgtWjRwtVVsLHKyDgh9/0JoboyNn+szuv+R2lmS4WmfiOrhU6BAAAAqF+GIdlsZ9/bV6rFssCqhIWFKSwszJ1vCR9XeqB8SWBa8HlKJlgBAACgAavVssCa2LFjR33fEo1YZMZ3kqTjTXp6uBIAAADg7Go9c/Xtt99qzZo1On78uEpLS/X7VYYOh0MlJSUqKCjQ/v37dejQIf3000+1vS18QUmB4op2SZKsrS/0cDEAAADA2dUqXD322GNauHDhOV9vmqYMg6VdODfWo9/LT2U6bDZRy9aJni4HAAAAOKsah6sVK1ZowYIFrp8jIiJkGIZycnIUGRmpoKAg5eTkqKioSJJkGIYGDhyoK664ovZVwycU7V0nSfre7KSeTUM9XA0AAABwdjV+5urjjz+WJMXFxWnhwoXasGGDXn75ZUnS4MGD9eWXX2rLli2aNWuWOnbsKNM0lZ2drZSUFPdUDq9n/PqtJOlAaHf50cwCAAAADVyNw9X27dtlGIb+8pe/qFOnTpKk5ORkWSwWrVu3znVdz5499d577ykuLk5bt27V4sWLa181vJ+jVE2yt0mS8pv38nAxAAAAwB+rcbjKzs6WVB6onEJCQhQfH6/ffvtNv/32m+t4ZGSk7rrrLpmmqUWLFtW8WvgMv4wfFegoVK4ZoohW3TxdDgAAAPCHahyuLJbyl/5+k+B27dpJkn755ZcKx/v37y9J2rlzZ01vCR/id3iDJGmTI0kdW0R6uBoAAADgj9U4XDlD1bFjxyocj4+PlyTt2rWrwvGIiAhJp2a8gLNxHPxGkrTJ7KQONppZAAAAoOGrcbjq3r27JGn58uUVjrdr106maWrLli0Vju/fv1+SaMWOP2aaCjy6UZL0a3gPBfrV+17XAAAAQLXV+Fvr8OHDZZqmpk+frjfffFO5ubmSpN69e0uSVq5cqW3byhsS2O12TZkyRdKpmS3gTKw5exVkz1Kx6S+16O7pcgAAAIBzUuNwNWLECHXv3l2lpaV65ZVX9Ne//lWSlJiYqIsuukglJSW66aabdO2112rgwIFav369DMPQ0KFD3VY8vJP/yeettpgJah/TxMPVAAAAAOemxuHKMAy98cYbGjBggEzTVMuWLV3nHn/8cUVGRqq0tFQ//PCDsrKyZJqmEhISNH78eLcUDu/lf+RUM4tOMWEergYAAAA4N361eXF0dLTeeOMNpaWlqayszHU8MTFRCxcu1PTp07V582ZZrVb1799ff/rTnxQaSnMCnJ3l5ObBGx2dlNKMcAUAAIDGoVbhyikhIaHSsdjYWD3zzDPueHv4EEt+ugJO7JfDNHQ0/DyFBbpliAIAAAB1jjZsaFD8jpR3CdxhtlarmBgPVwMAAACcO8IVGhTn81YbHB2V1JwlgQAAAGg8zmnNVefOnd12Q8Mw9NNPP7nt/eBdnJ0CNzk66jKaWQAAAKAROaeZK9M03foLqIphPyG/zPLgvdHRUR2ZuQIAAEAjcs7dAgzDkCTZbDYNHTpUkZGRdVYUfJPf0e9kmA4dcDSTI6yFmoQEeLokAAAA4JydU7gaNGiQ1q5dK7vdrmPHjmnevHnq37+/Ro4cqSFDhigkJKSu64QP8D/ZzGKj2YlZKwAAADQ65xSupk+frry8PH322Wf69NNP9e2332r16tX68ssvFRgYqEGDBmnkyJG69NJLFRDAbANqxv+wc38rlgQCAACg8THMGjwElZWVpaVLl2rJkiX6/vvvZZqmDMNQaGiohg0bppEjR6pfv36yWBp/M8KMjBPiMbF6UGaX7a3OMsqKNaT4n/rzlcM0MNHm6aoAAAAAGYZks4X/8XU1CVenS09P15IlS/Tpp5/qhx9+OHlzQ9HR0RoxYoRSUlLUq1ev2tzCJTMzU3/961+1YcMGWa1WjRo1So888oj8/M48Abdr1y5de+21evPNN9W3b99q35NwVT/8jn6n6I+uUqYZrp7Fr+uT8X0VGxHk6bIAAACAcw5XtZ5aiomJ0e2336558+ZpxYoVuu+++9ShQwdlZWXpP//5j2655RYNHDhQ//jHP/Tjjz/W6l4TJ05USEiI1qxZo3nz5mn9+vWaOXPmGa8vLCzUpEmTVFRUVKv7ou45lwRucnRURJC/WoQHergiAAAAoHrcum4vPj5ed999txYtWqRPP/1Ud999t9q0aaOjR49qxowZGjNmjIYPH16j996/f782bNighx56SMHBwYqPj1dqaqpmzZp1xtc8/fTTGjp0aE0/DuqRs5nFhpPPWzm7UwIAAACNRZ09FJWQkKD77rtPM2fO1HXXXSepfL+sAwcO1Oj9du/eraioKMXExFS4x+HDh5Wbm1vp+oULF2r//v265557avYBUH9Mh/yPnNo8mGYWAAAAaIzOeZ+r6jhy5IiWL1+uZcuWadu2bRU2D27VqlWN3jM/P1/BwcEVjjl/LigoUEREhOt4WlqaXnnlFc2ePVtWq7WGnwL1xZq1U5biHBUpUD+abTWGcAUAAIBGyG3h6ujRo1q2bJmWLVumrVu3SpIrUMXGxmrEiBG6/PLL1b179xq9f0hIiAoLCyscc/4cGhrqOlZcXKz7779fjz/+uOLi4mp0L9SvgP2rJEkbHJ1UKj91IlwBAACgEapVuEpPT9eyZcu0dOnSSjNUzZo10/Dhw5WSkqILLrig1oUmJiYqOztbGRkZstnKW3SnpaWpRYsWCg8/1blj+/bt2rdvn5544gk98cQTruN//vOfddVVV+mpp56qdS1wr8C9KyRJn5VdoCA/i+Kjg//gFQAAAEDDU+1w5QxUzhmq0wNVkyZNdNlllyklJUW9e/d2a1OCtm3bqmfPnnr++ef1zDPP6Pjx45o2bZrGjBlT4bpevXpp27ZtFY517NhRr7/+eo1asaNuGQUZ8jv6nSTp87ILlBQXJquFZhYAAABofM4pXKWnp7ueodqyZUuFQBUZGekKVH379q3TjYOnTJmiZ555RkOGDJHFYtHo0aOVmpoqSUpOTtbTTz+tUaNG1dn94X4B+1fKkKlfg5J0tKipLmFJIAAAABqpcwpXAwcOdP3eNE2Fh4dr6NChuvzyy9WvX7+zbuLrTjabTVOmTKny3ObNm8/4up07d9ZVSailwL2fSZK+tvaWJHVsHnq2ywEAAIAG65xSkWmariV+HTt21CWXXCJ/f39t3rz5rKHmTO67775qvwZeqLRIAQe/kiTNyytvdNKp+R/vfA0AAAA0RNWectq1a5d27dpVq5sSriBJAYfWyigtlD2khTZmtZKfxVB7W4inywIAAABq5JzDlfMZK8BdAvaVdwn81TZAyjLUpkmw/K1198weAAAAUJfOKVzt2LGjruuArzEdrnD1Y3g/SVLLSFqwAwAAoPFimgAe4Xdsu6z56XL4h+o7dZMkxUYEergqAAAAoOYIV/CIgJNdAktaD9ShPIckKS4yyJMlAQAAALVCuIJHBO4tXxJY3HaYjuQWSZJiIwhXAAAAaLwIV6h3ltxD8sv8SaZhkb3NYB3OKQ9XcYQrAAAANGKEK9Q7ZyOLkha9VegXqayCEklSbCTPXAEAAKDxIlyh3gWeDFf2dsN0NLdYkhQaYFV4YLW3XQMAAAAaDMIV6pVRnCv/X9dLkuztLtPhk89bxUUGyTAMT5YGAAAA1ArhCvUq4MCXMhwlKo1KUFlUe5pZAAAAwGsQrlCvAk5bEijJ1cyCPa4AAADQ2BGuUH8cpQrYv1KSVNz2MknS4ZzyZ67Y4woAAACNHeEK9cb/yEZZinPkCIpWaYueksSyQAAAAHgNwhXqTcDJjYPtbYdKFqukU+GKPa4AAADQ2BGuUD9MU4F7l0uSitsOlSQVlZSxxxUAAAC8BuEK9cJ6/BdZc/fLtASoJH6AJOkIe1wBAADAixCuUC/80jdLkkpie8oMCJMk9rgCAACAVyFcoV5YCn6TJDnC413HjuTQzAIAAADeg3CFemHJT5ckOUKauY6d6hTI81YAAABo/AhXqBdW58xVSHPXMfa4AgAAgDchXKFeWAqOSZLKQmNcx9jjCgAAAN6EcIV6cWpZ4KmZK/a4AgAAgDchXKHumeaphhah5eGKPa4AAADgbQhXqHNGSZ6M0kJJp2au2OMKAAAA3oZwhTpnyT85a+UfJvmHSGKPKwAAAHgfwhXqnKXg5PNWoac9b5XD81YAAADwLoQr1DnXzFUVzSxiacMOAAAAL0G4Qp1ztmF3nNaG3bnHFRsIAwAAwFsQrlDnXMsCacMOAAAAL0a4Qp1jWSAAAAB8AeEKde5se1wxcwUAAABvQbhCnfv9zJVzj6uwQKvCg9jjCgAAAN6BcIU69/tnrg6fbMMey6wVAAAAvAjhCnWrrFiW4hxJp5YFHqaZBQAAALwQ4Qp1ypJf3obdtAbKDIySdGoDYZpZAAAAwJsQrlCnTi0JbCYZhqTTOgWyxxUAAAC8COEKdcrVKfC0NuyHTza0YFkgAAAAvAnhCnXqVKfAZq5jLAsEAACANyJcoU6d2uMqRpJUWFKm44XscQUAAADvQ7hCnfr9skDn81bscQUAAABvQ7hCnXItCzzZhv1ITvnzVuxxBQAAAG9DuEKdOjVzVb4skD2uAAAA4K0IV6hTlWeuaGYBAAAA70S4Qt1xlMlSWL6J8O+fuWKPKwAAAHgbwhXqjFGYKcN0yJQhR3BTSexxBQAAAO9FuEKdsZ583soMtkmW8s6ALAsEAACAtyJcoc44m1mUnXzeij2uAAAA4M0IV6gzrmYWv3veKjzQjz2uAAAA4HUIV6gzrjbslfa4opkFAAAAvA/hCnXGUpAuqYo9rnjeCgAAAF6oUYWrzMxMpaamqlevXurbt6+ee+45lZaWVrrO4XDotdde04ABA5ScnKwrr7xSS5Ys8UDFvu3UssBmkk5rZsHzVgAAAPBCjSpcTZw4USEhIVqzZo3mzZun9evXa+bMmZWumzVrlhYuXKj3339fmzdv1gMPPKBJkybpwIED9V+0D6u0LDCXToEAAADwXo0mXO3fv18bNmzQQw89pODgYMXHxys1NVWzZs2qdO3YsWO1aNEitW7dWna7XVlZWQoODlZQEF/q65OlwLmBsHNZoHOPK565AgAAgPdpNC3bdu/eraioKMXExLiOJSQk6PDhw8rNzVVERITruMViUUhIiL7++muNHz9epmnqscceU/PmzT1Rum8yTVnyTz5z5WpowbJAAAAAeK9GE67y8/MVHBxc4Zjz54KCggrhyqlPnz7avn27Nm7cqNTUVDVr1kwpKSn1Uq+vM+y5MsrKZ6ocIc1VYD+1xxXhCgAAAN6o0SwLDAkJUWFhYYVjzp9DQ0OrfE1AQID8/Px00UUX6aqrrtKiRYvqvE6UczWzCIyU/ILY4woAAABer9GEq8TERGVnZysjI8N1LC0tTS1atFB4eHiFa1944QW98MILFY7Z7XZFRUXVR6nQac0sfreBMHtcAQAAwFs1mnDVtm1b9ezZU88//7zy8vJ08OBBTZs2TWPGjKl0ba9evfTf//5XGzdulMPh0KpVq7RkyRJde+21HqjcN7metzrZhn1/VvksY6uo4DO+BgAAAGjMGk24kqQpU6aotLRUQ4YM0XXXXadLLrlEqampkqTk5GR98sknkqShQ4dq8uTJmjx5snr37q2pU6fqtdde0wUXXODJ8n3K72eu9mYWSJLaNw3xWE0AAABAXWpUD7/YbDZNmTKlynObN2+u8POYMWOqnNVC/XC1YQ8t7+64JzNfktSOcAUAAAAv1ahmrtB4nFoW2FymaWqPc+bKVnXzEQAAAKCxI1yhTriWBYY21295duXby2Q1pNY8cwUAAAAvRbhCnTj9mau9J5cExkcHK8CPIQcAAADvxDdd1AnXPlchzU8tCWzKkkAAAAB4L8IV3K+0UBZ7rqTyZYHOcEUzCwAAAHgzwhXcztkp0LQGygyI0J4M2rADAADA+xGu4HauJYGhMTIl7c0qf+aKZYEAAADwZoQruJ2l4FQb9mN5duUVn+wUGE2nQAAAAHgvwhXc7tTMVXPX5sGtougUCAAAAO/Gt1243elt2Nk8GAAAAL6CcAW3q7oNO80sAAAA4N0IV3A762nPXO0lXAEAAMBHEK7gdsbJVuxlIaeeuaJTIAAAALwd4QpuZz25LDDTEk2nQAAAAPgMwhXcy1EqozBDkpRWGCaJToEAAADwDXzjhVtZCjNkyJRpWLUzL1CS1I7nrQAAAOADCFdwK1enwGCb0jKLJNGGHQAAAL6BcAW3cu1xFXpaG/YmzFwBAADA+xGu4FanbyDsasNuI1wBAADA+xGu4FbOZYEFAU11orhUFkNqE024AgAAgPcjXMGtnDNXxxQtiU6BAAAA8B1864VbWfLTJUm/lkZKktrTKRAAAAA+gnAFt3LOXO0pLt/jinAFAAAAX0G4gls5n7nakVceqto3pQ07AAAAfAPhCu5jmrIUHJMkbcsNlsQGwgAAAPAdhCu4jVGcLcNhlyTtLQor7xTIHlcAAADwEYQruI1zSaDdP1J2+atVVLAC6RQIAAAAH8E3X7iNs5nFCb+mkmhmAQAAAN9CuILbWArK27BnGOV7XBGuAAAA4EsIV3Ab5x5XR0ojJEnt6BQIAAAAH0K4gttYs/dKkn6y2yQxcwUAAADfQriC2/hl75Ek7bDH0CkQAAAAPodwBbexngxXaWYsnQIBAADgc/j2C7cwinNkKcyQJO0zW7AkEAAAAD6HcAW3cM5a5Vhtylew2hGuAAAA4GMIV3ALa3aaJOmAEStJak+nQAAAAPgYwhXcwtkpcEdpjCQxcwUAAACfQ7iCWziXBe4oOdkpMDrYwxUBAAAA9YtwBbfwO16+LHCPGaeWkUEK8rd6uCIAAACgfhGuUHumQ9ac8mWBe80WPG8FAAAAn0S4Qq1Z8o7KKC1Umaw6ZDZTgo3nrQAAAOB7CFeoNefzVoctLVQqPyU2C/NwRQAAAED9I1yh1pxt2HeXtpAkdWjGskAAAAD4HsIVas05c7Xb0UKBfhbFR9EpEAAAAL6HcIVa8zs5c7XXjFX7piGyWgwPVwQAAADUP8IVas25gfAeR6wSWRIIAAAAH0W4Qu2UFcty4qCk8pmrDjSzAAAAgI8iXKFWrDn7ZZgO5SlExxSpJGauAAAA4KMIV6gVZzOLNEcLSYYSbIQrAAAA+CbCFWrF2YZ9jxmr5mEBigr293BFAAAAgGcQrlArzpmrvY5Y9rcCAACATyNcoVb8nOHKbKEONppZAAAAwHc1qnCVmZmp1NRU9erVS3379tVzzz2n0tLSKq+dPXu2hg8fruTkZA0fPlyzZs2q52rdw2GaenfDQa3adczTpVTJOXO1x4yjDTsAAAB8mp+nC6iOiRMnKiYmRmvWrFFGRobuvvtuzZw5U3fddVeF6z7//HO9/PLLeuutt3T++edry5YtmjBhgmw2m4YPH+6h6msmt7BU/1qzVwFWQ71bRys8qOH8IzOKsmUpzJRUPnNFuAIAAIAvazQzV/v379eGDRv00EMPKTg4WPHx8UpNTa1yRio9PV3jx49Xjx49ZBiGkpOT1bdvX23cuNEDlddOZLCf2jcNkb3M1MoGNnvlnLU6YjZRiTVYbaKDPVwRAAAA4DmNJlzt3r1bUVFRiomJcR1LSEjQ4cOHlZubW+HasWPHasKECa6fMzMztXHjRnXr1q3e6nUXwzCU0qX8My/5+TcPV1ORNcfZzKKF2jUJkZ+10QwnAAAAwO0azbfh/Px8BQdXnBlx/lxQUHDG1x07dkzjx49Xt27ddMUVV9RpjXVleKdmMiRtPpSjI7lFni7HxXrc+bxVLEsCAQAA4PMaTbgKCQlRYWFhhWPOn0NDq/5iv2XLFo0ZM0bt2rXT9OnT5efXcJ5Xqo4WEUHqGR8pSVrWgGavXG3YzVh1aEanQAAAAPi2RhOuEhMTlZ2drYyMDNextLQ0tWjRQuHh4ZWunzdvnm677TbdeuuteumllxQQEFCf5brd5c6lgT+lyzRND1dTzu/kBsJpZqwSbcxcAQAAwLc1mnDVtm1b9ezZU88//7zy8vJ08OBBTZs2TWPGjKl07fLly/XUU0/ptdde0x133OGBat1vcKJNgX4W7csq1M/peZ4uRzIdsmTvlVQ+c5XYnHAFAAAA39ZowpUkTZkyRaWlpRoyZIiuu+46XXLJJUpNTZUkJScn65NPPpEk/etf/1JZWZnuvfdeJScnu349+eSTniy/VsIC/XRpQlNJ0tIGsDTQkndElrIi2U2rCoLi1CSkcc8MAgAAALXVqB5CstlsmjJlSpXnNm/e7Pr9okWL6qukepXSpblW7Dymz3b8pvsGtJefxfBYLc7nrQ6YMWrfPMJjdQAAAAANRaOaufJ1F7aJVnSwv7IKSvTtvuMercV68nmrvWasOthoZgEAAAAQrhoRP6tFl3VqJkla+nO6R2txzlyl0YYdAAAAkES4anScXQNX/5KpfHupx+qo2IadcAUAAAAQrhqZLjFhahMdrOJSh1btyvjjF9QRI6t8WeA+xaldkxCP1QEAAAA0FISrRsYwDKWcnL3yWNfAsmL55x0q/21kOwX4MYwAAAAAvhU3QiM6N5ckbTqQrfQTxfV+f2v2PhkylWuGqGmzuHq/PwAAANAQEa4aobjIICW3jJApabkHZq+sOeXPW+0xWyixeXi93x8AAABoiAhXjZSzscWSn9Nlmma93tt6vPx5qz1mHM0sAAAAgJMIV43UkCSb/K2G0jIKtPtYfr3e2zh+slOgo4USbYQrAAAAQCJcNVoRQf66pH1TSdKSn+p3aWBZxm5JUrp/KzULC6jXewMAAAANFeGqEUvpUt7YYtmO31RUUlZv9/XP3StJckS3l2EY9XZfAAAAoCEjXDVi/do1UfOwAGXm2/XOtwfq5Z5G0XEFl2RLkoJjkurlngAAAEBjQLhqxPytFj00uIMk6b2Nh/RLRt0/e2XNLn/e6rDZRG2b2+r8fgAAAEBjQbhq5AYm2jSwQ1OVOUz934rdctRx50Crq5lFLJ0CAQAAgNMQrrzAg4M7KDTAqm2Hc7Vg25G6u5Fpytz3hSRpr2LVvmlI3d0LAAAAaGQIV14gJjxQd/dvK0l67au9OpZX7P6bOEoV9sWDitzziSRpW/CFCvK3uv8+AAAAQCNFuPISY3rEqWuLcOXby/TSF2nuffPSIkUs/7OCf/5QDln0UMkEZbUY4N57AAAAAI0c4cpLWC2GHh+WKKshrdyVoTVpmW55X8Oep8jFtypwzzLZ5ae77fdpbtlA9Wod6Zb3BwAAALwF4cqLJDUP09herSRJf1/5iwrstdv7yig6Lr85YxTw61rlmUG6zf6wvgm4SBMHtNfV3WPdUTIAAADgNQhXXmb8RW0UFxmk9BPFen3tvhq/zy97dqtoZoqicn5Qlhmm2x1/VZc+KVp4Vx+N7dVKFjYPBgAAACowTLOOe3c3chkZJ9TY/oTW78vSvR/9IIshzRybrM4x4ef0uqO5RVq1O0N7ft6oh7KfVisjQ0fNJpqV8LKuGHCpmoQE1HHlAAAAQMNjGJLN9sffqQlXf6AxhitJmvzpz1q+45jio4I0rGMzxUcHq3V0iFpHBSsy2E/GyZmnQ9mFWrUrQ6t2Z6ggfZfu8/tIoyzrZTFMpfu3VObI/6hZywQPfxoAAADAcwhXbtJYw1Vmvl3Xz9yknKLSSucigvwUHxUse5lDu4/lK95I131+C3S1ZY2sRvmHzWk9XCVDXpAZ0qy+SwcAAAAaFMKVmzTWcCVJR3KLtGpXhg5mF2r/8UIdyCrQb3l21/k4Zehe/wUaY/1KfipvflHcdpgK+kxSabNuniobAAAAaFDONVz51UMtqI2yYkXPvULWrF2S1V+mNVCy+Mu0+kuWAJnWAMmwlP8T/51oSV1OPxApOSKkkjKHSsocCs/fL6tZIkmytx6g/D4PqjQmuV4+FgAAAOBtCFcNncMho+i4DLNMKi2TUVpU67c8vS2FvWV/5fd9UKWxvWv9vgAAAIAvY1ngH2gQywLL7LIUZkqOEhllJVJZsQxHiVRWIqOsWDIdNXpbR3BTldm6/PGFAAAAgA9jWaA3sQbIEcamvQAAAEBDxibCAAAAAOAGhCsAAAAAcAPCFQAAAAC4AeEKAAAAANyAcAUAAAAAbkC4AgAAAAA3IFwBAAAAgBsQrgAAAADADQhXAAAAAOAGhCsAAAAAcAPCFQAAAAC4AeEKAAAAANyAcAUAAAAAbkC4AgAAAAA3IFwBAAAAgBsQrgAAAADADQhXAAAAAOAGhCsAAAAAcAPCFQAAAAC4AeEKAAAAANyAcAUAAAAAbuDn6QIaOsPwdAUAAAAAPOlcM4FhmqZZt6UAAAAAgPdjWSAAAAAAuAHhCgAAAADcgHAFAAAAAG5AuAIAAAAANyBcAQAAAIAbEK4AAAAAwA0IVwAAAADgBoQrAAAAAHADwhUAAAAAuAHhqgE7fvy4nn32WQ0aNEjdu3fXqFGjNG/ePE+XhQZk586duvfee3XhhReqW7duGjx4sJ577jmdOHGiwnWHDx/Www8/rIsvvlg9evTQddddp5UrV3qoajQkZWVluummm9SxY8dK5xg3+D2Hw6EPPvhAo0aNUvfu3TVgwAA9+uijSk9Pr3AdYwen27t3r+677z717dtX3bp10+WXX66ZM2fK4XBUuI5xg61bt6pz58769ttvK52rzvjYvXu3UlNTddFFFyk5OVm33nqrvvvuu7ouX5JkmKZp1sudUC0FBQW6+eabtWvXLt10001q3769li1bpvXr1+v+++/Xn//8Z0+XCA/bs2ePrrnmGlmtVo0dO1axsbHasmWLPv74Y3Xo0EEffvihQkJCdOzYMV1//fXKzs7WLbfcopiYGM2bN08//vijXnzxRV155ZWe/ijwoKlTp2rKlCmSysO6E+MGVXn44Yf18ccfa8iQIbr00ku1d+9ezZo1Sy1atND8+fMVERHB2EEFhw4d0jXXXKPCwkKNHTtW8fHxWrFihdatW6cbbrhBTz/9tCT+nQNp3759uvnmm3Xs2DG999576tu3r+tcdcZHWlqabrjhBgUGBuqmm25SaGio/vOf/+jXX3/VO++8oz59+tTtBzHRIL3xxhtmUlKSuXjxYtcxh8Nh3nnnnWbXrl3Nw4cPe7A6NAR33HGH2bVrV3Pnzp0Vjr/77rtmUlKS+dZbb5mmaZpPPvmk2bFjR/O7775zXVNUVGSOGjXK7Nu3r5mfn1+vdaPh2Lp1q9mlSxezW7duZlJSUoVzjBv83ooVK8ykpCTzqaeeqnB8/vz5ZlJSkvnGG2+YpsnYQUXPPPOMmZSUZH766acVjo8bN85MSkoyf/nlF9M0GTe+7rPPPjN79+5tJiUlmUlJSeY333xT4Xx1xsedd95pdu/e3Txw4IDrWFZWlnnxxRebKSkppsPhqNPPwrLABmrhwoWKiYnRyJEjXccMw9Bdd92lkpISLVq0yIPVwdPsdrs2bdqknj17KikpqcK50aNHS5I2btyosrIyffLJJ+rRo4cuuOAC1zWBgYEaN26cjh8/rtWrV9dj5Wgo8vPz9eCDD+qSSy5Rjx49Kpxj3KAqs2fPVmhoqCZNmlTh+MiRIzVhwgS1bduWsYNK9u3bJ0kaOHBgheNDhw6VJO3YsYNx4+MmTJige+65R82aNdMVV1xR6Xx1xkdGRobWrFmjoUOHKj4+3nVtdHS0rr32Wv3yyy/atm1bnX4ewlUDdOLECe3Zs0fnn39+pXPOY3U9MNCw+fn5afHixXr22WcrncvIyJAkWSwW7d69WwUFBZW+PEunxtLWrVvrtFY0TM5n8/72t79VOse4we+VlZVp48aN6tOnj8LCwiRJRUVFstvtCggI0KRJk3TZZZcxdlBJu3btJEm//PJLheN79+6VJMXExDBufNyePXv0wAMPaMGCBWrbtm2l89UZH87/9eRYIlw1QOnp6TJNU7GxsZXOBQcHKzIyUocOHfJAZWgoLBaL4uPj1bp160rn3nnnHUlS3759XQ+ZVzWWWrRoIUmMJR/02Wef6aOPPtKzzz4rm81W6TzjBr936NAhFRcXq1WrVlq+fLmuvPJKnX/++erRo4fuvPNO7dmzRxJjB5VNmDBB7dq106OPPqr169fr0KFD+uCDD/Thhx/qoosuUs+ePRk3Pm7JkiX605/+pICAgCrPV2d8HD169IzXxsTEVLi2rhCuGiBnp7eQkJAqzwcFBamwsLA+S0IjsXDhQs2dO1exsbG69tprzzqWgoKCJImx5GPS09P117/+VWPGjHEty/k9xg1+LycnR5K0du1aPfjggxo0aJCmTp2q1NRUbdq0STfeeKMOHjzI2EElzZs318SJE3X06FHddtttGjJkiJ599lmdd955mjp1qgzDYNz4uDOFKqfqjI+8vDxJUmhoaKVrg4ODK1xbV/zq9N1RI+bJBo7mGRo5mqYpi4VcjIoWLFigJ554QiEhIZoyZYpCQ0PPOIakU+OLseQ7TNPUI488ovDwcD3++ONnve6PzjFufIvdbpdUvnzntdde02WXXSap/LmZLl266O6779arr76qAQMGnPE9GDu+6c0339RLL72kNm3a6KGHHpLNZtOmTZs0a9Ys3XrrrXrnnXf4dw7Oqjrj42zfoetrLBGuGiBn2i4qKqryfFFRUZXTnfBdznba4eHhev3119W9e3dJp8ZSVX9L4xxf4eHh9VcoPGrGjBn65ptvNHXqVBUXF6u4uFiSVFJSIknKysqS1Wpl3KAS598Yx8TEuIKV0+DBgxUbG6t169YpJSVFEmMH5fLy8jR16lQ1b95cc+fOVWRkpCRp2LBh6tKlix5++GFNnz5dvXv3lsS4QdWq89+khvDfL8JVA9SqVSsZhuFaN3q6goIC5ebmutaYwreVlJToySef1Pz58xUTE6M333xTnTp1cp1v1aqVJFU5lpzHGEu+44svvpBpmkpNTa3y/EUXXaSWLVvq9ddfl8S4wSnOf95VPaPnPL5z507+nYMK9u7dq6KiIl1zzTWuYOV05ZVX6qmnntL69et19dVXS2LcoGrV+ffKuVxb1xMUhKsGKDQ0VAkJCdq+fXulc84OJ6e3ooRvKisr06RJk7R8+XJ17NhRb731luthTaf27dsrPDy8yu6SjCXf88gjjyg3N7fS8RdeeEE7d+7UjBkzFBgYyLhBJU2aNFHr1q21b98+FRcXKzAw0HXO4XDo0KFDatWqFWMHFTifpSkrK6t0zjRNORwOmabJuMFZVWd8nHfeebJYLNq2bZvGjh1b5bXJycl1Wi8LWBuoUaNG6ddff9Wnn37qOmaapv79738rICDAtfQCvuvVV1/V8uXL1b17d82aNatSsJLKW7anpKRo06ZN+v77713Hi4uL9d5778lms+nSSy+tz7LhQd26dVO/fv0q/XL+jXK/fv3Us2dPxg2qdM011yg/P19vv/12heNz5szR8ePHNXLkSMYOKkhMTFTLli21bNkyV8c3p7lz56qoqEj9+/dn3OCsqjM+bDab+vXrp+XLl+vgwYOua48fP665c+eqU6dO6tKlS53Wa5hne0oMHuOcRt+/f79uueUWtWvXTkuXLtW6dev08MMP68477/R0ifCgw4cPa9iwYSorK9MDDzxQZbCy2Wzq37+/jh07pquvvlqFhYW6/fbb1bRpU82bN08//vijXn75ZYI6dMstt2jDhg3auXOn6xjjBr9nt9s1btw4bd68WVdccYX69Omjn376SXPmzFGHDh00Z84cBQcHM3ZQwdq1a/WnP/1JUVFRuuGGG2Sz2bR582Z9/PHHat++vf773/8qIiKCcQNJ0muvvaZ//etfeu+999S3b1/X8eqMj127dun6669XaGiobrvtNgUEBGjWrFk6fPiwZsyYoV69etXpZyBcNWBZWVl6+eWXtWrVKuXn56tdu3a67bbbNHr0aE+XBg9buHChHnnkkbNe06dPH73//vuSpIMHD+qll17SunXrVFJSoo4dO+ruu+8+a2cv+I6qwpXEuEFlhYWFeuutt7Ro0SIdOXJETZs21bBhwzRx4kTX5sISYwcV/fjjj5o2bZo2bdqk/Px8V2OU1NTUCs0FGDc4U7iSqjc+fv75Z7388sv67rvvZLFY1K1bN02cOLHKzYXdjXAFAAAAAG7AM1cAAAAA4AaEKwAAAABwA8IVAAAAALgB4QoAAAAA3IBwBQAAAABuQLgCAAAAADcgXAEAAACAGxCuAAAAAMANCFcAAAAA4AZ+ni4AAOBbbrnlFm3YsKHar7v66qv1wgsv1EFF9WPw4MH69ddfdeWVV+rFF1/0dDkAgDrAzBUAAAAAuAEzVwAAj4iLi9PixYvP+Xp/f/86rAYAgNojXAEAPMIwDIWGhnq6DAAA3IZlgQAAAADgBsxcAQAanUcffVQLFixQSkqKXnnlFc2ZM0ezZ8/W3r17FRYWpsTERN18880aMmTIWd9n9erVmjt3rrZu3ars7GyFhoYqKSlJKSkpGjNmzFmXImZlZWnu3Llavny5Dh06pMLCQsXFxemSSy7RnXfeqdjY2DO+1m636/3339fixYu1b98+Wa1WtWvXTqNHj9aNN94oi6Xy330WFRVp9uzZWr58uXbv3q3i4mJFRUWpW7duGjlypEaOHFnl6wAA9ccwTdP0dBEAAN/h7BbYsmVLrVq1qkbvcXq4CgwM1IIFC6q87v/9v/+nv/3tb7JarRWOFxYWatKkSVq5cuUZ75GUlKTXX39dLVu2rHRuw4YNmjhxojIzM6t8bWhoqKZPn66+ffu6jjm7Bfbv319ZWVn6+eefq3ztwIED9frrr8swDNexnJwcjRs3Tjt27DhjvRdeeKHeeOMNBQUFnfEaAEDd4q+4AACN1urVq7VgwQJ17txZM2bM0DfffKO5c+dq4MCBkqT58+drypQplV73wAMPuILViBEj9OGHH+rbb7/VkiVLNGHCBPn5+WnXrl264447lJeXV+G1Bw8e1IQJE5SZmammTZvq6aef1hdffKGvvvpKf//732Wz2ZSfn6977723yvC1du1a/fzzzxozZowWLFigtWvXasaMGUpKSnJ9poULF1Z4zUsvvaQdO3YoJCRETz75pFasWKFvvvlGCxcu1OjRoyVJ33zzjd59991a/okCAGqDcAUA8AjTNJWfn39OvwoLC6t8j4KCAnXs2FGzZs1Sv379FB0dre7du2v69OkaNGiQJGnGjBk6evSo6zVffPGFa8bs1ltv1auvvqoePXooKipKCQkJmjRpkl566SVJ0r59+zRt2rQK93z++edVWFiosLAwzZ49WzfccIPi4uIUExOj0aNH64033pDValV2drZmz55dZd333nuvnnvuOXXp0kU2m039+vXTzJkzXbNOn332WYXrnT+PHz9eY8eOVevWrRUdHa3OnTvr73//uy688EJJqlb3RQCA+/HMFQDAIw4fPqwLLrjgnK492xLCyZMnV+o6aLFY9MQTT2j16tUqLi7WZ599pnHjxkmS5syZI0lq2rSpHnzwwSrfc8SIERo8eLBWrVqlOXPmaNKkSbJarTpx4oTWrFkjSRo3bpzatGlT6bXdunXTiBEjdPToUQUGBlY6HxYWpgkTJlQ63rRpU11wwQVat26dDh48WOFccXGxJJ1xGeLkyZOVmZmp+Pj4Ks8DAOoHM1cAgEarWbNm6tOnT5Xn4uPjlZiYKElat26d6/jGjRslSYMGDVJAQMAZ33vEiBGSpBMnTrieddqwYYNKSkpcrz+Tl19+Wf/5z380fvz4Sue6det2xkYZNptNkpSfn1/heO/evSVJH3zwge655x4tWbJEOTk5rvOJiYm68MILq3w+DABQf5i5AgB4RG0aWjg5n1M6kzZt2mjXrl1KT0+XJOXl5enEiROSpISEhLO+9vTzR44cUdeuXV3v43zvmoiKijrjOWfjjbKysgrHH3nkEVdHwxUrVmjFihWyWq0677zzdMkll2jYsGHq2LFjjeoBALgPM1cAgEYrLCzsrOedzzA5A9XpM0IhISFnfW1wcLDr987XnT5bdPr56jhbe/czSUhI0OLFi3XLLbeoadOmksoD2JYtW/Taa69p1KhRGjt2rPbs2VOjmgAA7kG4AgA0Wna7/aznCwoKJEnR0dGSKgYq57kzqSqInR6oztRko640a9ZMkydP1tdff605c+bovvvuU+/eveXnV74IZdOmTbrtttsqLSkEANQfwhUAoNE6cODAWc/v3btXklzPIoWFhSkiIkKSlJaWdtbXnn4+Li5OkipsDHy2e69bt05TpkzRwoUL5e7tJC0Wi84//3ylpqbqgw8+0Jo1a1zt2NPT0yt1GgQA1B/CFQCg0dqzZ0+lznpOe/fudS2TGzBggCTJMAz17NlTUnlL9rPNfC1fvlxS+ayV89mu5ORk1+a+zq6BVZkzZ46mTp2qqVOnVtgMuCa2bdumG2+8UX369NHu3bsrnW/SpIkef/xx18+nPxcGAKhfhCsAQKNlmqb+8Y9/VJodKi0t1d/+9jdJUmRkpIYMGeI6d91110kqb2v+4osvVvm+n3/+ub744gtJ0tVXX+16Tqp58+a6+OKLJUnvvvuujhw5Uum1O3bs0Oeffy5JSklJqc3Hk1Q+W7Zt2zbl5OTo/fffr/Kan3/+2fX71q1b1/qeAICaoVsgAMAjnJsIV8fv97OSyjfYvfvuu5WamqrWrVtrz549mjJlitavXy9Jeuihh1xLASVp8ODBrj2s3n33Xf3222+6/fbb1bZtW2VkZOiTTz7Rv//9b0nl7dwfeOCBCvd75JFHtHHjRmVnZ+uGG27QAw88oH79+slut+ubb77RK6+8opKSEjVr1kx33HFHdf9YKmnWrJlGjRql+fPn68MPP1RJSYluvPFGtWrVSvn5+dqwYYNeeeUVSeVBbOjQobW+JwCgZghXAACPqM4mwk4bN26sEJSaNm2qjh076osvvnDNNDkZhqFJkybp2muvrfQ+L774oh588EGtWrVKS5cu1dKlSytd07VrV7366quVOhImJiZq2rRpuvfee3X06FE9/PDDlV7bvHlzvfXWW4qMjKzW5zuTxx9/XHv27NGWLVs0f/58zZ8/v9I1NptNr7/++ln37gIA1C3CFQCg0fLz89Nbb72l9957Tx999JEOHjwom82m5ORk3XHHHeratWuVrwsNDdX06dO1cuVKffTRR9q2bZuys7MVHR2tDh066KqrrlJKSsoZg0r//v21fPlyzZgxQ19++aUOHTokh8Oh1q1ba8iQIbr99tvPup9VdYWHh2vWrFmaO3euli5dql27dunEiRMKDQ1V69atNWjQII0bN07h4eFuuycAoPoM091tjAAAqGOPPvqoFixYoJiYGH311VeeLgcAAEk0tAAAAAAAtyBcAQAAAIAbEK4AAAAAwA0IVwAAAADgBoQrAAAAAHADugUCAAAAgBswcwUAAAAAbkC4AgAAAAA3IFwBAAAAgBsQrgAAAADADQhXAAAAAOAGhCsAAAAAcAPCFQAAAAC4AeEKAAAAANzg/wPhd2hVIuy/XQAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制F1得分曲线图\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_f1score, label='Train F1 Score')\n",
    "plt.plot(val_f1score, label='Validation F1 Score')\n",
    "plt.title('Training and Validation F1 Score')\n",
    "plt.xlabel('Epochs',fontsize=20)\n",
    "plt.ylabel('Macro F1 Score', fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T01:27:03.711706Z",
     "start_time": "2024-04-28T01:27:03.544657Z"
    }
   },
   "id": "7276fb5e40298b98",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 储存当前模型valf1score列表\n",
    "import pickle\n",
    "\n",
    "valf1_distilbert_CosineLR = val_f1score\n",
    "with open('./NLP_data_cache/valf1_distilbert_CosineLR.pkl', 'wb') as f:\n",
    "    pickle.dump(valf1_distilbert_CosineLR, f)\n",
    "    \n",
    "# 读取valf1score列表\n",
    "with open('./NLP_data_cache/valf1_distilbert_CosineLR.pkl', 'rb') as f:\n",
    "    valf1_distilbert_CosineLR = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d051d9d6a32cd44a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(valf1_distilbert_CosineLR, label='DistilBERT with CosineAnnealingLR')\n",
    "plt.title('Validation F1 Score')\n",
    "plt.xlabel('Epochs',fontsize=20)\n",
    "plt.ylabel('Weighted F1 Score', fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96e0c64c0fe34afc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Find the joyful and optimistic topics\n",
    "## 4.1 Filter the Data\n",
    "Find the text data with the labels of joy and optimism."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f76ee373aebb0611"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 定义一个函数来筛选特定标签的文本\n",
    "def filter_texts_by_labels(texts, labels, target_labels):\n",
    "    filtered_texts = [text for text, label in zip(texts, labels) if label in target_labels]\n",
    "    filtered_labels = [label for label in labels if label in target_labels]\n",
    "    return filtered_texts, filtered_labels\n",
    "\n",
    "# 设置目标标签：1 (joy) 和 2 (optimism)\n",
    "target_labels = [1, 2]\n",
    "\n",
    "# 筛选训练集中的文本和标签\n",
    "train_texts_filtered, train_labels_filtered = filter_texts_by_labels(train_texts, train_labels, target_labels)\n",
    "\n",
    "# 筛选验证集中的文本和标签\n",
    "val_texts_filtered, val_labels_filtered = filter_texts_by_labels(val_texts, val_labels, target_labels)\n",
    "\n",
    "# 筛选测试集中的文本和标签\n",
    "test_texts_filtered, test_labels_filtered = filter_texts_by_labels(test_texts, test_labels, target_labels)\n",
    "\n",
    "# 应用词形还原到你的文本数据\n",
    "train_texts_lemmatized = [lemmatize_text(text) for text in train_texts_filtered]\n",
    "val_texts_lemmatized = [lemmatize_text(text) for text in val_texts_filtered]\n",
    "test_texts_lemmatized = [lemmatize_text(text) for text in test_texts_filtered]\n",
    "docs= train_texts_lemmatized + val_texts_lemmatized + test_texts_lemmatized\n",
    "len(docs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28719d0c7cdf705a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2. Vectorization and Topic Modeling\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f2c98ec1ebc6fa1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "docs_tokenized = [doc.split() for doc in docs]  # 分词\n",
    "dictionary = Dictionary(docs_tokenized)\n",
    "\n",
    "# BOW\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs_tokenized]\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "790402f5f9304477",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 构建LDA模型\n",
    "# 使用词袋表示训练LDA\n",
    "# lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=30) # num_topics是主题数, passes是迭代次数\n",
    "\n",
    "# 或者使用TF-IDF表示训练LDA\n",
    "lda_model_tfidf = LdaModel(corpus=corpus_tfidf, id2word=dictionary, num_topics=5, passes=30)\n",
    "\n",
    "topics = lda_model_tfidf.print_topics()\n",
    "for topic in topics:\n",
    "    print(topic)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be7fb75a0bad5104",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "# 使用文档词袋表示计算一致性得分\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=docs_tokenized, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print(f'Coherence Score: {coherence_lda}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "468d852e68599149",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 假设lda_model是你的LDA模型实例\n",
    "num_topics = 5  # 你的模型的主题数量\n",
    "topn = 10  # 你希望从每个主题中提取的关键词数量\n",
    "\n",
    "topic_keywords = {}  # 初始化一个空字典来存储关键词及其权重\n",
    "\n",
    "# 循环遍历每个主题\n",
    "for topic_id in range(num_topics):\n",
    "    # 使用show_topic获取当前主题的前N个重要单词及其权重\n",
    "    for word, weight in lda_model_tfidf.show_topic(topic_id, topn=topn):\n",
    "        # 为了生成词云，我们将每个单词的权重累加（如果单词在多个主题中出现）\n",
    "        if word in topic_keywords:\n",
    "            topic_keywords[word] += weight\n",
    "        else:\n",
    "            topic_keywords[word] = weight\n",
    "\n",
    "# 确保topic_keywords字典包含了你想要显示在词云中的关键词和累计权重\n",
    "# 生成词云\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(topic_keywords)\n",
    "\n",
    "# 显示词云\n",
    "plt.figure(figsize=(8, 5))  # 设置图形的显示大小\n",
    "plt.imshow(wordcloud, interpolation='bilinear')  # 使用双线性插值显示更平滑的图像\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "\n",
    "plt.savefig('./img/wordcloud.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b38edb4c1bf78d54",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
