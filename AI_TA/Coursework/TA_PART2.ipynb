{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text Analysis Part2 - Named Entity Recognition (NER) \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dfe1e6007dd2718"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tag import CRFTagger\n",
    "import re, unicodedata\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:55:59.452843Z",
     "start_time": "2024-04-09T20:55:59.443871Z"
    }
   },
   "id": "ef5ad0dd046aed4b",
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Load the dataset\n",
    "Load the BC5CDR dataset from the Hugging Face datasets library.\n",
    "Use train and validation sets for training, and the test set for testing.\n",
    "\n",
    "Map the labels to the following tags:\n",
    "```\n",
    "{\n",
    "    0: \"O\",\n",
    "    1: \"B-Chemical\",\n",
    "    2: \"B-Disease\",\n",
    "    3: \"I-Disease\",\n",
    "    4: \"I-Chemical\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "124dd26fe746006a"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:23:06.789300Z",
     "start_time": "2024-04-09T20:23:02.851511Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"tner/bc5cdr\", \n",
    "    cache_dir=\"./NLP_data_cache\",\n",
    ")\n",
    "\n",
    "train_dataset= dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 定义标签的映射\n",
    "ner_tag_mapping= {0: \"O\",1: \"B-Chemical\",2: \"B-Disease\",3: \"I-Disease\",4: \"I-Chemical\"}\n",
    "\n",
    "train_set=[list(zip(s['tokens'], [ner_tag_mapping[tok] for tok in s['tags']])) for s in train_dataset][:-1]\n",
    "val_set=[list(zip(s['tokens'], [ner_tag_mapping[tok] for tok in s['tags']])) for s in val_dataset][:-1]\n",
    "test_set=[list(zip(s['tokens'], [ner_tag_mapping[tok] for tok in s['tags']])) for s in test_dataset][:-1]\n",
    "\n",
    "train_set=train_set+val_set\n",
    "test_tokens = [s['tokens'] for s in test_dataset][:-1]\n",
    "test_tags = [[ner_tag_mapping[tok] for tok in s['tags']] for s in test_dataset][:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:23:22.377970Z",
     "start_time": "2024-04-09T20:23:21.352010Z"
    }
   },
   "id": "9737e264922659cc",
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Train a CRF NER tagger\n",
    "Train a CRF NER tagger using the training set. \n",
    "Define some functions to evaluate the performance of the tagger on the test set. In NER, an entity may consist of a single word or multiple consecutive words. Therefore, an entity match is considered correct only if all its components are accurately identified and categorised correctly.\n",
    "\n",
    "Use the funcion \"extract_spans\" to extract the spans of the named entities from the tagged sentences. \"cal_span_level_f1\" function calculates the F1 score for each class and the macro-average F1 score.\n",
    "These 2 funcions are provieded by [text_labs_public](https://github.com/uob-TextAnalytics/text_labs_public/blob/main/2_sequence_tagging.ipynb)\n",
    "\n",
    "首先使用nltk.tag.CRFtagger来训练一个Tagger并进行评估，然后自定义一个CRFTagger类，添加以下特征：\n",
    "- 前后单词的特征：是否大小写等\n",
    "- 当前单词的特征：是否大小写，是否是数字，是否是化学品或疾病的常见后缀\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73a32b8ed27b842"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import re\n",
    "\n",
    "class CustomCRFTagger(CRFTagger):\n",
    "    def _get_features(self, tokens, idx):\n",
    "\n",
    "        token = tokens[idx]\n",
    "        feature_list = [\n",
    "            'bias',  # 偏置项\n",
    "            'word.lower=' + token.lower(), # 小写形式\n",
    "            'word[-3:]=' + token[-3:],  # 后缀\n",
    "            'word[-2:]=' + token[-2:],  # 后缀\n",
    "            'word.isupper=%s' % token.isupper(), # 是否全大写\n",
    "            'word.istitle=%s' % token.istitle(), # 是否首字母大写\n",
    "            'word.isdigit=%s' % token.isdigit(), # 是否是数字\n",
    "            'word.ischemical=%s' % bool(re.match(r'.*(ate|ium|ide|ite)$', token.lower())),  # 化学品常见后缀\n",
    "            'word.isdisease=%s' % bool(re.match(r'.*(itis|osis|oma|pathy)$', token.lower())),  # 疾病常见后缀\n",
    "        ]\n",
    "        \n",
    "        # 添加上下文特征\n",
    "        if idx > 0: # 如果不是句子的第一个单词\n",
    "            prev_token = tokens[idx-1]\n",
    "            feature_list.extend([\n",
    "                '-1:word.lower=' + prev_token.lower(), # 前一个单词的小写形式\n",
    "                '-1:word.istitle=%s' % prev_token.istitle(), # 前一个单词是否首字母大写\n",
    "                '-1:word.isupper=%s' % prev_token.isupper(), # 前一个单词是否全大写\n",
    "            ])\n",
    "        else:\n",
    "            feature_list.append(\"BOS\")  # 句子开始\n",
    "        \n",
    "        if idx < len(tokens)-1: # 如果不是句子的最后一个单词\n",
    "            next_token = tokens[idx+1]\n",
    "            feature_list.extend([\n",
    "                '+1:word.lower=' + next_token.lower(), # 后一个单词的小写形式\n",
    "                '+1:word.istitle=%s' % next_token.istitle(), # 后一个单词是否首字母大写\n",
    "                '+1:word.isupper=%s' % next_token.isupper(), # 后一个单词是否全大写\n",
    "            ])\n",
    "        else:\n",
    "            feature_list.append(\"EOS\")  # 句子结束\n",
    "        \n",
    "        return feature_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:57:48.189391Z",
     "start_time": "2024-04-09T20:57:48.181418Z"
    }
   },
   "id": "40f4b92e410228b7",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_spans(tagged_sents):\n",
    "    spans = {}\n",
    "        \n",
    "    for sidx, sent in enumerate(tagged_sents):\n",
    "        start = -1\n",
    "        entity_type = None\n",
    "        for i, (tok, lab) in enumerate(sent):\n",
    "            if 'B-' in lab:\n",
    "                start = i\n",
    "                end = i + 1\n",
    "                entity_type = lab[2:]\n",
    "            elif 'I-' in lab:\n",
    "                end = i + 1\n",
    "            elif lab == 'O' and start >= 0:\n",
    "                \n",
    "                if entity_type not in spans:\n",
    "                    spans[entity_type] = []\n",
    "                \n",
    "                spans[entity_type].append((start, end, sidx))\n",
    "                start = -1      \n",
    "        # Sometimes an I-token is the last token in the sentence, so we still have to add the span to the list\n",
    "        if start >= 0:    \n",
    "            if entity_type not in spans:\n",
    "                spans[entity_type] = []\n",
    "                \n",
    "            spans[entity_type].append((start, end, sidx))\n",
    "                \n",
    "    return spans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:14:59.394316Z",
     "start_time": "2024-04-09T20:14:59.381836Z"
    }
   },
   "id": "2fee222ed393037a",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cal_span_level_f1(test_sents, test_sents_with_pred):\n",
    "    # gold spans\n",
    "    gold_spans = extract_spans(test_sents)\n",
    "\n",
    "    # predicted spans\n",
    "    pred_spans = extract_spans(test_sents_with_pred)\n",
    "    \n",
    "    # compute the metrics for each class:\n",
    "    f1_per_class = []\n",
    "    \n",
    "    ne_types = gold_spans.keys()  # get the list of named entity types (not the tags)\n",
    "    \n",
    "    for ne_type in ne_types:\n",
    "        # compute the confusion matrix\n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "        \n",
    "        for span in pred_spans[ne_type]:\n",
    "            if span in gold_spans[ne_type]:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "                \n",
    "        false_neg = 0\n",
    "        for span in gold_spans[ne_type]:\n",
    "            if span not in pred_spans[ne_type]:\n",
    "                false_neg += 1\n",
    "                \n",
    "        if true_pos + false_pos == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = true_pos / float(true_pos + false_pos)\n",
    "            \n",
    "        if true_pos + false_neg == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = true_pos / float(true_pos + false_neg)\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "            \n",
    "        f1_per_class.append(f1)\n",
    "        print(f'F1 score for class {ne_type} = {f1}')\n",
    "        \n",
    "    print(f'Macro-average f1 score = {np.mean(f1_per_class)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:12:26.100926Z",
     "start_time": "2024-04-09T20:12:26.087043Z"
    }
   },
   "id": "bd6f484abddb67fe",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8510595960600934\n",
      "F1 score for class Disease = 0.7077707006369427\n",
      "Macro-average f1 score = 0.7794151483485181\n"
     ]
    }
   ],
   "source": [
    "# Train a CRF NER tagger\n",
    "def train_CRF_NER_tagger(train_set, tagger_name):\n",
    "    tagger = tagger_name\n",
    "    tagger.train(train_set, 'crf.tagger')\n",
    "    return tagger  # return the trained model\n",
    "\n",
    "tagger = train_CRF_NER_tagger(train_set,CRFTagger())\n",
    "predicted_tags = tagger.tag_sents(test_tokens)\n",
    "cal_span_level_f1(test_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:20:32.789181Z",
     "start_time": "2024-04-09T20:20:21.802796Z"
    }
   },
   "id": "71d7e5f1e2e3b486",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8648486664668865\n",
      "F1 score for class Disease = 0.7600696171059175\n",
      "Macro-average f1 score = 0.812459141786402\n"
     ]
    }
   ],
   "source": [
    "tagger = train_CRF_NER_tagger(train_set,CustomCRFTagger())\n",
    "predicted_tags = tagger.tag_sents(test_tokens)\n",
    "cal_span_level_f1(test_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:33:30.769035Z",
     "start_time": "2024-04-09T20:32:52.329255Z"
    }
   },
   "id": "6818846a71efe217",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class StemmedCRFTagger(CustomCRFTagger):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(StemmedCRFTagger, self).__init__(*args, **kwargs)\n",
    "        self.stemmer = PorterStemmer()\n",
    "    \n",
    "    def _get_features(self, tokens, idx):\n",
    "        # 首先，调用父类的_get_features方法来获取基础特征\n",
    "        features = super(StemmedCRFTagger, self)._get_features(tokens, idx)\n",
    "        \n",
    "        # 对当前单词进行词干提取\n",
    "        stem = self.stemmer.stem(tokens[idx])\n",
    "        \n",
    "        # 将词干特征添加到特征列表中\n",
    "        features.append('word.stem=' + stem)\n",
    "        \n",
    "        return features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:57:59.133502Z",
     "start_time": "2024-04-09T20:57:59.118538Z"
    }
   },
   "id": "723d77d55d2267e0",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.872792937399679\n",
      "F1 score for class Disease = 0.7830533235938643\n",
      "Macro-average f1 score = 0.8279231304967716\n"
     ]
    }
   ],
   "source": [
    "tagger = train_CRF_NER_tagger(train_set,StemmedCRFTagger())\n",
    "predicted_tags = tagger.tag_sents(test_tokens)\n",
    "cal_span_level_f1(test_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:58:56.384736Z",
     "start_time": "2024-04-09T20:58:05.571533Z"
    }
   },
   "id": "c82a9ce74b5a3128",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_data_for_pos(data):\n",
    "    \"\"\"将数据集转换为包含词性标注的格式，同时保留NER标签\"\"\"\n",
    "    processed_data = []\n",
    "    for sent in data:\n",
    "        words, ner_tags = zip(*sent)  # 分离单词和NER标签\n",
    "        pos_tags = [pos for word, pos in pos_tag(words)]  # 对单词进行词性标注\n",
    "        \n",
    "        processed_sent = [((word, pos), tag) for word, pos, tag in zip(words, pos_tags, ner_tags)]\n",
    "        processed_data.append(processed_sent)\n",
    "    return processed_data\n",
    "\n",
    "train_set_pos = preprocess_data_for_pos(train_set)\n",
    "test_set_pos = preprocess_data_for_pos(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T21:26:42.256296Z",
     "start_time": "2024-04-09T21:26:31.980357Z"
    }
   },
   "id": "ef214efe8b3473d0",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. 自定义CRFTagger类\n",
    "class CustomCRFTaggerWithPOS(CRFTagger):\n",
    "    def _get_features(self, tokens, idx):\n",
    "        token, pos = tokens[idx]\n",
    "        feature_list = [\n",
    "            'bias',\n",
    "            'word.lower=' + token.lower(),\n",
    "            'word[-3:]=' + token[-3:],\n",
    "            'word[-2:]=' + token[-2:],\n",
    "            'word.isupper=%s' % token.isupper(),\n",
    "            'word.istitle=%s' % token.istitle(),\n",
    "            'word.isdigit=%s' % token.isdigit(),\n",
    "            'word.ischemical=%s' % bool(re.match(r'.*(ate|ium|ide|ite)$', token.lower())),\n",
    "            'word.isdisease=%s' % bool(re.match(r'.*(itis|osis|oma|pathy)$', token.lower())),\n",
    "            'pos=' + pos,  # 添加POS特征\n",
    "        ]\n",
    "\n",
    "        if idx > 0: # 如果不是句子的第一个单词\n",
    "            prev_token, prev_pos = tokens[idx-1] # 获取前一个单词的大小写形式和POS标签\n",
    "            feature_list.extend([\n",
    "                '-1:word.lower=' + prev_token.lower(),\n",
    "                '-1:word.istitle=%s' % prev_token.istitle(),\n",
    "                '-1:word.isupper=%s' % prev_token.isupper(),\n",
    "                '-1:pos=' + prev_pos,\n",
    "            ])\n",
    "        else:\n",
    "            feature_list.append(\"BOS\")\n",
    "        \n",
    "        if idx < len(tokens) - 1: # 如果不是句子的最后一个单词\n",
    "            next_token, next_pos = tokens[idx+1] # 获取后一个单词的大小写形式和POS标签\n",
    "            feature_list.extend([\n",
    "                '+1:word.lower=' + next_token.lower(),\n",
    "                '+1:word.istitle=%s' % next_token.istitle(),\n",
    "                '+1:word.isupper=%s' % next_token.isupper(),\n",
    "                '+1:pos=' + next_pos,\n",
    "            ])\n",
    "        else:\n",
    "            feature_list.append(\"EOS\")\n",
    "        \n",
    "        return feature_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T21:28:21.550163Z",
     "start_time": "2024-04-09T21:28:21.532221Z"
    }
   },
   "id": "362581a93ee8099",
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8644135188866798\n",
      "F1 score for class Disease = 0.7635913312693499\n",
      "Macro-average f1 score = 0.8140024250780149\n"
     ]
    }
   ],
   "source": [
    "test_tokens_pos = [[(word, pos) for (word, pos), tag in sent] for sent in test_set_pos]\n",
    "\n",
    "tagger = train_CRF_NER_tagger(train_set_pos, CustomCRFTaggerWithPOS())\n",
    "predicted_tags = tagger.tag_sents(test_tokens_pos)\n",
    "cal_span_level_f1(test_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T21:38:10.144618Z",
     "start_time": "2024-04-09T21:37:19.850847Z"
    }
   },
   "id": "6681330fd3761bd3",
   "execution_count": 121
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
