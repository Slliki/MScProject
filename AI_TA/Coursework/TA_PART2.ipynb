{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text Analysis Part2 - Named Entity Recognition (NER) \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dfe1e6007dd2718"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tag import CRFTagger\n",
    "import re, unicodedata\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T11:55:23.041253Z",
     "start_time": "2024-04-10T11:55:20.383973Z"
    }
   },
   "id": "ef5ad0dd046aed4b",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Load the dataset\n",
    "Load the BC5CDR dataset from the Hugging Face datasets library.\n",
    "Use train and validation sets for training, and the test set for testing.\n",
    "\n",
    "Map the labels to the following tags:\n",
    "```\n",
    "{\n",
    "    0: \"O\",\n",
    "    1: \"B-Chemical\",\n",
    "    2: \"B-Disease\",\n",
    "    3: \"I-Disease\",\n",
    "    4: \"I-Chemical\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "124dd26fe746006a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-10T11:56:01.219359Z",
     "start_time": "2024-04-10T11:55:56.521317Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"tner/bc5cdr\", \n",
    "    cache_dir=\"./NLP_data_cache\",\n",
    ")\n",
    "\n",
    "train_dataset= dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 定义标签的映射\n",
    "ner_tag_mapping= {0: \"O\",1: \"B-Chemical\",2: \"B-Disease\",3: \"I-Disease\",4: \"I-Chemical\"}\n",
    "\n",
    "train_set=[list(zip(s['tokens'], [ner_tag_mapping[tok] for tok in s['tags']])) for s in train_dataset][:-1]\n",
    "val_set=[list(zip(s['tokens'], [ner_tag_mapping[tok] for tok in s['tags']])) for s in val_dataset][:-1]\n",
    "test_set=[list(zip(s['tokens'], [ner_tag_mapping[tok] for tok in s['tags']])) for s in test_dataset][:-1]\n",
    "\n",
    "train_set=train_set+val_set\n",
    "test_tokens = [s['tokens'] for s in test_dataset][:-1]\n",
    "test_tags = [[ner_tag_mapping[tok] for tok in s['tags']] for s in test_dataset][:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:09:37.128775Z",
     "start_time": "2024-04-10T12:09:36.056517Z"
    }
   },
   "id": "9737e264922659cc",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Train a CRF NER tagger\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73a32b8ed27b842"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Evaluation functions\n",
    "使用Lab（text_labs_public）中的函数进行评估，主要为了提取命名实体的span，然后计算整体的F1值\n",
    "\n",
    "Define some functions to evaluate the performance of the tagger on the test set. In NER, an entity may consist of a single word or multiple consecutive words. Therefore, an entity match is considered correct only if all its components are accurately identified and categorised correctly.\n",
    "\n",
    "Use the funcion \"extract_spans\" to extract the spans of the named entities from the tagged sentences. \"cal_span_level_f1\" function calculates the F1 score for each class and the macro-average F1 score.\n",
    "These 2 funcions are provieded by [text_labs_public](https://github.com/uob-TextAnalytics/text_labs_public/blob/main/2_sequence_tagging.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f36e70876245c3db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_spans(tagged_sents):\n",
    "    spans = {}\n",
    "        \n",
    "    for sidx, sent in enumerate(tagged_sents):\n",
    "        start = -1\n",
    "        entity_type = None\n",
    "        for i, (tok, lab) in enumerate(sent):\n",
    "            if 'B-' in lab:\n",
    "                start = i\n",
    "                end = i + 1\n",
    "                entity_type = lab[2:]\n",
    "            elif 'I-' in lab:\n",
    "                end = i + 1\n",
    "            elif lab == 'O' and start >= 0:\n",
    "                \n",
    "                if entity_type not in spans:\n",
    "                    spans[entity_type] = []\n",
    "                \n",
    "                spans[entity_type].append((start, end, sidx))\n",
    "                start = -1      \n",
    "        # Sometimes an I-token is the last token in the sentence, so we still have to add the span to the list\n",
    "        if start >= 0:    \n",
    "            if entity_type not in spans:\n",
    "                spans[entity_type] = []\n",
    "                \n",
    "            spans[entity_type].append((start, end, sidx))\n",
    "                \n",
    "    return spans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T11:56:09.480462Z",
     "start_time": "2024-04-10T11:56:09.468461Z"
    }
   },
   "id": "2fee222ed393037a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cal_span_level_f1(test_sents, test_sents_with_pred):\n",
    "    # gold spans\n",
    "    gold_spans = extract_spans(test_sents)\n",
    "\n",
    "    # predicted spans\n",
    "    pred_spans = extract_spans(test_sents_with_pred)\n",
    "    \n",
    "    # compute the metrics for each class:\n",
    "    f1_per_class = []\n",
    "    \n",
    "    ne_types = gold_spans.keys()  # get the list of named entity types (not the tags)\n",
    "    \n",
    "    for ne_type in ne_types:\n",
    "        # compute the confusion matrix\n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "        \n",
    "        for span in pred_spans[ne_type]:\n",
    "            if span in gold_spans[ne_type]:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "                \n",
    "        false_neg = 0\n",
    "        for span in gold_spans[ne_type]:\n",
    "            if span not in pred_spans[ne_type]:\n",
    "                false_neg += 1\n",
    "                \n",
    "        if true_pos + false_pos == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = true_pos / float(true_pos + false_pos)\n",
    "            \n",
    "        if true_pos + false_neg == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = true_pos / float(true_pos + false_neg)\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "            \n",
    "        f1_per_class.append(f1)\n",
    "        print(f'F1 score for class {ne_type} = {f1}')\n",
    "        \n",
    "    print(f'Macro-average f1 score = {np.mean(f1_per_class)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T11:56:11.409132Z",
     "start_time": "2024-04-10T11:56:11.403133Z"
    }
   },
   "id": "bd6f484abddb67fe",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Train a CRF NER tagger\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa24380b94c106e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. Customized CRF Tagger\n",
    "class CustomCRFTagger(CRFTagger):\n",
    "    def _get_features(self, tokens, idx):\n",
    "\n",
    "        token = tokens[idx]\n",
    "        feature_list = [\n",
    "            'bias',  # 偏置项\n",
    "            'word.lower=' + token.lower(), # 小写形式\n",
    "            'word[-3:]=' + token[-3:],  # 后缀\n",
    "            'word[-2:]=' + token[-2:],  # 后缀\n",
    "            'word.isupper=%s' % token.isupper(), # 是否全大写\n",
    "            'word.istitle=%s' % token.istitle(), # 是否首字母大写\n",
    "            'word.isdigit=%s' % token.isdigit(), # 是否是数字\n",
    "            'word.ischemical=%s' % bool(re.match(r'.*(ate|ium|ide|ite)$', token.lower())),  # 化学品常见后缀\n",
    "            'word.isdisease=%s' % bool(re.match(r'.*(itis|osis|oma|pathy)$', token.lower())),  # 疾病常见后缀\n",
    "        ]\n",
    "        \n",
    "        # 添加上下文特征\n",
    "        if idx > 0: # 如果不是句子的第一个单词\n",
    "            prev_token = tokens[idx-1]\n",
    "            feature_list.extend([\n",
    "                '-1:word.lower=' + prev_token.lower(), # 前一个单词的小写形式\n",
    "                '-1:word.istitle=%s' % prev_token.istitle(), # 前一个单词是否首字母大写\n",
    "                '-1:word.isupper=%s' % prev_token.isupper(), # 前一个单词是否全大写\n",
    "            ])\n",
    "        else:\n",
    "            feature_list.append(\"BOS\")  # 句子开始\n",
    "        \n",
    "        if idx < len(tokens)-1: # 如果不是句子的最后一个单词\n",
    "            next_token = tokens[idx+1]\n",
    "            feature_list.extend([\n",
    "                '+1:word.lower=' + next_token.lower(), # 后一个单词的小写形式\n",
    "                '+1:word.istitle=%s' % next_token.istitle(), # 后一个单词是否首字母大写\n",
    "                '+1:word.isupper=%s' % next_token.isupper(), # 后一个单词是否全大写\n",
    "            ])\n",
    "        else:\n",
    "            feature_list.append(\"EOS\")  # 句子结束\n",
    "        \n",
    "        return feature_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T11:56:06.968306Z",
     "start_time": "2024-04-10T11:56:06.949306Z"
    }
   },
   "id": "40f4b92e410228b7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. POS Tagger\n",
    "class CustomCRFTaggerWithPOS(CRFTagger):\n",
    "    def _get_features(self, tokens, idx):\n",
    "        token, pos = tokens[idx] # 这里的token=word, pos=POS标签\n",
    "        feature_list = [\n",
    "            'bias',\n",
    "            'word.lower=' + token.lower(),\n",
    "            'word[-3:]=' + token[-3:],\n",
    "            'word[-2:]=' + token[-2:],\n",
    "            'word.isupper=%s' % token.isupper(),\n",
    "            'word.istitle=%s' % token.istitle(),\n",
    "            'word.isdigit=%s' % token.isdigit(),\n",
    "            'word.ischemical=%s' % bool(re.match(r'.*(ate|ium|ide|ite)$', token.lower())),\n",
    "            'word.isdisease=%s' % bool(re.match(r'.*(itis|osis|oma|pathy)$', token.lower())),\n",
    "            'pos=' + pos,  # 添加POS特征\n",
    "        ]\n",
    "\n",
    "        if idx > 0: # 如果不是句子的第一个单词\n",
    "            prev_token, prev_pos = tokens[idx-1] # 获取前一个单词的大小写形式和POS标签\n",
    "            feature_list.extend([\n",
    "                '-1:word.lower=' + prev_token.lower(),\n",
    "                '-1:word.istitle=%s' % prev_token.istitle(),\n",
    "                '-1:word.isupper=%s' % prev_token.isupper(),\n",
    "                '-1:pos=' + prev_pos,\n",
    "            ])\n",
    "        else:\n",
    "            feature_list.append(\"BOS\")\n",
    "        \n",
    "        if idx < len(tokens) - 1: # 如果不是句子的最后一个单词\n",
    "            next_token, next_pos = tokens[idx+1] # 获取后一个单词的大小写形式和POS标签\n",
    "            feature_list.extend([\n",
    "                '+1:word.lower=' + next_token.lower(),\n",
    "                '+1:word.istitle=%s' % next_token.istitle(),\n",
    "                '+1:word.isupper=%s' % next_token.isupper(),\n",
    "                '+1:pos=' + next_pos,\n",
    "            ])\n",
    "        else:\n",
    "            feature_list.append(\"EOS\")\n",
    "        \n",
    "        return feature_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T11:59:10.430124Z",
     "start_time": "2024-04-10T11:59:10.410925Z"
    }
   },
   "id": "362581a93ee8099",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 3. POS and Stemming Tagger\n",
    "class CustomCRFTaggerWithPOSAndStemming(CustomCRFTaggerWithPOS):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomCRFTaggerWithPOSAndStemming, self).__init__(*args, **kwargs)\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        token, pos = tokens[idx]  # 这里的token=word, pos=POS标签\n",
    "        stem = self.stemmer.stem(token)  # 提取词干\n",
    "\n",
    "        feature_list = super(CustomCRFTaggerWithPOSAndStemming, self)._get_features(tokens, idx)\n",
    "\n",
    "        # 添加词干特征\n",
    "        feature_list.append('stem=' + stem)\n",
    "\n",
    "        return feature_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:26:00.871833Z",
     "start_time": "2024-04-10T12:26:00.865833Z"
    }
   },
   "id": "d73af32642b68a7f",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train a CRF NER tagger\n",
    "def train_CRF_NER_tagger(train_set, tagger_name):\n",
    "    tagger = tagger_name\n",
    "    tagger.train(train_set, 'crf.tagger')\n",
    "    return tagger  # return the trained model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:47:25.426545Z",
     "start_time": "2024-04-10T12:47:25.408038Z"
    }
   },
   "id": "c854aaf510c3451d",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[[(('Naloxone', 'NN'), 'B-Chemical'),\n  (('reverses', 'VBZ'), 'O'),\n  (('the', 'DT'), 'O'),\n  (('antihypertensive', 'JJ'), 'O'),\n  (('effect', 'NN'), 'O'),\n  (('of', 'IN'), 'O'),\n  (('clonidine', 'NN'), 'B-Chemical'),\n  (('.', '.'), 'O')],\n [(('In', 'IN'), 'O'),\n  (('unanesthetized', 'JJ'), 'O'),\n  ((',', ','), 'O'),\n  (('spontaneously', 'RB'), 'O'),\n  (('hypertensive', 'JJ'), 'B-Disease'),\n  (('rats', 'NNS'), 'O'),\n  (('the', 'DT'), 'O'),\n  (('decrease', 'NN'), 'O'),\n  (('in', 'IN'), 'O'),\n  (('blood', 'NN'), 'O'),\n  (('pressure', 'NN'), 'O'),\n  (('and', 'CC'), 'O'),\n  (('heart', 'NN'), 'O'),\n  (('rate', 'NN'), 'O'),\n  (('produced', 'VBN'), 'O'),\n  (('by', 'IN'), 'O'),\n  (('intravenous', 'JJ'), 'O'),\n  (('clonidine', 'NN'), 'B-Chemical'),\n  ((',', ','), 'O'),\n  (('5', 'CD'), 'O'),\n  (('to', 'TO'), 'O'),\n  (('20', 'CD'), 'O'),\n  (('micrograms', 'NNS'), 'O'),\n  (('/', 'JJ'), 'O'),\n  (('kg', 'NN'), 'O'),\n  ((',', ','), 'O'),\n  (('was', 'VBD'), 'O'),\n  (('inhibited', 'VBN'), 'O'),\n  (('or', 'CC'), 'O'),\n  (('reversed', 'VBN'), 'O'),\n  (('by', 'IN'), 'O'),\n  (('nalozone', 'NN'), 'B-Chemical'),\n  ((',', ','), 'O'),\n  (('0', 'CD'), 'O'),\n  (('.', '.'), 'O')]]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data_for_pos(data):\n",
    "    \"\"\"将数据集转换为包含词性标注的格式，同时保留NER标签\"\"\"\n",
    "    processed_data = []\n",
    "    for sent in data:\n",
    "        words, ner_tags = zip(*sent)  # 分离单词和NER标签\n",
    "        pos_tags = [pos for word, pos in pos_tag(words)]  # 对单词进行词性标注\n",
    "        \n",
    "        processed_sent = [((word, pos), tag) for word, pos, tag in zip(words, pos_tags, ner_tags)]\n",
    "        processed_data.append(processed_sent)\n",
    "    return processed_data\n",
    "\n",
    "train_set_pos = preprocess_data_for_pos(train_set)\n",
    "test_set_pos = preprocess_data_for_pos(test_set)\n",
    "\n",
    "train_set_pos[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T11:59:00.267429Z",
     "start_time": "2024-04-10T11:58:49.624449Z"
    }
   },
   "id": "ef214efe8b3473d0",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8510595960600934\n",
      "F1 score for class Disease = 0.7077707006369427\n",
      "Macro-average f1 score = 0.7794151483485181\n"
     ]
    }
   ],
   "source": [
    "# Original CRF Tagger\n",
    "tagger = train_CRF_NER_tagger(train_set,CRFTagger())\n",
    "predicted_tags = tagger.tag_sents(test_tokens)\n",
    "cal_span_level_f1(test_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:04.974446Z",
     "start_time": "2024-04-10T12:09:52.936680Z"
    }
   },
   "id": "71d7e5f1e2e3b486",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8648486664668865\n",
      "F1 score for class Disease = 0.7600696171059175\n",
      "Macro-average f1 score = 0.812459141786402\n"
     ]
    }
   ],
   "source": [
    "# Customized CRF Tagger\n",
    "tagger = train_CRF_NER_tagger(train_set,CustomCRFTagger())\n",
    "predicted_tags = tagger.tag_sents(test_tokens)\n",
    "cal_span_level_f1(test_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:10:44.283805Z",
     "start_time": "2024-04-10T12:10:04.975446Z"
    }
   },
   "id": "6818846a71efe217",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8644135188866798\n",
      "F1 score for class Disease = 0.7635913312693499\n",
      "Macro-average f1 score = 0.8140024250780149\n"
     ]
    }
   ],
   "source": [
    "# Customized with POS CRF Tagger\n",
    "test_tokens_pos = [[(word, pos) for (word, pos), tag in sent] for sent in test_set_pos]\n",
    "\n",
    "tagger = train_CRF_NER_tagger(train_set_pos, CustomCRFTaggerWithPOS())\n",
    "predicted_tags = tagger.tag_sents(test_tokens_pos)\n",
    "cal_span_level_f1(test_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:14:57.187466Z",
     "start_time": "2024-04-10T12:14:08.662731Z"
    }
   },
   "id": "6681330fd3761bd3",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8730316922463623\n",
      "F1 score for class Disease = 0.784527707044986\n",
      "Macro-average f1 score = 0.8287796996456742\n"
     ]
    }
   ],
   "source": [
    "# Customized with POS and Stemming CRF Tagger\n",
    "tagger = train_CRF_NER_tagger(train_set_pos, CustomCRFTaggerWithPOSAndStemming())\n",
    "predicted_tags = tagger.tag_sents(test_tokens_pos)\n",
    "cal_span_level_f1(test_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:27:02.472073Z",
     "start_time": "2024-04-10T12:26:10.701652Z"
    }
   },
   "id": "c226a171708fe287",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. 原版Tagger：0.8511，0.7078，0.7794\n",
    "2. 自定义Tagger：0.8648，0.7601，0.8125\n",
    "3. 自定义+pos：0.8744，0.7636，0.8140\n",
    "4. 自定义+pos+stem：0.8730，0.7845，0.8288"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b39be2324039347d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
