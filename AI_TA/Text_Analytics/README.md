# Text Analytics
该文件夹包含了文本分析的相关实验笔记。原笔记保存在project：text_analytics_public中。
该project使用单独的环境`text_analytics`。

本project统一使用`mytorch`环境，因此需要单独下载nlp相关的库。
- `nltk`：自然语言处理库，提供了大量的语料库和工具
- `datasets`: Huggingface的datasets库，提供了大量的NLP数据集.注意使用version=2.16.1，否则会报错
- `transformers`: Huggingface的transformers库，提供了大量的预训练模型和工具

## 文本分析的基本步骤
### 1. 数据收集
- **目的**：收集需要分析的文本数据。数据可以来源于多种渠道，如社交媒体、网站、论坛、在线评论、书籍、文章等。
- **方法**：使用网络爬虫、API调用、数据库访问等技术。

### 2. 数据预处理
- **目的**：清洗和准备数据，以便于分析。
- **步骤包括**：
  - **文本清洗**：去除无关的内容，如HTML标签、特殊字符、停用词（the, is, at, which等常见但对分析帮助不大的词）。
  - **分词（Tokenization）**：将文本拆分成单词或短语的过程。
  - **词形还原（Lemmatization）和词干提取（Stemming）**：将词汇还原到基本形式，以减少词汇的多样性。
  - **词性标注（POS Tagging）**：标记每个单词的词性（名词、动词等）。
  - **向量化**：将文本转换为数值形式，如词袋模型（Bag of Words）或TF-IDF（Term Frequency-Inverse Document Frequency）。

### 3. 探索性数据分析（EDA）
- **目的**：通过统计图表等方法对文本数据进行初步分析，理解数据的基本特征。
- **方法**：使用词频分布、词云、n-gram分析等探索文本内容的主题和模式。

### 4. 特征工程
- **目的**：基于原始数据构建有用的特征，以提高模型的性能。
- **方法**：创建基于文本的特征（如词频、句子长度等），以及使用高级文本表示方法（如Word2Vec、BERT嵌入）。

### 5. 建模和算法选择
- **目的**：选择合适的算法来训练模型，根据需求进行分类、聚类、情感分析等。
- **方法**：使用机器学习和深度学习算法，如朴素贝叶斯、逻辑回归、随机森林、神经网络等。

### 6. 训练模型
- **目的**：使用训练数据来训练选定的模型。
- **方法**：分割数据集为训练集和测试集，然后使用训练集来训练模型。

### 7. 评估和调优
- **目的**：评估模型的性能，并通过调整参数来优化。
- **方法**：使用准确率、召回率、F1分数等指标评估模型。可能需要进行交叉验证、调整学习率、改变模型结构等步骤来提高模型性能。

### 8. 解释和部署
- **目的**：解释模型结果，将模型部署为应用程序或服务。
- **方法**：提供模型解释（如特征重要性），并将训练好的模型集成到生产环境中，以便于实时或批量处理新数据。

文本分析是一个迭代过程，可能需要多次回到之前的步骤中，根据分析结果调整策略和方法。

此外，具体的步骤和方法可能会根据具体任务（如情感分析、主题建模、文本分类等）和数据的性质有所不同。


## 对比传统NLP和深度学习NLP
当我们谈论传统NLP（自然语言处理）与使用深度学习的NLP时，我们主要是在讨论两种不同的方法和技术集合，这些方法和技术集合在处理语言数据时采用了不同的工作流程和策略。

### 传统NLP工作流程

传统NLP依赖于手工设计的特征和规则。这个过程通常包括以下几个步骤：

1. **预处理**：这包括文本清洗、分词（将文本分解为单词或词语）、归一化（如将所有字母转换为小写）等。
2. **特征提取**：从文本数据中提取有用的特征，如词频（TF）、逆文档频率（IDF）、句法特征、词性标注等。
3. **建立模型**：使用统计学习方法，如决策树、支持向量机（SVM）、隐马尔可夫模型（HMM）等，基于提取的特征构建模型。
4. **评估与调优**：通过预留的测试集对模型进行评估，并根据评估结果调整模型参数或特征提取方法。

这种方法依赖于丰富的领域知识来设计有效的特征和规则，这些特征和规则对于不同的任务和语言可能会有很大的不同。

### 使用深度学习的NLP工作流程

![img.png](img.png)

深度学习在NLP中的应用摒弃了大量的手工特征工程，转而利用深度神经网络自动从数据中学习表示。其工作流程大致如下：

1. **预处理**：虽然深度学习减少了特征工程的需要，但预处理仍然很重要，例如分词、词嵌入（将词转换为向量表示）等。
2. **模型构建**：设计深度神经网络模型，如循环神经网络（RNN）、长短时记忆网络（LSTM）、Transformer等，这些模型能够捕捉文本中的复杂模式和依赖关系。
3. **训练模型**：使用大量标注数据来训练模型，通过反向传播和梯度下降等优化算法调整模型参数。
4. **评估与调优**：使用独立的测试集评估模型性能，并通过调整模型架构、优化算法参数等方式进行优化。

深度学习方法能够自动从大量数据中学习复杂的特征表示，减少了对领域知识的依赖，并在许多NLP任务中取得了显著的性能提升。

总的来说，传统NLP方法依赖于详细的特征工程和规则设计，而深度学习方法通过学习大量数据中的模式自动提取特征，这使得后者在处理复杂的语言模式和大规模数据集时更为有效。