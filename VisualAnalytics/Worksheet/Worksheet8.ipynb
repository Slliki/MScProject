{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 8 Worksheet \n",
    "\n",
    "In this worksheet we look at two topographic methods for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-distributed Stochastic Neighbourhood Embedding\n",
    "\n",
    "The first code block contains useful imports and variable initialisations.\n",
    "\n",
    "(Light-hearted quiz question - why is the number 1729 interesting?).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T13:37:07.103126Z",
     "start_time": "2024-03-13T13:37:07.088720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import mnist_reader\n",
    "import fashion_scatter as fs\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "RS = 1729; # Fix the random state for t-SNE. This makes the lab results reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset you will use for this section of the lab class is the Fashion-MNIST dataset. This dataset consists of 28x28 grayscale image of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images, and the test set has 10,000 images.\n",
    "\n",
    "The classes and their labels are given by the following list:\n",
    "<ull>\n",
    "    <li>0 T-shirt/top</li>\n",
    "    <li>1 Trouser</li>\n",
    "    <li>2 Pullover</li>\n",
    "    <li>3 Dress</li>\n",
    "    <li>4 Coat</li>\n",
    "    <li>5 Sandal</li>\n",
    "    <li>6 Shirt</li>\n",
    "    <li>7 Sneaker</li>\n",
    "    <li>8 Bag</li>\n",
    "    <li>9 Ankle boot</li>\n",
    "    </ul>\n",
    "\n",
    "Use the function `load_mnist` provided on Blackboard to read the datasets into variables `X_train` (image data) and `y_train` (labels) and print the shape of `X_train`. The argument to `load_mnist` is the path where you have stored the image zip files relative to the directory that this notebook is stored in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO block 1\n",
    "X_train, y_train = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60,000 data points is a healthy size of dataset. But for running experiments, it will be more convenient to work with a smaller subset. Write code to take a slice of the first 1000 points from both the X and y arrays. Check that we have examples of all the labels by calling `np.unique` on the y subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO block 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to apply PCA to this dataset and look at the resulting visualisation. Write code to apply the `PCA` class \n",
    "    from `sklearn.decomposition`, extracting four components. (Hint: you need two lines of code: one to call the constructor PCA to set the right number of components; the second should call the `fit_transform` function on `xsubset`. Look at the class documentation to see how to do this.)\n",
    "\n",
    "Make a note of the time elapsed and the proportion of variance explained for these four components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO block 3\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "print ('PCA done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "print ('Variance explained per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first two components from the data frame in the cell below and \n",
    "call the function `fashion_scatter` to visualise the PCA output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO block 4\n",
    "\n",
    "pca_df = pd.DataFrame(columns = ['pca1','pca2','pca3','pca4'])\n",
    "\n",
    "pca_df['pca1'] = pca_result[:,0]\n",
    "pca_df['pca2'] = pca_result[:,1]\n",
    "pca_df['pca3'] = pca_result[:,2]\n",
    "pca_df['pca4'] = pca_result[:,3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write code to apply TSNE (from `sklearn.manifold`) to the same data subset and visualise the result: \n",
    "call the `fit_transform` function to do this. \n",
    "Also, add code to time how long it takes, print the value and record it. Be sure to pass the random state `RS` to the TSNE \n",
    "constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO block 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, in the original t-SNE paper, it was recommended to apply the algorithm after reducing the dimensionality of the\n",
    "data to an intermediate range. Apply PCA again with 50 components \n",
    "(a significant reduction from the 784 dimensions of the original data) and then aply TSNE (again setting the random\n",
    "state). Time how long this takes and display the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO block 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run t-SNE with a perplexity value of 2 (the API can be found __[here](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)__) and plot the result. Write down what effect reducing this parameter from its default value of 30.0 has had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO block 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP\n",
    "\n",
    "The next task is to create and fit a UMAP model and then project the data.\n",
    "\n",
    "UMAP is <b>not</b> part of the standard Python packages but has been implemented as a separate library (located \n",
    "__[here](https://pypi.org/project/umap-learn/)__). There are several\n",
    "ways to install the package. The one that I used was to create an Anaconda power shell (an option from the Windows \n",
    "application selector) and in that shell to type\n",
    "\n",
    "`\n",
    "pip install umap-learn\n",
    "`\n",
    "### Digit data\n",
    "We will use the small digit dataset that is part of the sklearn package, for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "fig, ax_array = plt.subplots(20, 20, figsize=(12, 12))\n",
    "axes = ax_array.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(digits.images[i], cmap='gray_r')\n",
    "plt.setp(axes, xticks=[], yticks=[], frame_on=False)\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have installed the package, call the `fit` and `transform` functions to create an array `embedding` which contains the\n",
    "embedded data. The UMAP API guide can be found __[here](https://umap-learn.readthedocs.io/en/latest/api.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO block 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code plots the data with a colour-coding based on the digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=digits.target, cmap='Spectral', s=5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title('UMAP projection of the Digits dataset', fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review this graphic and write down any points of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour cube dataset\n",
    "We will now use a second dataset to experiment with some of the parameters of the UMAP algorithm. The next block of code defines a function that will be useful to run the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_umap(n_neighbors=15, min_dist=0.1, n_components=2, metric='euclidean', title='', init = 'spectral'):\n",
    "    fit = umap.UMAP(\n",
    "        random_state = 42,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        metric=metric,\n",
    "        init = init\n",
    "    )\n",
    "    u = fit.fit_transform(data);\n",
    "    fig = plt.figure()\n",
    "    if n_components == 1:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], range(len(u)), c=data)\n",
    "    if n_components == 2:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], u[:,1], c=data)\n",
    "    if n_components == 3:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(u[:,0], u[:,1], u[:,2], c=data, s=100)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code creates a four-dimensional dataset randomly sampled. We interpret each row as a tuple of (R,G,B,a) values specifying a color (and translucency). Thus when we plot low-dimensional representations each point can be colored according to its 4-dimensional value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration of parameters\n",
    "sns.set(style='white', context='poster', rc={'figure.figsize':(14,10)})\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(800, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit a UMAP model to the data and transform it into a variable `u`. Time how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO block 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will carry out experiments using `draw_umap`. Run the next block of code (where we set the number of neigbours to 2) and write down what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "draw_umap(n, title='n_neighbours = {}'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parameter controls how UMAP balances local versus global structure in the data. It does this by constraining the size of the local neighbourhood UMAP considers when attempting to learn the manifold structure of the data. \n",
    "\n",
    "Write some code using `draw_umap` to create scatter plots using UMAP for 5, 10, 50, 100, 200 neighbours. Write down what you notice about the effects of this parameter on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO block 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write some code to vary the paramet `min_dist` over values 0.0, 0.1, 0.25, 0.8, and 0.99. Write down what you notice about the effects of the this parameter on the results. The `min_dist` parameter controls how tightly UMAP is allowed to pack points together. It defines the minimum distance apart that points are allowed to be in the low-dimensional representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO block 11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
